The wildest thing right now is you can start a company that can make tens of millions of dollars literally in 24 months, and you can do it for potentially $2 million, $5 million. A year ago, I remember many of the startups in the batch would get sort of enterprise proof of concepts or pilots in particular. And there was a lot of cynicism around whether any of those pilots would translate into real revenue. Fast forward a year, I think we have all first-hand experience that these pilots have turned into real revenue. It's still early days, honestly. Like, you know, we sort of breathe a sigh of relief right now in 2024, but it's anyone's game, honestly. Like, these things are moving so quickly. Welcome back to another episode of The Light Cone. I'm Gary. This is Jared, Harj, and Diana. And collectively, we've funded companies worth hundreds of billions of dollars right at the beginning. So, 2024, what a year. How are you feeling about this, Harj? Pretty great. I think this is the year that everything broke in favor of startups. What I've been thinking about a lot recently is when ChatGBT launched two years ago now, the immediate consensus view was all of the value would go to OpenAI. And very specifically, do you all remember when they announced the GBT or the ChatGBT store? Yeah. I remember the consensus was everything that was built on top of ChatGBT was a GBT wrapper, and the app store was just going to be released and crush every single person trying to build an AI application. And OpenAI would be a ginormous company, but there'd be no opportunity for startups. It sounds kind of ridiculous to say that now, because... Who even remembers the ChatGBT store? Exactly. The ChatGBT store itself was a nothing burger. But more importantly, what are the big AI applications today? I'd say outside of ChatGBT itself, the breakout consumer application is Perplexity. The breakout enterprise application is probably Glean, maybe. In legal tech, you have CaseTex, you have Harvey. Prosumer, you have PhotoRoom. The point being, there are many, many applications that have been built, not by OpenAI. It's been a great time to build startups. Yeah. The wildest thing right now is you can start a company that can make tens of millions of dollars literally in 24 months from zero. And you can do it for potentially $2 million, $5 million. That's sort of the story of one of these companies, OpusClip, which never had to raise a real Series A, and that's something that we sort of see across the YC community as well. Yeah. I think that's a particularly important point that you can do it as a startup without raising tons of capital, because post the GBT store launch, I then remember Anthropic and Claude emerged. And the consensus view for a while was, all of the value is going to go to one of these foundation model companies, and that the only way you can compete in AI is to raise huge amounts of money, either because you've got venture capital or you're Amazon or Facebook or Google with tons of cash already, but that if you weren't one of the big foundation models, there would be no value. And the applications built on top of these things would either be built by the foundation model companies themselves, or just not be that valuable. Again, something that turned out to be completely not true, right? And in particular, what drove that is open source, like the weird series of events where the weight's being leaked and like Meta just like rolling with it. The torrent. Yeah, right. That's going to force the hand for Meta to launch Llama, which was funny. And people thought, oh, it was just this cool open source model, but it was 18 months behind open AI. And people started doing a lot of derivative work out of it. It's like Vicu√±a and all these other animals related to llamas that came out. And it took the old llamas, one of the companies at YC as well, that enabled people to do local kind of Docker development, like models running on device. It was pretty cool, but people didn't think that they were going to be able to catch up. And the thing that changed from 2023 to 2024 is that during the summer, it was a turning point. It was the first time that the top foundation model in all the rankings benchmarks was Llama. And that was a shock to the community. Yeah, so it turns out choice matters. And choice means that it's not as much about the model. I think the model still matters quite a lot. But once you have choice in model, it means you can't have this sort of idea of monopoly pricing. And you have that model. Your competitor.
 also has that model. But all the other things seem to end up mattering a lot more, which is product, your ability to sell, your ability to actually adjust to user feedback, your ability to get to zero churn. All of those suddenly become far more important than capturing a light cone of all future value through the model. A very specific way I've felt this is I remember a year ago working with startups in the batch that were essentially building model routers, just like an API to call a specific model. And I remember a lot of the motivation for that at the time was reducing cost. It was like, oh, you don't want to just burn up all of your ChachiBT calls. You want to spread them out across various different models. And the argument against that was just, oh, the cost of all this stuff is going down to zero anyway. There's no value to be had in being a model router. And no one wants to build their applications with a model router. They're all just going to call whatever is the best model. I think fast forward a year, that's totally not true. From what I can tell, the model router was actually a really great entry point into just building a new stack for building LLM-powered apps. And most of the applications we're seeing, I think they just don't want to be beholden to a specific model. Does that map with what you've seen? Yeah, actually one of the things we've seen now in the fall batch that just presented at Demo Day, which was one of the trends that shifted from summer 24 and winter 24, was precisely what you're saying. Companies started to use multiple models for the applications. Like the best one for speed at some point, because sometimes you need to parse a lot of the input very quickly. It's fine if it's a bit more lossy. And then you need the bigger model to handle the more complex task. So a lot of companies in fall 24 have this actually multiple model architecture to use the best one for the best task, which is similar to the concept of the model router, but the idea evolved. Instead of being more of a routing, it was more of an orchestration. I think a concrete example we gave a couple episodes ago was Camphor. It was a company you work with. They use the fastest model for parsing PDFs. And the more complex ones, they use O1. And that's how it's done. And other companies are doing fraud detection. They have this concept of a junior risk analyst, where they just use a fast and easy GPT-4 mini. And then they use the bigger one with O1. Or the other example is, I think, Cursor talks about it in their episode with Lex Friedman. They also have this complex multi-architecture with multiple models. And this is why it works well, is like they do one very specific for predicting what you're going to take next, but one for understanding the whole code base. So very different tasks. So that's definitely happening now. Yeah, the other thing that popped up for Fallbatch, there's a company I'm working with called Variant. And what they're trying to do is take, basically, state-of-the-art open source LLM models that can do code gen, and then teach them aesthetics. So starting with icon generation. And so they built this huge post-training workflow that should work on as the open source models get smarter and better at code gen broadly. They can just take the next version of that, and then take their post-training architecture and data set, and then basically teach a given model aesthetics. So what a certain thing is supposed to look like. And not in a diffusion sort of way, but actually at the SVG level. And we think SVG will actually translate into all kinds of aesthetics. So it's an interesting approach. Unlike one of the newer ones, in that post-training is a whole coherent way to sort of skip the whole idea that all of the value is accruing into the model, especially because of open source, to your point. The other thing I've been having flashbacks to is a year ago, I remember many of the startups in the batch would get enterprise proof of concepts, or pilots in particular. And there was a lot of cynicism around whether any of those pilots would translate into real revenue. Lots of parallels to crypto, and how anytime there's some new interesting technology, blockchain more specifically than crypto, but anytime there's a new technology, enterprises always wanna run pilots and POCs because it's someone's job to check off, yeah, we did the hot new technology thing. The chief innovation officer must have his due. We've spoken about this one of our episodes, I think. And fast forward a year, I think we have all firsthand experience that these pilots have turned into real revenue. And if anything, the startups in the YC batch now are going to sell into real enterprises faster than they have before, and are ramping up revenue and reaching milestones like a million dollars ARR faster than ever.
 than I've certainly ever seen. Yeah, the fall batch just did this actually again, which is actually the first time I think we noticed it was actually the summer batch of this year. And one of the funnier things that we realized was, do you remember when Paul Graham would tell us how fast you needed to grow during the YC batch? 10% a week. 10% a week. And the wild thing is in aggregate across both, you know, summer and fall batches, that's what those batches did. Wow. So, which I don't think ever happened before. Which is 3X over the course of YC. Yeah, 3X over the course of YC, which I don't think has ever actually happened. On average. On average. It was only the best companies that did that, which is the top quartile or something, right? So, the companies are better. The general thing that is true is that the time it's taking to reach $100 million in annual revenue is trending down. Yeah, and not only that, we had dinner with Ben Horowitz recently, and remember he was saying when they started Andreessen Horowitz, the common understanding was that in any given year, there'd only be 15 companies that year that would even make it to $100 million a year revenue. And they said they ran the numbers the last 20 years, and every decade, the number of companies that could actually make it to $100 million went up by 10X. So, what was 15 per year maybe 20 years ago, I mean, we're talking about 1,500 companies a year that have a real shot at actually making that number. And when you combine that with what we're seeing in the summer and fall batches, it's not that surprising. And Jared had a really good argument on our last episode about how vertical AI is gonna enable this to have 1,500 plus companies to bloom. Yeah, that's why it's growing so fast. It's because the value prop to companies of these products is so incredibly strong that they're just flying off the shelves because companies are smart and they can do an ROI calculation. And when the ROI is fantastic, all these truisms that people believe about enterprise sales cycles and how to chase to get big enterprise deals go out the window because companies are smart and they'll make rational decisions. You know, Harj, there's another way that this broke in favor of startups that I was thinking about. It's hard to even remember now, but a year ago, one of the things that people said a lot was that these LLMs are not reliable enough to deploy in the enterprise. They hallucinate. Yeah, that was why a lot of people said like these pilots and POCs like won't translate into real contracts is because yeah, it's too risky of a technology for people to actually deploy. Yeah, and not only is it translating into real revenue, but it's translating into real deployments that are like being used at large scale, doing thousands of tickets a day. And I think it's because we've learned how to make the agents reliable via the kinds of techniques that Jake talked about when he was here. And just the, all this infrastructure has grown up around the models that's enabled people to make them reliable. That's actually a big trend. This year is this concept of thinking of AI more as agentic. That is a term that kind of bubbled up a lot this year. It was not in the bubble space of conversation last year. Last year was more about a lot of things that were kind of very chat-like. ChatGP, I mean, that was kind of the riff on it, but now it remixed into a bunch of agents for XYZ. And we just, I mean, you just put out, Gary just put out a great explainer video about computer use from Claude, but just the capability of the models keeps pushing in the direction of just being able to do like complex, multi-step things and actually take over your computer and call other applications and perform complex tasks that just didn't seem possible a year ago. What about regulations? Seems like we sort of dodged a bullet there with 1047, and it looks like some of the Biden EO is not that likely to survive the Trump White House. TBD, what that means in the longer term, but certainly one of the things that we were very worried about was that some certain amount of math beyond a certain level would suddenly become illegal or require registration at your local office. It's certainly been a weird time to be in tech because I've never experienced software and technology intersecting with politics so much. And in particular, I'm not used to genuinely caring about national politics affecting startups in a YC batch or just companies that are less than a year old. But it did really, it did really for a moment was worrying. It wasn't clear whether the startups would actually be able to build innovative AI applications versus suffering from regularity capture from open AI and a few big players. We're obviously very glad it broke in the favor of startups. Seems like we're still in the early game, right? I mean, it's very easy.
 to see that the platforms themselves really will or could possibly resemble, you know, the Win32 monopoly, right? Windows has access to the APIs. They, in fact, know all the stats about what's working on their platforms. And guess what? They can build it into their platform. You know, we sort of breathe a sigh of relief right now in 2024, but, you know, it's anyone's game, honestly. Like, these things are moving so quickly. I wouldn't totally breathe your last sigh of relief yet. You know, we gotta keep working on this. Okay, so it's clearly been a great year for startups. What else has been happening? Who else has it been a great year for, do we think? There's certainly been some big funding rounds, right? Like, OpenAI, unsurprisingly, has raised huge amounts of capital. Scale. Yeah, even within YC, though, we've seen, like, scale. AI has really broken out this year. Six billion dollars for OpenAI, one billion dollars for Scale, a billion dollars for SSI, the new Ilya Sutskever startup. Scale, I think, is just worth talking about because it's such a classic startup story. I mean, you were there in the early days, right? You interviewed them for YC. Tell us what the idea was that they interviewed with and how they ended up landing on what, you know, is probably one of the best startup ideas of the last 10 years. The fun thing about the scale.ai story is that it is the sort of epitome of the, like, classic YC startup story. And there's other kinds of startups that get started, you know, like SSI, for example. That's not a typical YC startup story where, like, some very well-established people raise a billion dollars with, like, a PowerPoint pitch. But, like, scale.ai is, like, the classic story of how, like, young programmers can just gradually build a, like, 10 billion dollar company over time by being, like, smarter and harder working than anybody else. And so, yeah, when Alex interviewed at YC, he wasn't working on anything related to AI. It was a completely different idea. And the idea for scale.ai kind of got pulled out of him by the market. And it's actually still, like, several pivots. Because, like, the original idea at YC didn't have anything to do with AI. And then for a long time, he was basically doing data labeling for the self-driving car companies. They applied, as I remember, they applied, like, a healthcare-related idea. Yeah, it was a website for booking doctor's appointments. Okay, yeah, cool. And then they pivoted during the batch. Do you remember how they came up with the data labeling idea? Because this must have been, was this 2016? Yeah, the way they came up with the data labeling idea was that Alex had worked at Quora, and Quora had to do some data labeling for, like, moderation and stuff. And so, at the time, the big data labeling service was Amazon Mechanical Turk. And they were deemed unbeatable because they were, like, run by Amazon, and Amazon could throw infinite money at it. And it was always at scale, it was at, like, quite large scale already. But Alex had a unique insight, which is he had actually used Mechanical Turk at Quora, and he knew that it kind of sucked to actually use it. And so he had this sort of, like, unique insight on the world, and so he just tried to build a better Mechanical Turk, basically the version he would have wanted when he was at Quora. And as I remember it, like, really, their early traction came almost entirely from one customer, Cruise, right? Cruise, yes, which needed to do tons of data labeling on all the images that the cars were taking as they were driving around San Francisco. You've got to, like, draw a circle around the traffic light and things like that. And the cool thing about scale is that they've actually caught two waves. So they, you know, accidentally caught the first wave of all these self-driving car companies. Because ML took off at that time in computer vision, there was just an unprecedented demand for labeled data for training sets that just hadn't existed before. And so they were able to ride that wave. And then as that wave was, like, cresting, LLMs got big, and all of these companies needed to do RLHF at very large scale. And scale was just, like, perfectly positioned to move into that business as well. Yeah, I think the scale story is just so interesting, because it was pre-LLM, it was clearly a multi-billion dollar business anyway. And LLM, it caught the LLM wave, which is now propelled into probably, it's going to be like a $100 billion plus company. And I'm seeing that at the ground level too, where many companies I had that maybe finished the batch, even pre the batch, didn't have an idea, pivoted into an AI idea that's taking off. Like, I'm just seeing much more success in founders who waited out and can find an idea that they just couldn't before. I have a company from a year ago, they pivoted the whole batch, they couldn't find a great idea. It actually took them six months after the batch until they realized one of their parents ran a dentist office. So he just decided to go hang out at the office to see if there was anything he could automate. And they just ended up building an AI back office for dentist offices. And now it's just like, their week over week growth is fantastic. It's doing really, really.
 Well, and I'm seeing lots of cases like that spring up. Definitely seeing that as well. I think there's something about the advantage of having all these very hardcore young technical founders that are willing to kind of just bet the farm and go all in on just a little bit of a glimmer of, oh, this is where the future is gonna be. Let me just try it. And then it actually ends up working. Like your story with the dentists, I have a lot of teams that pivoted as well into different spaces where they kind of found that glimmer. It's like, oh, computer use came out and I have a couple of companies that are working and betting and going in that direction. And it's like working well. I mean, it's still early. I mean, this is just a fall batch, but that's cool too. Okay, so what are some of the trends that we've seen or some of the specific trends and waves that startups have been riding coming out of the batches? Voice AI is something we've talked about. It's clearly maybe the most promising vertical for AI right now in terms of just raw traction. Do you think voice is a winner take all or will it be something that has sort of a hundred different verticals that are very tailored to those specific verticals? That's literally one of the questions I get from some of our voice AI startups themselves. They're like, should I be going horizontal or should I just continue to grow within my vertical? It feels to me like voice itself, voice is, I don't know, just like AI, it touches everything and there's so many different applications for it that you can, there's probably infinite applications to build where voice is the interesting element of it. I mean, things that just spring off the top of your head, like language learning applications. I'm sure there's not gonna be just one really cool voice AI powered language learning applications. It's probably gonna be multiple of them. Remote work, like teleconferencing, probably like a whole other area where there's interesting things to do with voice AI. And even within customer support, we highlighted a number of companies. We talked about last time, company PowerHelp, Kappa.ai. Yeah, it turns out that customer support is not really one vertical. There's like many different flavors of customer support and there's like very different on the inside once you get into the details. Because I think there's very specific types of workflows you need to do per industry. And that's to the point of why vertical AI agents are gonna really flourish. I mean, same thing for voice, it's just very different workflows. If you're building the, I don't know, the voice agent to do customer support for our airline, very different than doing it for a bank, very different than doing it for a B2B SaaS company, et cetera. Yeah, I guess that question of, is there going to be pure horizontal integration is sort of like saying, will there only be one website? Yeah. Or it'd be like saying, there's just gonna be both. There'll be horizontal infrastructure companies that do really well in vertical applications. To say otherwise would be like saying, oh, like Stripe powers payments on the internet and it's also just gonna have all the most valuable applications that accept payments on the internet. It's just not how it works. Like there's enough value at just being the horizontal infrastructure layer. So I'm sure there'll be great voice AI companies that just make it really easy for you to build your own voice AI application while there'll also be hundreds of really valuable vertical apps. What are the other trends that we've seen besides voice? We were talking about robotics earlier. There's certainly, we are certainly working with more founders building robots this year than I think any year. Ever. Ever. What's driving that? I have a ex Apple team that's called Weave Robotics that they're going to try to ship a real robot in 2025. It costs about 65, $70,000. But that's actually what it costs to have the actuators and the safety needed to actually have it work in your home. I think it's actually driven by this idea that the LLM itself can be sort of the consciousness of the robot. Like, am I doing this thing that my owner needs me to do? How do I actually interact with them and the other people in the household? But it's funny because then the voice language action model that might actually do a certain thing like fold laundry, that's almost tool use inside of the broader LLM consciousness. So I feel like that's one of the things that I'm excited to see, will it really work? And I think we're going to find out this year. I guess the way I think about it, robotics is basically half AI and half hardware. Half of the part of the equation is starting to work. Well, the hardware is still hard. The hardware is still very expensive. Yeah, there's some evidence that being able to actually do laundry, for instance, like that might be one of the first things that gets shipped. I think the dream case for startups is going to be that you can build just the AI or the software piece of it and run it on commodity hardware and do really great things. The opposite case would just be actually if the two things, like if you need to be good at the hardware and the software and they're like coupled together and you need to produce both and.
 you would expect Tesla to be the obvious winner in the space, and it remains to be seen. I'm pretty optimistic. We have multiple companies, I feel, that are trying to be creative on how to run the models on commodity hardware for specific use cases. It still feels early. It feels like the robotics hasn't quite hit its chat GPT moment yet. Maybe the moment is self-driving cars have been working in San Francisco. I don't think it's talked enough. People who don't live in San Francisco often don't realize the extent to which these are fully deployed in San Francisco, and regular people are riding them every single day. I saw Tony from DoorDash recently, and he said he exclusively uses Waymo everywhere. I live in Palo Alto, and I have no option for it, but I'd love to. It'd be amazing. I mean, the wild thing is there are only a few thousand of these deployed right now in the entire world. They're all in San Francisco. What about big flops for 2024? I seem to remember that we started one of our light cone episodes all wearing Apple Vision Pros and Quests, and we have not talked about AR since. Diana, what happened? It hasn't happened. There's this moment for a lot of the hardware that needs to be a lot more lightweight. We need to get to this form factor, but there's actually constraints with physics to fit all that hardware in such a small form factor. In order to have enough compute and the optics to fit, it's just super challenging. I think there's still more actual engineering and physics that needs to be discovered. That's it. I think the algorithms are there, but it's just lots of really hard hardware and optics problems. It's a tough chicken and egg problem because there's not enough hardware in people's hands for it to be worth it for app developers to build apps, and so there's not enough apps for people to want to buy the hardware. The killer application so far seems to be using it as a really large monitor. It does work very well for that. You've actually retained it as a user, Gary, right? Yeah, it's great for watching movies. Maybe the one device that I think actually has been playing and actually feels good is actually the Meta Ray Barn. It doesn't have any of the actual displays, but I really like it for the audio and voice. One workflow I've been trying out is actually using the Meta Ray Barn and connect it to any of the voice modes for either ChatGPT or Cloud and have a conversation with it about a topic. Oh, I haven't tried that. That's an interesting idea. Yeah, yeah. That's a great idea. That is a fun thing that I've been doing and just chatting with myself. Maybe look a little bit like a crazy person while you're walking, but it's been fun to learn about different topics. Should we talk about AI coding? Oh, yeah. 2024 was the year that AI coding really broke out. We had the majority of YC founders now use cursor or other AI IDEs. They just exploded over the summer. Devin proved that you could fully automate large programming tasks. Yeah, all that was this year. That was pretty wild. Red plate agents continue to improve. I hear more anecdotal stories of people building red plate apps on their way home from work. Yeah. I'm really impressed. Red plate took this technology and popularized it among non-technical people for the first time. That's really crazy. And an even more lower technical version is Anthropics Artifact, where you can actually prototype very simple apps and chat with Cloud to build really simple front pages. And then you could prototype stuff as a PM and show it to your engineering team. And it's like a full-fledged working version. Yeah, it's wild because it just means that one person can do so much more. And do you think it's going to change the nature of how startups are actually hiring? Are you seeing this yet? Some of the founders I've met who recently raised their seed rounds coming out of YC, they're not really approaching it how maybe the classic advice would teach them. In the past, you might say, let me try to hire more people. There are certain tasks that normally I have to find the person who did it at my competitor who did all of customer success. And I need to find that person who's under the person who runs that function. And I've got to hire that person and promote them. And they're going to come with all this knowledge and people networks. Some people are saying sort of the opposite, which is I'm going to get my software engineers to write more processes that use LLMs upfront. And I probably will end up needing to hire that person, but maybe after the series B or C and not right now.
 Yeah, I think I've seen that as well with companies after the batch, where they're looking for engineers that have more upside, and they're really fully native with a setup with an AI coding stack. And part of the, one of the clever interview tricks I've seen is people do pair programming and watch them use the tools, and you can really tell if someone really has tinkered with them. So there's actually an engineer cut that is not only good at coding, but also prompting and telling when the AI output is not correct. I think the part of reading and evaluating the output of all these AI coding agents is actually a lot more critical. Yeah, there's been an interesting controversy this past year about AI coding agents and programming interviews, because AI coding agents basically broke the standard programming interviews that companies have been doing for years. I'm curious what you think about this, since you ran a programming interview company. I guess the interesting debate is whether you should penalize or prevent people who are interviewing at your company from using Cursor or one of these tools to ace your programming interview, or whether you should just lean into it and adapt and test to see how productive they are. I generally think the way these things tend to err is more in that direction, that I think you'll just be measured on your absolute output and the bar will go up. I think Stripe, for example, were early on this about a decade or so ago, where they recognized that so much of what they needed their programmers to do was build web application and web software and not do hard CS problems. So the industry shifted away from the Google-style interview of lots of computer science problems and whiteboarding to just give someone a laptop and make them build a to-do app in four hours. So I think we'll just see the same thing happen, where the industry will just adjust and you'll just be interviewed using these tools and just be expected to do a lot more in a two-hour interview than you are today. To your point, Gary, around just the startups, like maybe how many people they need to hire or just how do they scale, it seems too early to see dramatic effects on that yet. But one thing that I'm interested in is, I saw an interview with Jeff Bezos recently, and he said that, well, one, he's back at Amazon working on AI, and two, that apparently Amazon itself has like a hundred, maybe it was a thousand, it was a surprisingly large number of internal LLM-powered applications, presumably to just run Amazon. The last time Amazon took something, it ran for internal infrastructure and released it to the world was AWS, which completely changed how startups are built. So I'm curious to see if they have interesting applications to run Amazon internally that they'll just release out and suddenly there'll be new stacks to just build and scale your companies on, and we'll see the whole, something that we've talked about in recent episodes of the 10-person, the one-person, unicorn. One of the applications that they talk about is they did this giant migration for an old version of programming languages, whenever you need to upgrade different versions of database or et cetera, it's like a lot of work. And they use LLMs for it. It was like changing hundreds of thousands of lines of code, and it would have taken an engineering project of six months or more. It was done in weeks. I mean, Amazon is just such a perfect use case for LLM-powered agents doing back office processes. They must have just an absolute goldmine of opportunities. And they just launched their big foundation model, actually, that is starting to be top in some of the benchmarks as well. So I think they're trying to be another contender through this race. That's interesting because from the bottom up, certainly from some of the people who still work at Amazon, maybe right out of college, many of them do not have access to LLMs or aren't actually barred from using it in their day-to-day. So maybe that's one of the downsides of organizations. When they get big enough, the future is already here, but it is not evenly distributed, even within the same organization. But that bodes sort of well for both open source and sort of self-hosting LLMs. I'm just on my to-do list to build my own stack of Apple minis and run Llama on my own little cluster on my desk. I bought all the hardware to build my own machine, but then we had a baby and it hasn't happened yet. But it will at some point. I've been pretty excited in that YC has been operating back in person in San Francisco for some time, but we got a real live demo day all the way back. So no more Zoom demo days, no more Zoom Alumni Demo Day. We did Alumni Demo Day right here in this room.
 the office right downstairs, that was awesome. And then we took over the Masonic Center and 1,200 investors all in one room. It was actually really great for the founders, I thought, because it was about a third as many founders than the summer batch, and it was more than 2X, maybe 3X the number of investors who had came to our investor reception party. So it was like a ratio of 10 investors for one company, roughly. So I think all of them had a really good time. I'd almost forgotten how great the energy of an in-person demo day is. It's just not something that you can replicate over Zoom. The YC demo days also always acted as the de facto investor reunion in Silicon Valley, because it's the one event that all the investors would reliably show up at. And so they were really excited that we had brought it back because when we weren't doing it, there was no equivalent event. Sort of the homecoming for Silicon Valley. Yeah, so now it's four times a year, and it's the one time that all the top early-stage investors in the world are gonna come back to San Francisco for hopefully that week's festivities culminating in our demo day. So it's a real celebration. It feels like in-person in general is back. That's certainly another theme of 2024. Certainly the late-stage startups that we've been meeting with and speaking to this year, one of the highest priority items has been figuring out how to get everyone back into person, back into the office. I think the era of it's gonna be remote forever is definitely gone. I certainly think- Good riddance. Yeah, exactly, right? And then find like, yeah, in-person is back, and then San Francisco is back. Like, a lot of thanks to you, Gary. The elections recently seem to have gone well. Like, there's a lot of optimism, I feel, around San Francisco. Yeah, we have a new mayor. We're hoping that he does the right things. And we have a very thin, moderate majority on the board of supervisors, but we did get rid of some of the worst people who created a doom loop in San Francisco. So I'm optimistic. We didn't get everything we wanted, but it's tracking in the right direction. And I think as in startups, as in politics, you always way overestimate what you will get done in one year, but you always way underestimate what's going to happen in 10 years. I think it's gonna take 10 years. It's gonna take 20 years. But just as startups went from 15 companies a year that could possibly make it to $100 million a year to 1,500 in any given year, knock on wood. I think San Francisco needs to be the beacon for all the smartest people in the world. And that's actually probably the thing that I'm most hopeful for, is that we can actually just keep building. So from all of us to all of you watching, happy holidays, and we'll see you in the new year.
