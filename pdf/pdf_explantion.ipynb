{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: anthropic in /Users/jeongmin/PycharmProjects/agents/.venv/lib/python3.12/site-packages (0.42.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/jeongmin/PycharmProjects/agents/.venv/lib/python3.12/site-packages (from anthropic) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/jeongmin/PycharmProjects/agents/.venv/lib/python3.12/site-packages (from anthropic) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/jeongmin/PycharmProjects/agents/.venv/lib/python3.12/site-packages (from anthropic) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/jeongmin/PycharmProjects/agents/.venv/lib/python3.12/site-packages (from anthropic) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/jeongmin/PycharmProjects/agents/.venv/lib/python3.12/site-packages (from anthropic) (2.9.2)\n",
      "Requirement already satisfied: sniffio in /Users/jeongmin/PycharmProjects/agents/.venv/lib/python3.12/site-packages (from anthropic) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in /Users/jeongmin/PycharmProjects/agents/.venv/lib/python3.12/site-packages (from anthropic) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/jeongmin/PycharmProjects/agents/.venv/lib/python3.12/site-packages (from anyio<5,>=3.5.0->anthropic) (3.10)\n",
      "Requirement already satisfied: certifi in /Users/jeongmin/PycharmProjects/agents/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->anthropic) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/jeongmin/PycharmProjects/agents/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->anthropic) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/jeongmin/PycharmProjects/agents/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/jeongmin/PycharmProjects/agents/.venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Users/jeongmin/PycharmProjects/agents/.venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->anthropic) (2.23.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: rich in /Users/jeongmin/PycharmProjects/agents/.venv/lib/python3.12/site-packages (13.9.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/jeongmin/PycharmProjects/agents/.venv/lib/python3.12/site-packages (from rich) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/jeongmin/PycharmProjects/agents/.venv/lib/python3.12/site-packages (from rich) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/jeongmin/PycharmProjects/agents/.venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: python-dotenv in /Users/jeongmin/PycharmProjects/agents/.venv/lib/python3.12/site-packages (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install anthropic\n",
    "%pip install rich\n",
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from typing import Dict, List\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "api_key = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "client = OpenAI(api_key=api_key, base_url=\"https://api.deepseek.com\")\n",
    "\n",
    "model_name = \"deepseek-reasoner\"\n",
    "# model_name = \"o1-preview-2024-09-12\"\n",
    "\n",
    "def get_completion(messages: List[Dict[str, str]]) -> str:\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=messages,\n",
    "        max_completion_tokens=25000, \n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello! I'm just a program, so I don't have feelings, but I'm here and ready to help with whatever you need. How can I assist you today?\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# api calling test \n",
    "\n",
    "get_completion([{\"role\": \"user\", \"content\": \"Hello, how are you?\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import Dict, List\n",
    "from pathlib import Path\n",
    "\n",
    "class MarkdownSectionParser:\n",
    "    def __init__(self):\n",
    "        self.section_pattern = r'^#+ .*$'  # '#'으로 시작하는 헤더 패턴\n",
    "        self.end_sections = {'ACKNOWLEDGEMENTS', 'REFERENCES', 'CONCLUSION', 'CONCLUSIONS'}\n",
    "        \n",
    "    def parse_sections(self, markdown_path: str) -> Dict[str, str]:\n",
    "        sections = {}\n",
    "        current_section = None\n",
    "        current_content = []\n",
    "        \n",
    "        with open(markdown_path, 'r', encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "            \n",
    "        for line in lines:\n",
    "            if re.match(self.section_pattern, line):\n",
    "                section_title = line.strip('# \\n')\n",
    "                \n",
    "                if current_section and current_content:\n",
    "                    sections[current_section] = ''.join(current_content).strip()\n",
    "                \n",
    "                # 대문자로 변환하여 비교\n",
    "                if any(end_sec in section_title.upper() for end_sec in self.end_sections):\n",
    "                    break\n",
    "                    \n",
    "                current_section = section_title\n",
    "                current_content = []\n",
    "            else:\n",
    "                if current_section is None and 'ABSTRACT' not in line.upper():\n",
    "                    continue\n",
    "                current_content.append(line)\n",
    "        \n",
    "        # 마지막 섹션 저장\n",
    "        if current_section and current_content:\n",
    "            sections[current_section] = ''.join(current_content).strip()\n",
    "        \n",
    "        # Abstract 필터링\n",
    "        filtered_sections = {}\n",
    "        include_section = False\n",
    "        \n",
    "        for section, content in sections.items():\n",
    "            if 'ABSTRACT' in section.upper():\n",
    "                include_section = True\n",
    "            \n",
    "            if include_section:\n",
    "                filtered_sections[section] = content\n",
    "                \n",
    "        return filtered_sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anthropic import Anthropic\n",
    "from typing import Dict, List\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "class PaperExplainer:\n",
    "    def __init__(self):\n",
    "        self.conversation_history = []\n",
    "        self.delay = 1  # API 호출 간 딜레이 (초)\n",
    "        \n",
    "    def _create_section_prompt(self, section_title: str, section_content: str, is_first: bool = False) -> str:\n",
    "        if is_first:\n",
    "            return f\"\"\"You are an expert academic paper explainer. Please explain the following section '{section_title}' \n",
    "            from an academic paper in a clear and concise manner. Please explain in Korean.\n",
    "\n",
    "            Section content:\n",
    "            {section_content}\"\"\"\n",
    "        else:\n",
    "            return f\"\"\"Please explain the following section '{section_title}'.\n",
    "            \n",
    "            Section content:\n",
    "            {section_content}\"\"\"\n",
    "    \n",
    "    def explain_section(self, section_title: str, section_content: str) -> str:\n",
    "        try:\n",
    "            # Create prompt based on whether this is the first section\n",
    "            is_first = len(self.conversation_history) == 0\n",
    "            prompt = self._create_section_prompt(section_title, section_content, is_first)\n",
    "            \n",
    "            # Add previous conversation for context\n",
    "            self.conversation_history.append({\"role\": \"user\", \"content\": prompt})\n",
    "            \n",
    "            response = get_completion(self.conversation_history)\n",
    "            \n",
    "            # Update conversation history\n",
    "            self.conversation_history.append({\"role\": \"assistant\", \"content\": response})            \n",
    "            # API 호출 간 딜레이\n",
    "            time.sleep(self.delay)\n",
    "            \n",
    "            return response\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error explaining section {section_title}: {str(e)}\")\n",
    "            return f\"Error: Failed to explain section {section_title}\"\n",
    "\n",
    "    def explain_paper(self, sections: Dict[str, str]) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        논문의 각 섹션을 순차적으로 설명\n",
    "        \n",
    "        Args:\n",
    "            sections: 섹션 제목과 내용을 매핑한 딕셔너리\n",
    "            \n",
    "        Returns:\n",
    "            섹션 제목과 설명을 매핑한 딕셔너리\n",
    "        \"\"\"\n",
    "        explanations = {}\n",
    "        \n",
    "        print(\"\\nProcessing sections:\")\n",
    "        for title, content in tqdm(sections.items(), desc=\"Explaining sections\"):\n",
    "            print(f\"\\nProcessing: {title}\")\n",
    "            explanation = self.explain_section(title, content)\n",
    "            explanations[title] = explanation\n",
    "            \n",
    "        return explanations\n",
    "    \n",
    "    def get_conversation_history(self):\n",
    "        return self.conversation_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Optional, List\n",
    "\n",
    "class PaperQA:\n",
    "    def __init__(self, context: Optional[List[Dict[str, str]]] = None):\n",
    "        self.conversation_history = context or []\n",
    "        self.delay = 1\n",
    "        \n",
    "    def load_paper_context(self, explanations: Dict[str, str]):\n",
    "        \"\"\"논문 설명을 대화 기록에 로드\"\"\"\n",
    "        context = \"Here's the paper summary:\\n\\n\"\n",
    "        for section, explanation in explanations.items():\n",
    "            context += f\"## {section}\\n{explanation}\\n\\n\"\n",
    "            \n",
    "        # 논문 컨텍스트를 대화 기록에 추가\n",
    "        self.conversation_history.append({\"role\": \"user\", \"content\": context})\n",
    "\n",
    "    def ask_question(self, question: str) -> str:\n",
    "        \"\"\"논문에 대한 질문에 답변\"\"\"\n",
    "        try:\n",
    "            # 질문 프롬프트 생성\n",
    "            prompt = f\"\"\"Based on the paper we discussed, please answer the following question in Korean. \n",
    "            Be specific and cite relevant sections when possible.\n",
    "\n",
    "            Question: {question}\"\"\"\n",
    "            \n",
    "            # 이전 대화 기록과 함께 질문 전송\n",
    "            self.conversation_history.append({\"role\": \"user\", \"content\": prompt})\n",
    "            \n",
    "            # Claude에 질문\n",
    "            response = get_completion(self.conversation_history)\n",
    "            \n",
    "            # 대화 기록 업데이트\n",
    "            self.conversation_history.append({\"role\": \"assistant\", \"content\": response})\n",
    "            \n",
    "            time.sleep(self.delay)\n",
    "            return response\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing question: {str(e)}\")\n",
    "            return f\"Error: Failed to process question\"\n",
    "    \n",
    "    def view_conversation_history(self, start_idx: int = 0, end_idx: Optional[int] = None) -> None:\n",
    "        \"\"\"대화 내역을 출력하는 함수\n",
    "        \n",
    "        Args:\n",
    "            start_idx: 시작 인덱스 (기본값: 0)\n",
    "            end_idx: 종료 인덱스 (기본값: None, None일 경우 끝까지 출력)\n",
    "        \"\"\"\n",
    "        # 논문 컨텍스트는 제외하고 실제 대화만 출력\n",
    "        conversations = [\n",
    "            msg for msg in self.conversation_history \n",
    "            if not msg[\"content\"].startswith(\"Here's the paper summary:\")\n",
    "        ]\n",
    "        \n",
    "        # end_idx가 None이면 리스트 끝까지\n",
    "        end_idx = end_idx if end_idx is not None else len(conversations)\n",
    "        \n",
    "        print(\"\\n=== 대화 내역 ===\\n\")\n",
    "        for i, msg in enumerate(conversations[start_idx:end_idx], start=start_idx):\n",
    "            role = msg[\"role\"].upper()\n",
    "            if role == \"ASSISTANT\":\n",
    "                print(f\"\\n🤖 Assistant ({i}):\\n{msg['content']}\\n\")\n",
    "                print(\"-\" * 80)\n",
    "            elif role == \"USER\":\n",
    "                print(f\"\\n👤 User ({i}):\\n{msg['content']}\\n\")\n",
    "                print(\"-\" * 80)\n",
    "    \n",
    "    \n",
    "    def get_last_n_conversations(self, n: int = 1) -> None:\n",
    "        \"\"\"최근 n개의 대화 내역을 출력\n",
    "        \n",
    "        Args:\n",
    "            n: 출력할 최근 대화 개수 (기본값: 1)\n",
    "        \"\"\"\n",
    "        conversations = [\n",
    "            msg for msg in self.conversation_history \n",
    "            if not msg[\"content\"].startswith(\"Here's the paper summary:\")\n",
    "        ]\n",
    "        start_idx = max(0, len(conversations) - n)\n",
    "        self.view_conversation_history(start_idx)\n",
    "        \n",
    "    def get_conversation_history(self):\n",
    "        return self.conversation_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import json\n",
    "\n",
    "def process_paper(markdown_path: str) -> Tuple[Dict[str, str], PaperQA]:\n",
    "    \"\"\"\n",
    "    전체 논문 처리 프로세스\n",
    "    \"\"\"\n",
    "    # 1. Markdown 파싱\n",
    "    parser = MarkdownSectionParser()\n",
    "    sections = parser.parse_sections(markdown_path)\n",
    "    \n",
    "    # 2. 섹션별 설명 생성\n",
    "    explainer = PaperExplainer()\n",
    "    explanations = explainer.explain_paper(sections)\n",
    "\n",
    "    # 3. 대화 기록 파일에 저장 \n",
    "    conversation_history = explainer.get_conversation_history()\n",
    "    with open(f\"data/explanation_data_by_{model_name}.jsonl\", \"a\") as f:\n",
    "        data = json.dumps({\"messages\": conversation_history}, ensure_ascii=False)\n",
    "        f.write(data + \"\\n\")\n",
    "    \n",
    "    # 4. 질문 답변 준비 \n",
    "    qa = PaperQA(context=conversation_history)\n",
    "    \n",
    "    return explanations, qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing sections:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explaining sections:   0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: ABSTRACT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explaining sections:   9%|▉         | 1/11 [00:17<02:58, 17.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: 1 INTRODUCTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explaining sections:  18%|█▊        | 2/11 [00:51<04:02, 27.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: 2 WHAT MAKES GOOD DATA FOR ALIGNMENT?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explaining sections:  27%|██▋       | 3/11 [01:20<03:44, 28.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: 2.1 THE DATA SELECTION PROBLEM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explaining sections:  36%|███▋      | 4/11 [01:48<03:15, 27.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: 2.2 EXPERIMENTAL SETUP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explaining sections:  45%|████▌     | 5/11 [02:16<02:47, 27.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: 2.4 FROM THE QUALITY PERSPECTIVE – EVOL QUALITY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explaining sections:  55%|█████▍    | 6/11 [02:49<02:28, 29.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: 3 DEITA– DATA EFFICIENT INSTRUCTION TUNING FOR ALIGNMENT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explaining sections:  64%|██████▎   | 7/11 [03:23<02:04, 31.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: 3.1 METHOD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explaining sections:  73%|███████▎  | 8/11 [03:45<01:24, 28.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: Algorithm 1 Score-First, Diversity-Aware Data Selection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explaining sections:  82%|████████▏ | 9/11 [04:15<00:57, 28.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: 3.2 EXPERIMENTAL SETUP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explaining sections:  91%|█████████ | 10/11 [04:39<00:27, 27.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: 3.3 RESULTS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explaining sections: 100%|██████████| 11/11 [05:15<00:00, 28.70s/it]\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "markdown_path = \"input_file/WHAT MAKES GOOD DATA FOR ALIGNMENT? A COMPREHENSIVE STUDY OF AUTOMATIC DATA SELECTION IN INSTRUCTION TUNING.md\"\n",
    "output_dir = \"output_file\"\n",
    "\n",
    "explanations, qa = process_paper(markdown_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Explanations saved to: output_file/WHAT MAKES GOOD DATA FOR ALIGNMENT? A COMPREHENSIVE STUDY OF AUTOMATIC DATA SELECTION IN INSTRUCTION TUNING_explained.md\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"output_file\"\n",
    "\n",
    "input_filename = Path(markdown_path).stem  # 파일 이름만 추출 (확장자 제외)\n",
    "output_path = os.path.join(output_dir, f\"{input_filename}_explained.md\")\n",
    "\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    for section, explanation in explanations.items():\n",
    "        f.write(f\"\\n## {section}\\n\\n\")\n",
    "        f.write(explanation)\n",
    "        f.write(\"\\n\\n---\\n\")\n",
    "\n",
    "print(f\"\\nExplanations saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "                                                     <span style=\"font-weight: bold; text-decoration: underline\">ABSTRACT</span>                                                      \n",
       "\n",
       "<span style=\"font-weight: bold\">요약 설명:</span>                                                                                                         \n",
       "이 논문은 대규모 언어 모델을 특정 작업과 사용자 선호에 맞추기 위한 핵심 기술인 **지시 튜닝(Instruction Tuning)**의 \n",
       "데이터 선택 전략을 탐구합니다. 기존 연구는 적절한 데이터 선택이 적은 양으로도 우수한 성능을 낼 수 있음을 보였지만, \n",
       "\"좋은 데이터\"의 기준과 자동 선택 방법은 명확히 규명되지 않았습니다.                                                \n",
       "\n",
       "<span style=\"font-weight: bold\">핵심 내용:</span>                                                                                                         \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 1 </span><span style=\"font-weight: bold\">데이터 측정 3가지 차원</span>:                                                                                         \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">복잡성(Complexity)</span>: 데이터의 난이도와 정보 밀도                                                              \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">품질(Quality)</span>: 정확성과 유용성                                                                               \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">다양성(Diversity)</span>: 주제와 형식의 다양성                                                                      \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">      </span>기존 방법을 분석하고, 이를 개선한 새로운 측정 기법을 제안합니다.                                             \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 2 </span><span style=\"font-weight: bold\">DEITA (Data-Efficient Instruction Tuning for Alignment)</span>:                                                        \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>LLaMA와 Mistral 모델을 기반으로, <span style=\"font-weight: bold\">자동 선택된 6,000개의 SFT 데이터</span>만으로 미세 조정한 모델 시리즈입니다.       \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>기존 오픈소스 모델 대비 <span style=\"font-weight: bold\">10배 이상 적은 데이터</span>로 동등하거나 더 나은 성능을 달성했습니다.                      \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>DPO(Direct Preference Optimization) 추가 학습 시 <span style=\"font-weight: bold\">MT-Bench 7.55점</span>, **AlpacaEval 90.06%**의 우수한 결과를      \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">      </span>보였습니다.                                                                                                  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 3 </span><span style=\"font-weight: bold\">의의</span>:                                                                                                           \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>데이터 선택의 과학적 접근법과 효율적인 정렬 도구를 제시하여, <span style=\"font-weight: bold\">적은 데이터로 고성능 모델을 구축</span>하는 방법을     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">      </span>개척했습니다.                                                                                                \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>선택된 데이터셋과 모델을 공개해 향후 연구에 기여할 것으로 기대됩니다.                                        \n",
       "\n",
       "<span style=\"font-weight: bold\">결론</span>: 이 연구는 데이터 품질과 선택 전략이 모델 성능에 미치는 영향을 체계화하고, 효율적인 모델 정렬을 위한 실용적인 \n",
       "프레임워크를 제시했습니다.                                                                                         \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "\n",
       "                                                  <span style=\"font-weight: bold; text-decoration: underline\">1 INTRODUCTION</span>                                                   \n",
       "\n",
       "<span style=\"font-weight: bold\">1. 서론 (INTRODUCTION) 설명:</span>                                                                                       \n",
       "\n",
       "이 섹션은 대규모 언어 모델(LLM)을 인간의 선호도에 맞추는 <span style=\"font-weight: bold\">정렬(Alignment)</span> 과정의 중요성과 방법론, 특히 <span style=\"font-weight: bold\">데이터 </span>      \n",
       "<span style=\"font-weight: bold\">효율성</span>을 높이기 위한 접근법을 다룹니다. 핵심 내용은 다음과 같습니다:                                               \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                                 <span style=\"font-weight: bold\">배경 및 문제 제기</span>                                                 \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 1 </span><span style=\"font-weight: bold\">LLM 정렬의 필요성</span>                                                                                               \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>LLM이 인간의 지시를 정확히 이해하고 유용한 응답을 생성하려면 <span style=\"font-weight: bold\">인간 선호도와의 정렬</span>이 필수적입니다.            \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>주요 정렬 기법으로는 **지시 튜닝(Instruction Tuning/SFT)**과 **인간 피드백 강화학습(RLHF)**이 사용됩니다.    \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">       • </span><span style=\"font-weight: bold\">지시 튜닝</span>: 사전 학습된 모델을 주석이 달린 지시 데이터로 미세 조정합니다.                                  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">       • </span><span style=\"font-weight: bold\">RLHF</span>: 모델의 응답에 대한 인간 피드백을 바탕으로 강화학습을 적용합니다.                                    \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>최근 연구는 지시 튜닝만으로도 RLHF 수준의 성능을 달성할 수 있음을 보였습니다.                                \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 2 </span><span style=\"font-weight: bold\">데이터 효율성의 중요성</span>                                                                                          \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>기존 과제별 미세 조정은 대량의 데이터가 필요했지만, <span style=\"font-weight: bold\">지시 튜닝은 모델의 사전 학습된 지식을 적은 데이터로 </span>     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">      </span><span style=\"font-weight: bold\">조정</span>합니다.                                                                                                  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>1,000개 수준의 고품질 데이터만으로도 효과적인 정렬이 가능하다는 연구 결과가 있습니다.                        \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">문제점</span>: 현재 데이터 선택은 경험적 자동화(예: ChatGPT에서 추출)나 수작업에 의존하며, 체계적인 기준이          \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">      </span>부족합니다.                                                                                                  \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                         <span style=\"font-weight: bold\">해결 방안: 데이터 측정 3가지 차원</span>                                         \n",
       "\n",
       "연구진은 \"좋은 데이터\"를 정의하기 위해 다음 세 가지 측면을 제시합니다:                                             \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 1 </span><span style=\"font-weight: bold\">복잡성(Complexity)</span>: 데이터의 난이도와 정보 밀도                                                                 \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 2 </span><span style=\"font-weight: bold\">품질(Quality)</span>: 응답의 정확성과 유용성                                                                           \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 3 </span><span style=\"font-weight: bold\">다양성(Diversity)</span>: 주제와 형식의 다양성                                                                         \n",
       "\n",
       "<span style=\"font-weight: bold\">측정 방법</span>                                                                                                          \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">EVOL COMPLEXITY/QUALITY</span>:                                                                                        \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>단일 데이터 포인트를 변형해 복잡성/품질이 다른 예시를 생성합니다.                                            \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>ChatGPT로 변형된 예시를 순위 매기고 점수화한 후, 이를 학습해 <span style=\"font-weight: bold\">자동 점수 판별기</span>를 개발합니다.                  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">다양성 측정</span>: 모델 임베딩 간 거리를 계산해 데이터의 다양성을 평가합니다.                                         \n",
       "\n",
       "이를 바탕으로 대량 데이터 풀에서 <span style=\"font-weight: bold\">효율적인 데이터 샘플을 자동 선별</span>하는 전략을 수립합니다(그림 1 참조).              \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                                 <span style=\"font-weight: bold\">DEITA 모델과 성과</span>                                                 \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">DEITA (Data-Efficient Instruction Tuning for Alignment)</span>:                                                        \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>LLaMA와 Mistral 모델을 기반으로, <span style=\"font-weight: bold\">자동 선별된 6,000개 SFT 데이터</span>로 미세 조정된 모델군입니다.                  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">주요 성과</span>:                                                                                                   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">       • </span>기존 모델(Zephyr, Vicuna 등) 대비 <span style=\"font-weight: bold\">10배 이상 적은 데이터</span>로 동등/우수한 성능 달성.                          \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">       • </span>DEITA-Mistral-7B: 6K SFT 데이터로 MT-bench 7.22점, AlpacaEval 80.78%.                                     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">       • </span>DPO(Direct Preference Optimization) 추가 시 <span style=\"font-weight: bold\">MT-bench 7.55점, AlpacaEval 90.06%</span> 기록.                      \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>데이터셋과 모델을 공개해 향후 연구에 기여합니다.                                                             \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                                       <span style=\"font-weight: bold\">의의</span>                                                        \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>데이터 선택의 과학적 기준을 제시하고, <span style=\"font-weight: bold\">적은 데이터로 고성능 모델 정렬</span>을 가능하게 함.                             \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>자동화된 데이터 선별 프레임워크를 통해 LLM 개발의 리소스 효율성을 개선.                                         \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "\n",
       "                                       <span style=\"font-weight: bold; text-decoration: underline\">2 WHAT MAKES GOOD DATA FOR ALIGNMENT?</span>                                       \n",
       "\n",
       "<span style=\"font-weight: bold\">2. \"정렬을 위한 좋은 데이터의 조건은 무엇인가?\" 섹션 설명</span>                                                          \n",
       "이 섹션에서는 **지시 튜닝(Instruction Tuning)**에 효과적인 데이터의 특성을 체계적으로 분석합니다. 연구진은 \"좋은   \n",
       "데이터\"의 기준을 규명하기 위해 다음 단계로 접근합니다:                                                             \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                            <span style=\"font-weight: bold\">2.1 데이터 선택 문제의 정의</span>                                            \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">핵심 질문</span>:                                                                                                      \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>\"적은 양의 데이터로도 대규모 언어 모델(LLM)을 인간의 의도에 효과적으로 정렬하려면, 어떤 데이터를 선택해야       \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>하는가?\"                                                                                                        \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">문제 배경</span>:                                                                                                      \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>기존 연구는 데이터 품질과 양의 균형이 모델 성능에 미치는 영향에 대한 명확한 기준이 부족했습니다.                \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-style: italic\">예시</span>: 수작업 선별이나 ChatGPT 추출과 같은 경험적 방법은 과학적 근거가 미흡합니다.                            \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                                   <span style=\"font-weight: bold\">2.2 실험 설계</span>                                                   \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">목표</span>:                                                                                                           \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>데이터의 <span style=\"font-weight: bold\">복잡성(Complexity)</span>, <span style=\"font-weight: bold\">품질(Quality)</span>, **다양성(Diversity)**이 모델 정렬에 미치는 영향을 정량적으로        \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>평가합니다.                                                                                                     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">방법</span>:                                                                                                           \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    1 </span>다양한 데이터 측정 지표(기존 방법 + 새로운 기법)를 도입합니다.                                               \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    2 </span>각 지표와 모델 성능 간의 상관관계를 분석합니다.                                                              \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    3 </span>실제 지시 튜닝 실험을 통해 이론적 가설을 검증합니다.                                                         \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                           <span style=\"font-weight: bold\">2.3-2.5 데이터 측정 지표 탐구</span>                                           \n",
       "\n",
       "                                                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">1. 복잡성(§2.3)</span>                                                  \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">정의</span>: 데이터의 <span style=\"font-weight: bold\">난이도</span>와 <span style=\"font-weight: bold\">정보 밀도</span>                                                                               \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">측정 방법</span>:                                                                                                      \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">EVOL COMPLEXITY</span>: 단일 데이터를 변형해 복잡성 수준이 다른 예시 생성 → ChatGPT로 순위 매기기 → 복잡성 점수     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">      </span>판별기 학습.                                                                                                 \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-style: italic\">예시</span>: \"고양이 설명\" (단순) vs. \"양자역학의 기본 원리 설명\" (복잡).                                           \n",
       "\n",
       "                                                   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">2. 품질(§2.4)</span>                                                   \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">정의</span>: 응답의 <span style=\"font-weight: bold\">정확성</span>과 <span style=\"font-weight: bold\">유용성</span>                                                                                    \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">측정 방법</span>:                                                                                                      \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">EVOL QUALITY</span>: 데이터 품질을 인위적으로 조절한 변형 예시 생성 → ChatGPT로 품질 순위 평가 → 품질 점수 판별기   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">      </span>개발.                                                                                                        \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-style: italic\">예시</span>: 명확한 답변 (고품질) vs. 모호하거나 오류 있는 답변 (저품질).                                           \n",
       "\n",
       "                                                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">3. 다양성(§2.5)</span>                                                  \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">정의</span>: 데이터의 <span style=\"font-weight: bold\">주제</span>와 <span style=\"font-weight: bold\">형식</span>적 다양성                                                                             \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">측정 방법</span>:                                                                                                      \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>모델 임베딩(Embedding) 간 <span style=\"font-weight: bold\">코사인 유사도</span> 계산 → 유사도가 낮을수록 다양성이 높음.                              \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-style: italic\">예시</span>: 다양한 분야(과학, 문학, 역사)와 질문 유형(설명, 요약, 추론)을 포함하는 데이터.                         \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                                       <span style=\"font-weight: bold\">의의</span>                                                        \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">3가지 차원의 측정 지표</span>를 통해 데이터 선택의 과학적 근거 마련.                                                   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">EVOL 기법</span>을 통해 복잡성/품질을 자동으로 평가하는 방법 제시.                                                     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>후속 실험(§3)에서 이 지표들을 활용해 <span style=\"font-weight: bold\">고효율 데이터 선택 전략</span>을 수립함으로써, 적은 데이터로도 우수한 모델 성능을 \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>입증합니다.                                                                                                     \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "\n",
       "                                          <span style=\"font-weight: bold; text-decoration: underline\">2.1 THE DATA SELECTION PROBLEM</span>                                           \n",
       "\n",
       "<span style=\"font-weight: bold\">2.1 데이터 선택 문제 (THE DATA SELECTION PROBLEM) 설명</span>                                                             \n",
       "이 섹션은 **지시 튜닝(Instruction Tuning)**을 위한 최적의 데이터를 선별하는 문제를 체계적으로 정의하고, 이를       \n",
       "해결하기 위한 프레임워크를 제시합니다. 핵심 개념은 다음과 같습니다:                                                \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                                     <span style=\"font-weight: bold\">문제 정의</span>                                                     \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">목표</span>: 대규모 데이터 풀에서 **제한된 데이터 예산(Data Budget, <span style=\"font-style: italic\">m</span>)**으로 최고의 정렬 성능(<span style=\"font-style: italic\">Q</span>)을 달성하는 데이터     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>부분집합(<span style=\"font-style: italic\">S_π^(m)</span>)을 선택하는 것.                                                                                \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">데이터 풀 구성</span>:                                                                                                 \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-style: italic\">X = {x₁, x₂, ..., xₙ}</span>: 지시-응답 쌍(instruction-response pair)으로 이루어진 대규모 데이터 집합.              \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>각 <span style=\"font-style: italic\">xᵢ</span>는 하나의 데이터 샘플을 의미합니다.                                                                     \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                               <span style=\"font-weight: bold\">선택 전략(π)과 최적화</span>                                               \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">선택 전략(π)</span>: 데이터 품질을 평가하는 **측정 지표(metric)**를 기반으로 데이터를 선별하는 방법.                   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-style: italic\">최적 전략(π)</span>*: 주어진 데이터 예산 <span style=\"font-style: italic\">m</span>으로 최대 정렬 성능 <span style=\"font-style: italic\">Q</span>를 달성하는 전략.                                       \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>수식:                                                                                                        \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">      </span>$$                                                                                                           \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">      </span>\\pi^{*} = \\arg\\max_{\\pi} Q(S_{\\pi}^{(m)})                                                                    \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">      </span>$$                                                                                                           \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-style: italic\">해석</span>: 가능한 모든 전략(π) 중에서 <span style=\"font-style: italic\">m</span>개의 데이터로 학습했을 때 가장 높은 성능(<span style=\"font-style: italic\">Q</span>)을 내는 전략을 선택합니다.      \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                                     <span style=\"font-weight: bold\">핵심 개념</span>                                                     \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 1 </span><span style=\"font-weight: bold\">데이터 예산(Data Budget, </span><span style=\"font-weight: bold; font-style: italic\">m</span><span style=\"font-weight: bold\">)</span>:                                                                                    \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>사용할 데이터 샘플 수. 모델 학습에 소요되는 계산 자원과 비례합니다.                                          \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-style: italic\">예시</span>: 6,000개의 데이터만으로도 우수한 성능을 내는 것이 목표일 때, <span style=\"font-style: italic\">m=6,000</span>.                                   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 2 </span><span style=\"font-weight: bold\">정렬 성능(</span><span style=\"font-weight: bold; font-style: italic\">Q</span><span style=\"font-weight: bold\">)</span>:                                                                                                   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>지시 튜닝 후 모델이 보이는 성능 지표(예: MT-Bench, AlpacaEval 점수).                                         \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 3 </span><span style=\"font-weight: bold\">측정 지표의 역할</span>:                                                                                               \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>데이터 샘플의 <span style=\"font-weight: bold\">복잡성, 품질, 다양성</span> 등을 정량화하여, 어떤 데이터가 <span style=\"font-style: italic\">Q</span>를 높이는지 판단하는 기준으로 사용됩니다. \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                                    <span style=\"font-weight: bold\">연구의 방향</span>                                                    \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>이론적 프레임워크를 바탕으로, 다양한 측정 지표와 선택 전략을 실험적으로 탐구합니다.                             \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-style: italic\">예시 실험 과정</span>:                                                                                              \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">       1 </span>특정 지표(예: 복잡성 점수)로 데이터를 정렬합니다.                                                         \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">       2 </span>상위 <span style=\"font-style: italic\">m</span>개 데이터를 선택해 지시 튜닝을 수행합니다.                                                          \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">       3 </span>결과 성능(<span style=\"font-style: italic\">Q</span>)을 비교하여 해당 지표의 유효성을 검증합니다.                                                  \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                                       <span style=\"font-weight: bold\">의의</span>                                                        \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>데이터 선택 문제를 <span style=\"font-weight: bold\">수학적 최적화 문제</span>로 명확히 정의함으로써,                                                    \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>체계적인 데이터 선별 전략 수립의 기반을 마련했습니다.                                                        \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>후속 섹션(§2.3-2.5)에서 제안된 복잡성, 품질, 다양성 지표가 <span style=\"font-style: italic\">Q</span>와 어떻게 연관되는지 분석할 수 있는 토대를       \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">      </span>제공합니다.                                                                                                  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>이 프레임워크는 <span style=\"font-weight: bold\">DEITA</span> 모델 개발 시 데이터 효율성을 극대화하는 데 직접적으로 활용됩니다.                         \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "\n",
       "                                              <span style=\"font-weight: bold; text-decoration: underline\">2.2 EXPERIMENTAL SETUP</span>                                               \n",
       "\n",
       "<span style=\"font-weight: bold\">2.2 실험 설계 (EXPERIMENTAL SETUP) 설명</span>                                                                            \n",
       "이 섹션에서는 데이터 측정 지표의 효과를 검증하기 위한 <span style=\"font-weight: bold\">체계적인 실험 절차</span>를 소개합니다. 핵심은 <span style=\"font-weight: bold\">3단계 프레임워크</span>를   \n",
       "통해 각 지표의 유효성을 평가하는 것입니다:                                                                         \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                                  <span style=\"font-weight: bold\">실험 프레임워크</span>                                                  \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 1 </span><span style=\"font-weight: bold\">데이터 선별</span>: 특정 측정 지표(예: 복잡성)를 기반으로 데이터 풀에서 <span style=\"font-style: italic\">m=6,000개</span> 샘플을 선택합니다.                   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 2 </span><span style=\"font-weight: bold\">모델 미세 조정</span>: 선별된 데이터로 LLaMA-1 13B 모델을 지시 튜닝합니다.                                             \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 3 </span><span style=\"font-weight: bold\">성능 평가</span>: MT-Bench 점수를 통해 모델의 <span style=\"font-weight: bold\">지시 수행 능력</span>을 측정합니다.                                             \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                                  <span style=\"font-weight: bold\">데이터 풀 구성</span>                                                   \n",
       "\n",
       "두 가지 유형의 데이터 풀을 구축해 다양한 실제 시나리오를 모의합니다:                                               \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 1 </span><span style=\"font-weight: bold\">X_sota (고품질 데이터 풀)</span>                                                                                       \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">목적</span>: 이미 우수한 데이터 풀에서 <span style=\"font-weight: bold\">효율성 극대화</span> 가능성 탐구.                                                   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">구성</span>: WizardLM, UltraChat 등 SOTA 모델의 학습 데이터를 통합 (총 300K 샘플).                                  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">특징</span>: 복잡성, 다양성, 품질이 모두 높음.                                                                      \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 2 </span><span style=\"font-weight: bold\">X_base (저품질 데이터 풀)</span>                                                                                       \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">목적</span>: 실제 환경에서 흔히 접하는 <span style=\"font-weight: bold\">저품질/중복 데이터</span> 대응 전략 검증.                                           \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">구성</span>: Alpaca, Dolly 등 기본 데이터셋 통합 (총 100K 샘플).                                                    \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">특징</span>: 응답 길이 짧고, 주제/형식 다양성 낮음.                                                                 \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                                 <span style=\"font-weight: bold\">학습 및 평가 설정</span>                                                 \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">모델</span>: LLaMA-1 13B (고정된 하이퍼파라미터 사용, 부록 A 참조).                                                    \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">데이터 예산</span>: <span style=\"font-style: italic\">m=6,000</span> 샘플.                                                                                      \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">평가 지표</span>: <span style=\"font-weight: bold\">MT-Bench</span> (다중 회차 대화 평가, GPT-4가 응답 점수화).                                                 \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                            <span style=\"font-weight: bold\">복잡성 측정 지표 비교 결과</span>                                             \n",
       "\n",
       "표 2는 다양한 복잡성 지표로 선별된 데이터로 학습한 모델의 MT-Bench 점수를 보여줍니다.                              \n",
       "\n",
       "                                                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">주요 결과</span>                                                     \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 1 </span><span style=\"font-weight: bold\">EVOL COMPLEXITY의 우수성</span>:                                                                                       \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>X_sota: <span style=\"font-weight: bold\">6.27점</span> (최고 성능).                                                                                  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>X_base: <span style=\"font-weight: bold\">5.57점</span> (기존 방법 대비 큰 격차).                                                                     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">강점</span>: 데이터 품질에 관계없이 <span style=\"font-weight: bold\">강건한 성능</span> 발휘.                                                               \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 2 </span><span style=\"font-weight: bold\">기존 방법의 한계</span>                                                                                                \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">Instruction Length (지시 길이)</span>: 긴 지시문 ≠ 고복잡성 (X_base 4.00점).                                        \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">Perplexity (응답 혼란도)</span>: 낮은 성능 (X_sota 4.06점) → 짧은 응답 샘플 선별 경향성 문제.                       \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">Direct Scoring/Instruction Node</span>: ChatGPT 주석 비용高 → 50K 샘플 제한 시 성능 하락.                           \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 3 </span><span style=\"font-weight: bold\">EVOL COMPLEXITY의 혁신성</span>                                                                                        \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">진화 기반 평가</span>: 단일 데이터를 점진적 복잡성 변형 → ChatGPT로 세밀한 점수화.                                  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">자동 점수 판별기</span>: 소량 시드 데이터 학습 → 대규모 데이터에 확장 적용 가능.                                    \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                                   <span style=\"font-weight: bold\">결론적 시사점</span>                                                   \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">데이터 복잡성 ≠ 단순 길이/혼란도</span>: 질적 진화와 세밀한 평가가 필수적.                                             \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">EVOL 기법의 효용성</span>: 비용 효율적이며, 다양한 데이터 환경에서 일관된 성능 확보.                                   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">실용적 프레임워크</span>: 제한된 자원으로 고성능 모델 구축 가능성 입증.                                                \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "\n",
       "                                  <span style=\"font-weight: bold; text-decoration: underline\">2.4 FROM THE QUALITY PERSPECTIVE – EVOL QUALITY</span>                                  \n",
       "\n",
       "<span style=\"font-weight: bold\">2.4 품질 관점 – EVOL QUALITY</span>                                                                                       \n",
       "이 섹션은 지시 튜닝 데이터의 <span style=\"font-weight: bold\">품질(Quality)</span> 측정 방법을 탐구하며, 특히 <span style=\"font-weight: bold\">EVOL QUALITY</span> 기법을 제안합니다. 핵심 내용은  \n",
       "다음과 같습니다:                                                                                                   \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                                <span style=\"font-weight: bold\">품질 측정의 중요성</span>                                                 \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">목표</span>: 정확성, 상세성, 유용성이 높은 응답을 생성하는 모델 개발.                                                  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">문제 인식</span>:                                                                                                      \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>저품질 데이터(모호한 답변, 오류 포함)는 모델 성능을 크게 저하시킵니다.                                       \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>기존 방법(예: 응답 길이)은 품질을 정확히 반영하지 못함.                                                      \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                                <span style=\"font-weight: bold\">품질 측정 방법 비교</span>                                                \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 1 </span><span style=\"font-weight: bold\">Random Selection (무작위 선택)</span>: 기준 없이 샘플링.                                                               \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 2 </span><span style=\"font-weight: bold\">Response Length (응답 길이)</span>: 긴 응답 = 고품질 가정.                                                             \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 3 </span><span style=\"font-weight: bold\">Direct Scoring (직접 점수화)</span>: ChatGPT로 응답 정확성 평가 (고비용).                                              \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 4 </span><span style=\"font-weight: bold\">EVOL QUALITY (제안 방법)</span>:                                                                                       \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">진화 기반 품질 향상</span>:                                                                                         \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">       1 </span>원본 데이터 $(I_k^{(0)}, R_k^{(0)})$에 대해 ChatGPT가 응답을 <span style=\"font-weight: bold\">품질 향상 방향</span>으로 변형 (예: 세부 정보 추가, \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">         </span>창의성 강화).                                                                                             \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">       2 </span>5회 변형을 거쳐 다양한 품질의 응답 집합 ${R_k^{(0)}, ..., R_k^{(5)}}$ 생성.                               \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">ChatGPT 순위/점수화</span>:                                                                                         \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">       • </span>동일 지시문에 대한 변형 응답들을 비교하여 세밀한 품질 점수($q$) 부여.                                     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">자동 점수 판별기 학습</span>:                                                                                       \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">       • </span>LLaMA-1 7B 모델을 미세 조정해 품질 점수 예측.                                                             \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                                 <span style=\"font-weight: bold\">실험 결과 (표 3)</span>                                                  \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">X_sota (고품질 풀)</span>:                                                                                             \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>EVOL QUALITY <span style=\"font-weight: bold\">6.19점</span> (Random 5.84점 대비 우수).                                                               \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>고품질 풀에서는 응답 길이 영향 적음 (5.94점).                                                                \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">X_base (저품질 풀)</span>:                                                                                             \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>EVOL QUALITY <span style=\"font-weight: bold\">5.67점</span> (Random 4.93점 대비 큰 격차).                                                            \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>품질 지표가 저품질 풀에서 더 큰 성능 향상 기여.                                                              \n",
       "\n",
       "<span style=\"font-weight: bold\">결론</span>:                                                                                                              \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>EVOL QUALITY는 <span style=\"font-weight: bold\">데이터 품질 편차가 큰 환경</span>에서 특히 효과적.                                                      \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>ChatGPT 주석 의존도 낮춰 비용 효율성 확보.                                                                      \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "<span style=\"font-weight: bold\">2.5 다양성 관점 – 임베딩 기반 접근법</span>                                                                               \n",
       "이 섹션은 데이터 <span style=\"font-weight: bold\">다양성(Diversity)</span> 측정 및 선택 전략을 다룹니다.                                                   \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                                  <span style=\"font-weight: bold\">다양성의 중요성</span>                                                  \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">목표</span>: 다양한 주제/형식의 요청 처리 능력 확보.                                                                   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">문제 인식</span>: 실제 데이터는 중복성 높음 → 다양성 보장 필수.                                                        \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                               <span style=\"font-weight: bold\">다양성 측정 방법 비교</span>                                               \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 1 </span><span style=\"font-weight: bold\">Random Selection</span>: 다양성 무시.                                                                                  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 2 </span><span style=\"font-weight: bold\">Instag Diversity (태그 기반)</span>:                                                                                   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>데이터에 의미론적 태그 부여 → 태그 집합의 성장으로 다양성 측정.                                              \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 3 </span><span style=\"font-weight: bold\">Repr Filter (제안 방법, 임베딩 기반)</span>:                                                                           \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">LLaMA-1 13B 임베딩</span> 활용:                                                                                     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">       1 </span>데이터 샘플을 벡터로 변환.                                                                                \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">       2 </span><span style=\"font-weight: bold\">코사인 거리</span> 계산 → 기존 선택 집합($S$)과의 유사도 평가.                                                   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">반복적 선택 프로세스</span>:                                                                                        \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">       • </span>임계값($\\tau=0.9$) 미만 시 샘플 추가 → $S$의 다양성 유지.                                                 \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">복잡성/품질 점수 선정렬</span>: 우수한 샘플 우선 검토.                                                              \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                                 <span style=\"font-weight: bold\">실험 결과 (표 4)</span>                                                  \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">X_sota</span>:                                                                                                         \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>Repr Filter <span style=\"font-weight: bold\">6.17점</span> (Instag Diversity 6.10점 대비 소폭 우위).                                                 \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">X_base</span>:                                                                                                         \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>Repr Filter <span style=\"font-weight: bold\">4.68점</span> (Instag Diversity 4.46점 대비 성능 개선).                                                 \n",
       "\n",
       "<span style=\"font-weight: bold\">결론</span>:                                                                                                              \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>임베딩 기반 접근법이 <span style=\"font-weight: bold\">태그 기반 방법보다 강건함</span>.                                                                 \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>다양성 보장 시 무작위 선택 대비 성능 향상 필수적.                                                               \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                                    <span style=\"font-weight: bold\">종합 시사점</span>                                                    \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">품질, 복잡성, 다양성</span>의 3축 데이터 측정이 모델 정렬 성능을 결정.                                                 \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">EVOL 기법</span>과 <span style=\"font-weight: bold\">임베딩 필터링</span>을 결합해 자동화된 고효율 데이터 선택 가능 → DEITA 모델의 성공적 구현.                 \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "\n",
       "                             <span style=\"font-weight: bold; text-decoration: underline\">3 DEITA– DATA EFFICIENT INSTRUCTION TUNING FOR ALIGNMENT</span>                              \n",
       "\n",
       "<span style=\"font-weight: bold\">3. DEITA – 데이터 효율적 지시 튜닝을 위한 정렬</span>                                                                     \n",
       "이 섹션에서는 복잡성(Complexity), 품질(Quality), 다양성(Diversity)의 <span style=\"font-weight: bold\">3가지 차원을 통합</span>하여 최적의 데이터를 선별하는\n",
       "방법론 <span style=\"font-weight: bold\">DEITA</span>를 제안합니다. DEITA는 적은 양의 데이터로도 고성능 모델을 구축하는 것을 목표로 합니다.                 \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                             <span style=\"font-weight: bold\">DEITA의 데이터 선택 전략</span>                                              \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 1 </span><span style=\"font-weight: bold\">3차원 통합 접근법</span>:                                                                                              \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">복잡성</span>: EVOL COMPLEXITY로 측정된 점수를 기반으로 고난이도 데이터 우선 선정.                                  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">품질</span>: EVOL QUALITY 점수를 통해 정확성과 유용성이 높은 응답을 가진 데이터 필터링.                             \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">다양성</span>: 임베딩 기반 <span style=\"font-weight: bold\">Repr Filter</span>를 적용해 중복성을 제거하고 주제/형식 다양성 보장.                            \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 2 </span><span style=\"font-weight: bold\">선별 프로세스</span>:                                                                                                  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">단계적 필터링</span>:                                                                                               \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">       1 </span><span style=\"font-weight: bold\">복잡성 + 품질 점수</span>로 상위 데이터 추출.                                                                    \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">       2 </span><span style=\"font-weight: bold\">다양성 필터링</span>: 임베딩 유사도 분석을 통해 중복 데이터 제거.                                                \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">우선순위 정렬</span>: 복잡성과 품질이 높은 데이터를 우선 검토한 후, 다양성을 확보하기 위해 반복적 선택 수행.        \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                                  <span style=\"font-weight: bold\">DEITA 모델 학습</span>                                                  \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">기반 모델</span>: LLaMA 및 Mistral 모델을 사전 학습된 모델로 사용.                                                     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">학습 데이터</span>: 상기 전략으로 선별된 <span style=\"font-weight: bold\">6,000개의 SFT 데이터</span>만 활용.                                                  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">성능</span>:                                                                                                           \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">DEITA-Mistral-7B</span>: 6K SFT 데이터로 <span style=\"font-weight: bold\">MT-Bench 7.22점</span>, <span style=\"font-weight: bold\">AlpacaEval 80.78%</span> 달성.                                   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">DPO 추가 학습 시</span>: 6K SFT + 10K DPO 데이터로 <span style=\"font-weight: bold\">MT-Bench 7.55점</span>, <span style=\"font-weight: bold\">AlpacaEval 90.06%</span> 기록.                         \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">효율성</span>: 기존 모델 대비 <span style=\"font-weight: bold\">10배 이상 적은 데이터</span>로 동등/우수한 성능 구현.                                           \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                                   <span style=\"font-weight: bold\">의의 및 기여</span>                                                    \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 1 </span><span style=\"font-weight: bold\">과학적 데이터 선별</span>:                                                                                             \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>복잡성, 품질, 다양성의 체계적 측정을 통해 경험적 방법의 한계 극복.                                           \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 2 </span><span style=\"font-weight: bold\">리소스 효율성</span>:                                                                                                  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>대량 데이터 수집/주석 비용 절감 및 학습 시간 단축.                                                           \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 3 </span><span style=\"font-weight: bold\">오픈소스 공개</span>:                                                                                                  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>선별된 데이터셋과 모델을 공개해 연구 재현성 및 후속 연구 지원.                                               \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                                       <span style=\"font-weight: bold\">결론</span>                                                        \n",
       "\n",
       "DEITA는 <span style=\"font-weight: bold\">데이터 효율성</span>과 <span style=\"font-weight: bold\">모델 성능</span> 간의 균형을 최적화하는 프레임워크로, LLM 정렬에 필요한 데이터 선택의 과학적      \n",
       "기준을 제시했습니다. 이 접근법은 향후 모델 개발 시 자원 제약 문제를 해결하는 데 기여할 것으로 기대됩니다.          \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "\n",
       "                                                    <span style=\"font-weight: bold; text-decoration: underline\">3.1 METHOD</span>                                                     \n",
       "\n",
       "<span style=\"font-weight: bold\">3.1 방법론 (METHOD) 설명</span>                                                                                           \n",
       "(참고: 원문에 내용이 누락된 것으로 보이지만, 논문의 흐름과 이전 섹션들을 바탕으로 <span style=\"font-weight: bold\">추론된 설명</span>을 제공합니다.)       \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                             <span style=\"font-weight: bold\">DEITA 방법론의 핵심 단계</span>                                              \n",
       "\n",
       "DEITA는 복잡성(Complexity), 품질(Quality), 다양성(Diversity)의 <span style=\"font-weight: bold\">3가지 차원을 종합</span>하여 데이터를 선택하고, 이를       \n",
       "바탕으로 고효율 지시 튜닝을 수행합니다. 구체적인 단계는 다음과 같습니다:                                           \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">1. 데이터 측정 및 점수화</span>                                              \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 1 </span><span style=\"font-weight: bold\">복잡성 점수 (Complexity Score)</span>:                                                                                 \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">EVOL COMPLEXITY</span> 기법을 사용해 각 데이터 샘플의 복잡성을 측정합니다.                                          \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>ChatGPT로 생성된 변형 예시의 순위와 점수를 학습해 자동 복잡성 판별기를 구축합니다.                           \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 2 </span><span style=\"font-weight: bold\">품질 점수 (Quality Score)</span>:                                                                                      \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">EVOL QUALITY</span> 기법을 적용해 응답의 정확성과 유용성을 평가합니다.                                              \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>동일한 지시문에 대한 다양한 품질의 응답을 비교하여 세밀한 점수화를 수행합니다.                               \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 3 </span><span style=\"font-weight: bold\">다양성 점수 (Diversity Score)</span>:                                                                                  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">임베딩 기반 Repr Filter</span>를 활용해 데이터 간 유사도를 계산합니다.                                              \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>LLaMA 모델의 임베딩 공간에서 코사인 거리를 측정하여 중복성을 제거합니다.                                     \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">2. 데이터 선별 전략</span>                                                \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 1 </span><span style=\"font-weight: bold\">우선순위 정렬</span>:                                                                                                  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>복잡성과 품질 점수를 종합해 상위 데이터를 선별합니다.                                                        \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>예: 복잡성 점수 × 품질 점수의 가중합으로 순위 결정.                                                          \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 2 </span><span style=\"font-weight: bold\">다양성 필터링</span>:                                                                                                  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>선정된 상위 데이터 집합에 대해 <span style=\"font-weight: bold\">임베딩 유사도 분석</span>을 수행합니다.                                              \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>임계값(τ=0.9)을 초과하는 중복 샘플을 제거하며, 최종 6K 데이터 선택.                                          \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                               <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">3. 모델 학습 및 평가</span>                                                \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 1 </span><span style=\"font-weight: bold\">모델 미세 조정</span>:                                                                                                 \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>선별된 데이터로 LLaMA 또는 Mistral 모델을 지시 튜닝합니다.                                                   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>고정된 하이퍼파라미터를 사용해 재현성 보장 (부록 A 참조).                                                    \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 2 </span><span style=\"font-weight: bold\">성능 평가</span>:                                                                                                      \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">MT-Bench</span>, <span style=\"font-weight: bold\">AlpacaEval</span>, <span style=\"font-weight: bold\">Open LLM Leaderboard</span>에서 성능을 측정합니다.                                            \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>GPT-4를 평가자로 활용해 응답의 유용성과 정확성을 점수화합니다.                                               \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                                       <span style=\"font-weight: bold\">의의</span>                                                        \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">통합 프레임워크</span>: 3가지 차원의 측정 지표를 조합해 데이터 효율성을 극대화합니다.                                  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">계층적 선택</span>: 복잡성/품질 → 다양성 순의 단계적 필터링으로 최적화된 데이터셋 구축.                                \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">확장성</span>: 다른 LLM 및 데이터셋에 적용 가능한 일반적인 방법론을 제시합니다.                                        \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "이 방법론은 <span style=\"font-weight: bold\">DEITA 모델</span>의 우수한 성능(§3 결과 섹션 참조)을 가능하게 한 핵심 기여로, 적은 데이터로도 고품질 정렬을   \n",
       "달성하는 과학적 접근법을 구현합니다.                                                                               \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "\n",
       "                              <span style=\"font-weight: bold; text-decoration: underline\">Algorithm 1 Score-First, Diversity-Aware Data Selection</span>                              \n",
       "\n",
       "<span style=\"font-weight: bold\">알고리즘 1: 점수 우선, 다양성 고려 데이터 선택 (Score-First, Diversity-Aware Data Selection)</span>                       \n",
       "\n",
       "이 알고리즘은 **복잡성(Complexity)**과 <span style=\"font-weight: bold\">품질(Quality)</span> 점수를 기반으로 데이터를 우선순위화한 후,                     \n",
       "**다양성(Diversity)**을 보장하기 위해 중복 샘플을 제거하는 과정을 체계적으로 결합합니다.                           \n",
       "DEITA 모델의 데이터 효율적 학습을 위해 설계되었으며, 주요 단계는 다음과 같습니다:                                  \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                                <span style=\"font-weight: bold\">알고리즘 단계 설명</span>                                                 \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 1 </span><span style=\"font-weight: bold\">입력</span>:                                                                                                           \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>데이터 풀 ( X ): 지시-응답 쌍으로 구성된 대규모 데이터 집합.                                                 \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>데이터 예산 ( m ): 선택할 샘플 수 (예: 6,000개).                                                             \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 2 </span><span style=\"font-weight: bold\">출력</span>:                                                                                                           \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>선별된 데이터 부분집합 ( S_{\\pi_{\\mathrm{DEITA}}}^{(m)} ).                                                   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 3 </span><span style=\"font-weight: bold\">초기화</span>:                                                                                                         \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>빈 데이터셋 ( S ) 생성.                                                                                      \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 4 </span><span style=\"font-weight: bold\">점수 계산 및 정렬</span>:                                                                                              \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>각 샘플의 **복잡성 점수(( c ))**와 **품질 점수(( q ))**를 곱해 종합 점수 ( s = c \\times q ) 계산.            \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>( s )를 기준으로 데이터 풀 ( X )를 내림차순 정렬 → ( X^* ).                                                  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 5 </span><span style=\"font-weight: bold\">반복적 선택 및 다양성 필터링</span>:                                                                                   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>정렬된 ( X^* )의 샘플을 순차적으로 검토:                                                                     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">       • </span><span style=\"font-weight: bold\">단계 7-8</span>: 현재 샘플 ( x )와 ( S ) 내 가장 가까운 샘플 간 <span style=\"font-weight: bold\">임베딩 거리</span> 계산.                                \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">          • </span><span style=\"font-weight: bold\">LLaMA-1 13B</span> 모델로 임베딩 추출 → <span style=\"font-weight: bold\">코사인 거리</span> 측정.                                                     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">       • </span><span style=\"font-weight: bold\">단계 9-12</span>: 거리가 임계값 ( \\tau=0.9 ) 미만이면 ( S )에 추가 (중복으로 판단해 제외).                       \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">       • </span><span style=\"font-weight: bold\">단계 14-16</span>: ( S )의 크기가 ( m )에 도달하면 종료.                                                         \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                                     <span style=\"font-weight: bold\">핵심 개념</span>                                                     \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 1 </span><span style=\"font-weight: bold\">Evol Score (( s = c \\times q ))</span>:                                                                                \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>복잡성과 품질을 동시에 반영한 종합 점수.                                                                     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>높은 ( s )를 가진 샘플은 <span style=\"font-weight: bold\">난이도 높고 정확한 응답</span>을 가짐.                                                     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">다중 회차 대화</span>에서는 각 회차별 점수를 합산해 전체 점수 계산.                                                 \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 2 </span><span style=\"font-weight: bold\">Repr Filter (임베딩 기반 필터링)</span>:                                                                               \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">LLaMA 임베딩</span>을 사용해 샘플 간 의미적 유사도 측정.                                                            \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>코사인 거리 ( d(x, S) )가 임계값 ( \\tau=0.9 )보다 작으면 중복으로 판단 → 제외.                               \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">계층적 선택</span>: 우수한 샘플을 우선 검토한 후, 다양성 보장을 위해 필터링.                                        \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                                  <span style=\"font-weight: bold\">DEITA 모델 학습</span>                                                  \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">학습 데이터</span>: 알고리즘으로 선별된 ( m )개 샘플 (예: 6K).                                                         \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">기반 모델</span>: LLaMA-1-13B, LLaMA-2-13B, Mistral-7B 등.                                                             \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">학습 세부사항</span>: 고정된 하이퍼파라미터 사용 (부록 A 참조).                                                        \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                                       <span style=\"font-weight: bold\">의의</span>                                                        \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">효율성</span>: 복잡성/품질 점수 정렬 + 다양성 필터링으로 <span style=\"font-weight: bold\">적은 데이터로 고성능 달성</span>.                                    \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">과학적 데이터 선택</span>: 경험적 방법 대신 체계적 지표 기반 접근.                                                     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">확장성</span>: 다른 LLM 및 데이터셋에 적용 가능한 일반화된 프레임워크.                                                 \n",
       "\n",
       "이 알고리즘은 DEITA 모델이 <span style=\"font-weight: bold\">10배 이상 적은 데이터</span>로도 SOTA 성능을 내는 데 기여한 핵심 메커니즘입니다.               \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "\n",
       "                                              <span style=\"font-weight: bold; text-decoration: underline\">3.2 EXPERIMENTAL SETUP</span>                                               \n",
       "\n",
       "<span style=\"font-weight: bold\">3.2 실험 설정 (EXPERIMENTAL SETUP) 설명</span>                                                                            \n",
       "이 섹션에서는 DEITA 모델의 학습 및 평가를 위한 구체적인 실험 환경을 설명합니다. 주요 내용은 다음과 같습니다:       \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                                <span style=\"font-weight: bold\">데이터 및 학습 설정</span>                                                \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 1 </span><span style=\"font-weight: bold\">데이터 예산</span>:                                                                                                    \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">6K</span> 및 <span style=\"font-weight: bold\">10K</span> 샘플로 DEITA 모델을 각각 학습합니다.                                                               \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>데이터 풀: 고품질 데이터 집합인 <span style=\"font-weight: bold\">X_sota</span>에서 샘플 선별.                                                        \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 2 </span><span style=\"font-weight: bold\">기반 모델</span>:                                                                                                      \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">LLaMA-1-13B</span>, <span style=\"font-weight: bold\">LLaMA-2-13B</span>, <span style=\"font-weight: bold\">Mistral-7B</span>를 기본 모델로 사용합니다.                                               \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 3 </span><span style=\"font-weight: bold\">학습 방법</span>:                                                                                                      \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>**지시 튜닝(SFT)**에 집중: 데이터 선택 전략의 효과를 명확히 분석하기 위해 RLHF 대신 SFT만 적용.              \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>추가 실험: 최고 성능 SFT 모델에 **DPO(Direct Preference Optimization)**를 적용해 성능 향상 확인.             \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">       • </span>DPO 데이터: <span style=\"font-weight: bold\">UltraFeedback</span> 데이터셋에서 추출한 10K 비교 쌍 사용.                                           \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                                   <span style=\"font-weight: bold\">평가 벤치마크</span>                                                   \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 1 </span><span style=\"font-weight: bold\">MT-Bench</span>:                                                                                                       \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>다중 회차 대화 평가 (글쓰기, 추론, 코딩 등).                                                                 \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>GPT-4가 응답 품질을 점수화.                                                                                  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 2 </span><span style=\"font-weight: bold\">AlpacaEval</span>:                                                                                                     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>지시 수행 능력 평가.                                                                                         \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>인간 평가자 또는 GPT-4가 응답의 유용성과 정확성을 평가.                                                      \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 3 </span><span style=\"font-weight: bold\">Open LLM Leaderboard</span>:                                                                                           \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>4가지 분류 과제로 구성:                                                                                      \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">       • </span><span style=\"font-weight: bold\">ARC</span>: 과학적 추론 능력.                                                                                    \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">       • </span><span style=\"font-weight: bold\">HellaSwag</span>: 상식 추론.                                                                                     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">       • </span><span style=\"font-weight: bold\">MMLU</span>: 다학제적 지식 이해.                                                                                 \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">       • </span><span style=\"font-weight: bold\">TruthfulQA</span>: 사실 기반 응답 정확성.                                                                        \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 4 </span><span style=\"font-weight: bold\">인간 평가</span>: 부록 D에서 추가 결과 제공.                                                                           \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                                  <span style=\"font-weight: bold\">비교 대상 모델</span>                                                   \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 1 </span><span style=\"font-weight: bold\">데이터 선택 기법 비교</span>:                                                                                          \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">LIMA</span>, <span style=\"font-weight: bold\">Alpagasus</span>, <span style=\"font-weight: bold\">TAGLM</span>과 DEITA의 성능 차이 분석.                                                             \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 2 </span><span style=\"font-weight: bold\">오픈소스 SOTA 모델 비교</span>:                                                                                        \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">Vicuna</span>, <span style=\"font-weight: bold\">WizardLM</span>, <span style=\"font-weight: bold\">Mistral-Instruct</span>, <span style=\"font-weight: bold\">Zephyr</span> 등과 성능 경쟁력 평가.                                            \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                                     <span style=\"font-weight: bold\">실험 목적</span>                                                     \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 1 </span><span style=\"font-weight: bold\">데이터 선택 전략 검증</span>:                                                                                          \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>제안된 복잡성-품질-다양성 통합 전략이 기존 방법 대비 우수함을 입증.                                          \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 2 </span><span style=\"font-weight: bold\">모델 확장성 확인</span>:                                                                                               \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>다양한 기반 모델(LLaMA-1, LLaMA-2, Mistral)에서 DEITA의 일반화 가능성 검토.                                  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 3 </span><span style=\"font-weight: bold\">DPO 효과 분석</span>:                                                                                                  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>SFT 후 DPO 적용 시 최종 성능 향상 정도 측정.                                                                 \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                                       <span style=\"font-weight: bold\">의의</span>                                                        \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>DEITA의 <span style=\"font-weight: bold\">데이터 효율성</span>과 <span style=\"font-weight: bold\">범용성</span>을 다각도로 입증하기 위한 체계적 실험 설계.                                       \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>오픈소스 LLM 생태계에서 <span style=\"font-weight: bold\">적은 데이터로 고성능 모델 구축</span> 가능성을 제시.                                           \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "\n",
       "                                                    <span style=\"font-weight: bold; text-decoration: underline\">3.3 RESULTS</span>                                                    \n",
       "\n",
       "<span style=\"font-weight: bold\">3.3 실험 결과 (RESULTS) 설명</span>                                                                                       \n",
       "이 섹션은 DEITA 모델의 성능을 다양한 벤치마크와 기존 SOTA 모델과 비교한 결과를 제시합니다. 핵심 내용은 다음과      \n",
       "같습니다:                                                                                                          \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                                  <span style=\"font-weight: bold\">주요 비교 결과</span>                                                   \n",
       "\n",
       "                              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">표 5: 데이터 선택 기법 간 성능 비교 (LLaMA-1-13B 기반)</span>                               \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">DEITA-LLaMA1-13B (6K)</span>:                                                                                          \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">MT-Bench 6.46</span>, **AlpacaEval 77.08%**로 모든 경쟁 방법(Random, Alpagasus, LIMA, TAGLM)을 큰 격차로 능가.      \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">LIMA (1K 데이터)</span> 대비 MT-Bench <span style=\"font-weight: bold\">+2.17점</span>, AlpacaEval <span style=\"font-weight: bold\">+35.1%p</span> 향상.                                             \n",
       "\n",
       "                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">표 6: 다양한 기반 모델별 SOTA 모델 비교</span>                                      \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 1 </span><span style=\"font-weight: bold\">LLaMA-1-13B 기반</span>:                                                                                               \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">DEITA-10K</span>: MT-Bench <span style=\"font-weight: bold\">6.60</span>, AlpacaEval **78.01%**로 WizardLM(70K 데이터) 및 Vicuna(125K 데이터)보다 우수.      \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 2 </span><span style=\"font-weight: bold\">LLaMA-2-13B 기반</span>:                                                                                               \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">DEITA-10K</span>: MT-Bench <span style=\"font-weight: bold\">6.79</span>, AlpacaEval **81.09%**로 RLHF 적용된 LLaMA2-Chat(&gt;100K SFT + 1M RLHF)와 동등.       \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 3 </span><span style=\"font-weight: bold\">Mistral-7B 기반</span>:                                                                                                \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">DEITA-6K + DPO</span>: MT-Bench <span style=\"font-weight: bold\">7.55</span>, AlpacaEval **90.06%**로 Zephyr(200K SFT + 60K DPO)과 비슷한 성능 달성.        \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">Mistral-Instruct-v0.2</span> (비공개 데이터)에 근접한 성능.                                                         \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                         <span style=\"font-weight: bold\">Open LLM Leaderboard 결과 (표 7)</span>                                          \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">DEITA-Mistral-7B (6K + DPO)</span>:                                                                                    \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">평균 69.86점</span>으로 Zephyr-beta(66.36점)를 능가.                                                                \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">TruthfulQA 67.14점</span>, <span style=\"font-weight: bold\">ARC 66.21점</span>에서 특히 뛰어남.                                                             \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">DEITA-LLaMA1-13B (10K)</span>:                                                                                         \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>LIMA, WizardLM, Vicuna 등 모든 LLaMA-1 기반 모델을 큰 격차로 제치고 최고 평균 점수(<span style=\"font-weight: bold\">64.27</span>) 기록.              \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                           <span style=\"font-weight: bold\">데이터 스케일링 분석 (그림 2)</span>                                           \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">DEITA의 효율성</span>:                                                                                                 \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">3K 데이터</span>로 전체 300K 데이터 사용 시와 동등 성능 → <span style=\"font-weight: bold\">100배 데이터 효율성</span>.                                      \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>데이터 증가 시 초기 성능 상승 후 감소 → \"좋은 데이터\" 비중 제한적임을 시사.                                  \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                         <span style=\"font-weight: bold\">MT-Bench 세부 능력 분석 (그림 3)</span>                                          \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">DEITA-Mistral</span>의 강점:                                                                                           \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">코딩</span>, <span style=\"font-weight: bold\">수학</span>, <span style=\"font-weight: bold\">추론</span> 과제에서 탁월한 성능 → MT-Bench 고득점 주원인.                                              \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>AlpacaEval은 기본 지시 수행에 집중되므로 상대적 격차 작음.                                                   \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                                    <span style=\"font-weight: bold\">핵심 시사점</span>                                                    \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 1 </span><span style=\"font-weight: bold\">데이터 효율성</span>:                                                                                                  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span><span style=\"font-weight: bold\">6K~10K 데이터</span>로 기존 70K~200K 데이터 기반 모델 대비 우수한 성능.                                             \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 2 </span><span style=\"font-weight: bold\">DPO의 시너지</span>:                                                                                                   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>SFT 후 DPO 적용 시 성능 추가 향상 (MT-Bench <span style=\"font-weight: bold\">7.22 → 7.55</span>, AlpacaEval <span style=\"font-weight: bold\">80.78% → 90.06%</span>).                        \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 3 </span><span style=\"font-weight: bold\">범용성</span>:                                                                                                         \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>LLaMA-1, LLaMA-2, Mistral 등 다양한 기반 모델에서 일관된 우수성 입증.                                        \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 4 </span><span style=\"font-weight: bold\">데이터 품질의 중요성</span>:                                                                                           \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    • </span>고품질 데이터 선택이 양적 확장보다 성능에 더 직결됨을 실험적으로 검증.                                       \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                                       <span style=\"font-weight: bold\">결론</span>                                                        \n",
       "\n",
       "DEITA는 <span style=\"font-weight: bold\">데이터 선택의 과학적 접근법</span>을 통해 적은 자원으로도 SOTA 성능을 달성함으로써, LLM 정렬 분야에 새로운        \n",
       "패러다임을 제시했습니다. 특히 오픈소스 모델 생태계에서 리소스 효율적 고성능 모델 개발의 가능성을 입증했습니다.     \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "                                                     \u001b[1;4mABSTRACT\u001b[0m                                                      \n",
       "\n",
       "\u001b[1m요약 설명:\u001b[0m                                                                                                         \n",
       "이 논문은 대규모 언어 모델을 특정 작업과 사용자 선호에 맞추기 위한 핵심 기술인 **지시 튜닝(Instruction Tuning)**의 \n",
       "데이터 선택 전략을 탐구합니다. 기존 연구는 적절한 데이터 선택이 적은 양으로도 우수한 성능을 낼 수 있음을 보였지만, \n",
       "\"좋은 데이터\"의 기준과 자동 선택 방법은 명확히 규명되지 않았습니다.                                                \n",
       "\n",
       "\u001b[1m핵심 내용:\u001b[0m                                                                                                         \n",
       "\n",
       "\u001b[1;33m 1 \u001b[0m\u001b[1m데이터 측정 3가지 차원\u001b[0m:                                                                                         \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1m복잡성(Complexity)\u001b[0m: 데이터의 난이도와 정보 밀도                                                              \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1m품질(Quality)\u001b[0m: 정확성과 유용성                                                                               \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1m다양성(Diversity)\u001b[0m: 주제와 형식의 다양성                                                                      \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0m기존 방법을 분석하고, 이를 개선한 새로운 측정 기법을 제안합니다.                                             \n",
       "\u001b[1;33m 2 \u001b[0m\u001b[1mDEITA (Data-Efficient Instruction Tuning for Alignment)\u001b[0m:                                                        \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mLLaMA와 Mistral 모델을 기반으로, \u001b[1m자동 선택된 6,000개의 SFT 데이터\u001b[0m만으로 미세 조정한 모델 시리즈입니다.       \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m기존 오픈소스 모델 대비 \u001b[1m10배 이상 적은 데이터\u001b[0m로 동등하거나 더 나은 성능을 달성했습니다.                      \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mDPO(Direct Preference Optimization) 추가 학습 시 \u001b[1mMT-Bench 7.55점\u001b[0m, **AlpacaEval 90.06%**의 우수한 결과를      \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0m보였습니다.                                                                                                  \n",
       "\u001b[1;33m 3 \u001b[0m\u001b[1m의의\u001b[0m:                                                                                                           \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m데이터 선택의 과학적 접근법과 효율적인 정렬 도구를 제시하여, \u001b[1m적은 데이터로 고성능 모델을 구축\u001b[0m하는 방법을     \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0m개척했습니다.                                                                                                \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m선택된 데이터셋과 모델을 공개해 향후 연구에 기여할 것으로 기대됩니다.                                        \n",
       "\n",
       "\u001b[1m결론\u001b[0m: 이 연구는 데이터 품질과 선택 전략이 모델 성능에 미치는 영향을 체계화하고, 효율적인 모델 정렬을 위한 실용적인 \n",
       "프레임워크를 제시했습니다.                                                                                         \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "\n",
       "                                                  \u001b[1;4m1 INTRODUCTION\u001b[0m                                                   \n",
       "\n",
       "\u001b[1m1. 서론 (INTRODUCTION) 설명:\u001b[0m                                                                                       \n",
       "\n",
       "이 섹션은 대규모 언어 모델(LLM)을 인간의 선호도에 맞추는 \u001b[1m정렬(Alignment)\u001b[0m 과정의 중요성과 방법론, 특히 \u001b[1m데이터 \u001b[0m      \n",
       "\u001b[1m효율성\u001b[0m을 높이기 위한 접근법을 다룹니다. 핵심 내용은 다음과 같습니다:                                               \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                                 \u001b[1m배경 및 문제 제기\u001b[0m                                                 \n",
       "\n",
       "\u001b[1;33m 1 \u001b[0m\u001b[1mLLM 정렬의 필요성\u001b[0m                                                                                               \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mLLM이 인간의 지시를 정확히 이해하고 유용한 응답을 생성하려면 \u001b[1m인간 선호도와의 정렬\u001b[0m이 필수적입니다.            \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m주요 정렬 기법으로는 **지시 튜닝(Instruction Tuning/SFT)**과 **인간 피드백 강화학습(RLHF)**이 사용됩니다.    \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1m지시 튜닝\u001b[0m: 사전 학습된 모델을 주석이 달린 지시 데이터로 미세 조정합니다.                                  \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1mRLHF\u001b[0m: 모델의 응답에 대한 인간 피드백을 바탕으로 강화학습을 적용합니다.                                    \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m최근 연구는 지시 튜닝만으로도 RLHF 수준의 성능을 달성할 수 있음을 보였습니다.                                \n",
       "\u001b[1;33m 2 \u001b[0m\u001b[1m데이터 효율성의 중요성\u001b[0m                                                                                          \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m기존 과제별 미세 조정은 대량의 데이터가 필요했지만, \u001b[1m지시 튜닝은 모델의 사전 학습된 지식을 적은 데이터로 \u001b[0m     \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0m\u001b[1m조정\u001b[0m합니다.                                                                                                  \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m1,000개 수준의 고품질 데이터만으로도 효과적인 정렬이 가능하다는 연구 결과가 있습니다.                        \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1m문제점\u001b[0m: 현재 데이터 선택은 경험적 자동화(예: ChatGPT에서 추출)나 수작업에 의존하며, 체계적인 기준이          \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0m부족합니다.                                                                                                  \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                         \u001b[1m해결 방안: 데이터 측정 3가지 차원\u001b[0m                                         \n",
       "\n",
       "연구진은 \"좋은 데이터\"를 정의하기 위해 다음 세 가지 측면을 제시합니다:                                             \n",
       "\n",
       "\u001b[1;33m 1 \u001b[0m\u001b[1m복잡성(Complexity)\u001b[0m: 데이터의 난이도와 정보 밀도                                                                 \n",
       "\u001b[1;33m 2 \u001b[0m\u001b[1m품질(Quality)\u001b[0m: 응답의 정확성과 유용성                                                                           \n",
       "\u001b[1;33m 3 \u001b[0m\u001b[1m다양성(Diversity)\u001b[0m: 주제와 형식의 다양성                                                                         \n",
       "\n",
       "\u001b[1m측정 방법\u001b[0m                                                                                                          \n",
       "\n",
       "\u001b[1;33m • \u001b[0m\u001b[1mEVOL COMPLEXITY/QUALITY\u001b[0m:                                                                                        \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m단일 데이터 포인트를 변형해 복잡성/품질이 다른 예시를 생성합니다.                                            \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mChatGPT로 변형된 예시를 순위 매기고 점수화한 후, 이를 학습해 \u001b[1m자동 점수 판별기\u001b[0m를 개발합니다.                  \n",
       "\u001b[1;33m • \u001b[0m\u001b[1m다양성 측정\u001b[0m: 모델 임베딩 간 거리를 계산해 데이터의 다양성을 평가합니다.                                         \n",
       "\n",
       "이를 바탕으로 대량 데이터 풀에서 \u001b[1m효율적인 데이터 샘플을 자동 선별\u001b[0m하는 전략을 수립합니다(그림 1 참조).              \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                                 \u001b[1mDEITA 모델과 성과\u001b[0m                                                 \n",
       "\n",
       "\u001b[1;33m • \u001b[0m\u001b[1mDEITA (Data-Efficient Instruction Tuning for Alignment)\u001b[0m:                                                        \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mLLaMA와 Mistral 모델을 기반으로, \u001b[1m자동 선별된 6,000개 SFT 데이터\u001b[0m로 미세 조정된 모델군입니다.                  \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1m주요 성과\u001b[0m:                                                                                                   \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m기존 모델(Zephyr, Vicuna 등) 대비 \u001b[1m10배 이상 적은 데이터\u001b[0m로 동등/우수한 성능 달성.                          \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mDEITA-Mistral-7B: 6K SFT 데이터로 MT-bench 7.22점, AlpacaEval 80.78%.                                     \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mDPO(Direct Preference Optimization) 추가 시 \u001b[1mMT-bench 7.55점, AlpacaEval 90.06%\u001b[0m 기록.                      \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m데이터셋과 모델을 공개해 향후 연구에 기여합니다.                                                             \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                                       \u001b[1m의의\u001b[0m                                                        \n",
       "\n",
       "\u001b[1;33m • \u001b[0m데이터 선택의 과학적 기준을 제시하고, \u001b[1m적은 데이터로 고성능 모델 정렬\u001b[0m을 가능하게 함.                             \n",
       "\u001b[1;33m • \u001b[0m자동화된 데이터 선별 프레임워크를 통해 LLM 개발의 리소스 효율성을 개선.                                         \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "\n",
       "                                       \u001b[1;4m2 WHAT MAKES GOOD DATA FOR ALIGNMENT?\u001b[0m                                       \n",
       "\n",
       "\u001b[1m2. \"정렬을 위한 좋은 데이터의 조건은 무엇인가?\" 섹션 설명\u001b[0m                                                          \n",
       "이 섹션에서는 **지시 튜닝(Instruction Tuning)**에 효과적인 데이터의 특성을 체계적으로 분석합니다. 연구진은 \"좋은   \n",
       "데이터\"의 기준을 규명하기 위해 다음 단계로 접근합니다:                                                             \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                            \u001b[1m2.1 데이터 선택 문제의 정의\u001b[0m                                            \n",
       "\n",
       "\u001b[1;33m • \u001b[0m\u001b[1m핵심 질문\u001b[0m:                                                                                                      \n",
       "\u001b[1;33m   \u001b[0m\"적은 양의 데이터로도 대규모 언어 모델(LLM)을 인간의 의도에 효과적으로 정렬하려면, 어떤 데이터를 선택해야       \n",
       "\u001b[1;33m   \u001b[0m하는가?\"                                                                                                        \n",
       "\u001b[1;33m • \u001b[0m\u001b[1m문제 배경\u001b[0m:                                                                                                      \n",
       "\u001b[1;33m   \u001b[0m기존 연구는 데이터 품질과 양의 균형이 모델 성능에 미치는 영향에 대한 명확한 기준이 부족했습니다.                \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[3m예시\u001b[0m: 수작업 선별이나 ChatGPT 추출과 같은 경험적 방법은 과학적 근거가 미흡합니다.                            \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                                   \u001b[1m2.2 실험 설계\u001b[0m                                                   \n",
       "\n",
       "\u001b[1;33m • \u001b[0m\u001b[1m목표\u001b[0m:                                                                                                           \n",
       "\u001b[1;33m   \u001b[0m데이터의 \u001b[1m복잡성(Complexity)\u001b[0m, \u001b[1m품질(Quality)\u001b[0m, **다양성(Diversity)**이 모델 정렬에 미치는 영향을 정량적으로        \n",
       "\u001b[1;33m   \u001b[0m평가합니다.                                                                                                     \n",
       "\u001b[1;33m • \u001b[0m\u001b[1m방법\u001b[0m:                                                                                                           \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m 1 \u001b[0m다양한 데이터 측정 지표(기존 방법 + 새로운 기법)를 도입합니다.                                               \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m 2 \u001b[0m각 지표와 모델 성능 간의 상관관계를 분석합니다.                                                              \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m 3 \u001b[0m실제 지시 튜닝 실험을 통해 이론적 가설을 검증합니다.                                                         \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                           \u001b[1m2.3-2.5 데이터 측정 지표 탐구\u001b[0m                                           \n",
       "\n",
       "                                                  \u001b[1;2m1. 복잡성(§2.3)\u001b[0m                                                  \n",
       "\n",
       "\u001b[1;33m • \u001b[0m\u001b[1m정의\u001b[0m: 데이터의 \u001b[1m난이도\u001b[0m와 \u001b[1m정보 밀도\u001b[0m                                                                               \n",
       "\u001b[1;33m • \u001b[0m\u001b[1m측정 방법\u001b[0m:                                                                                                      \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1mEVOL COMPLEXITY\u001b[0m: 단일 데이터를 변형해 복잡성 수준이 다른 예시 생성 → ChatGPT로 순위 매기기 → 복잡성 점수     \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0m판별기 학습.                                                                                                 \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[3m예시\u001b[0m: \"고양이 설명\" (단순) vs. \"양자역학의 기본 원리 설명\" (복잡).                                           \n",
       "\n",
       "                                                   \u001b[1;2m2. 품질(§2.4)\u001b[0m                                                   \n",
       "\n",
       "\u001b[1;33m • \u001b[0m\u001b[1m정의\u001b[0m: 응답의 \u001b[1m정확성\u001b[0m과 \u001b[1m유용성\u001b[0m                                                                                    \n",
       "\u001b[1;33m • \u001b[0m\u001b[1m측정 방법\u001b[0m:                                                                                                      \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1mEVOL QUALITY\u001b[0m: 데이터 품질을 인위적으로 조절한 변형 예시 생성 → ChatGPT로 품질 순위 평가 → 품질 점수 판별기   \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0m개발.                                                                                                        \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[3m예시\u001b[0m: 명확한 답변 (고품질) vs. 모호하거나 오류 있는 답변 (저품질).                                           \n",
       "\n",
       "                                                  \u001b[1;2m3. 다양성(§2.5)\u001b[0m                                                  \n",
       "\n",
       "\u001b[1;33m • \u001b[0m\u001b[1m정의\u001b[0m: 데이터의 \u001b[1m주제\u001b[0m와 \u001b[1m형식\u001b[0m적 다양성                                                                             \n",
       "\u001b[1;33m • \u001b[0m\u001b[1m측정 방법\u001b[0m:                                                                                                      \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m모델 임베딩(Embedding) 간 \u001b[1m코사인 유사도\u001b[0m 계산 → 유사도가 낮을수록 다양성이 높음.                              \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[3m예시\u001b[0m: 다양한 분야(과학, 문학, 역사)와 질문 유형(설명, 요약, 추론)을 포함하는 데이터.                         \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                                       \u001b[1m의의\u001b[0m                                                        \n",
       "\n",
       "\u001b[1;33m • \u001b[0m\u001b[1m3가지 차원의 측정 지표\u001b[0m를 통해 데이터 선택의 과학적 근거 마련.                                                   \n",
       "\u001b[1;33m • \u001b[0m\u001b[1mEVOL 기법\u001b[0m을 통해 복잡성/품질을 자동으로 평가하는 방법 제시.                                                     \n",
       "\u001b[1;33m • \u001b[0m후속 실험(§3)에서 이 지표들을 활용해 \u001b[1m고효율 데이터 선택 전략\u001b[0m을 수립함으로써, 적은 데이터로도 우수한 모델 성능을 \n",
       "\u001b[1;33m   \u001b[0m입증합니다.                                                                                                     \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "\n",
       "                                          \u001b[1;4m2.1 THE DATA SELECTION PROBLEM\u001b[0m                                           \n",
       "\n",
       "\u001b[1m2.1 데이터 선택 문제 (THE DATA SELECTION PROBLEM) 설명\u001b[0m                                                             \n",
       "이 섹션은 **지시 튜닝(Instruction Tuning)**을 위한 최적의 데이터를 선별하는 문제를 체계적으로 정의하고, 이를       \n",
       "해결하기 위한 프레임워크를 제시합니다. 핵심 개념은 다음과 같습니다:                                                \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                                     \u001b[1m문제 정의\u001b[0m                                                     \n",
       "\n",
       "\u001b[1;33m • \u001b[0m\u001b[1m목표\u001b[0m: 대규모 데이터 풀에서 **제한된 데이터 예산(Data Budget, \u001b[3mm\u001b[0m)**으로 최고의 정렬 성능(\u001b[3mQ\u001b[0m)을 달성하는 데이터     \n",
       "\u001b[1;33m   \u001b[0m부분집합(\u001b[3mS_π^(m)\u001b[0m)을 선택하는 것.                                                                                \n",
       "\u001b[1;33m • \u001b[0m\u001b[1m데이터 풀 구성\u001b[0m:                                                                                                 \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[3mX = {x₁, x₂, ..., xₙ}\u001b[0m: 지시-응답 쌍(instruction-response pair)으로 이루어진 대규모 데이터 집합.              \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m각 \u001b[3mxᵢ\u001b[0m는 하나의 데이터 샘플을 의미합니다.                                                                     \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                               \u001b[1m선택 전략(π)과 최적화\u001b[0m                                               \n",
       "\n",
       "\u001b[1;33m • \u001b[0m\u001b[1m선택 전략(π)\u001b[0m: 데이터 품질을 평가하는 **측정 지표(metric)**를 기반으로 데이터를 선별하는 방법.                   \n",
       "\u001b[1;33m • \u001b[0m\u001b[3m최적 전략(π\u001b[0m\u001b[3m)\u001b[0m*: 주어진 데이터 예산 \u001b[3mm\u001b[0m으로 최대 정렬 성능 \u001b[3mQ\u001b[0m를 달성하는 전략.                                       \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m수식:                                                                                                        \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0m$$                                                                                                           \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0m\\pi^{*} = \\arg\\max_{\\pi} Q(S_{\\pi}^{(m)})                                                                    \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0m$$                                                                                                           \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[3m해석\u001b[0m: 가능한 모든 전략(π) 중에서 \u001b[3mm\u001b[0m개의 데이터로 학습했을 때 가장 높은 성능(\u001b[3mQ\u001b[0m)을 내는 전략을 선택합니다.      \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                                     \u001b[1m핵심 개념\u001b[0m                                                     \n",
       "\n",
       "\u001b[1;33m 1 \u001b[0m\u001b[1m데이터 예산(Data Budget, \u001b[0m\u001b[1;3mm\u001b[0m\u001b[1m)\u001b[0m:                                                                                    \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m사용할 데이터 샘플 수. 모델 학습에 소요되는 계산 자원과 비례합니다.                                          \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[3m예시\u001b[0m: 6,000개의 데이터만으로도 우수한 성능을 내는 것이 목표일 때, \u001b[3mm=6,000\u001b[0m.                                   \n",
       "\u001b[1;33m 2 \u001b[0m\u001b[1m정렬 성능(\u001b[0m\u001b[1;3mQ\u001b[0m\u001b[1m)\u001b[0m:                                                                                                   \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m지시 튜닝 후 모델이 보이는 성능 지표(예: MT-Bench, AlpacaEval 점수).                                         \n",
       "\u001b[1;33m 3 \u001b[0m\u001b[1m측정 지표의 역할\u001b[0m:                                                                                               \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m데이터 샘플의 \u001b[1m복잡성, 품질, 다양성\u001b[0m 등을 정량화하여, 어떤 데이터가 \u001b[3mQ\u001b[0m를 높이는지 판단하는 기준으로 사용됩니다. \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                                    \u001b[1m연구의 방향\u001b[0m                                                    \n",
       "\n",
       "\u001b[1;33m • \u001b[0m이론적 프레임워크를 바탕으로, 다양한 측정 지표와 선택 전략을 실험적으로 탐구합니다.                             \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[3m예시 실험 과정\u001b[0m:                                                                                              \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0m\u001b[1;33m 1 \u001b[0m특정 지표(예: 복잡성 점수)로 데이터를 정렬합니다.                                                         \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0m\u001b[1;33m 2 \u001b[0m상위 \u001b[3mm\u001b[0m개 데이터를 선택해 지시 튜닝을 수행합니다.                                                          \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0m\u001b[1;33m 3 \u001b[0m결과 성능(\u001b[3mQ\u001b[0m)을 비교하여 해당 지표의 유효성을 검증합니다.                                                  \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                                       \u001b[1m의의\u001b[0m                                                        \n",
       "\n",
       "\u001b[1;33m • \u001b[0m데이터 선택 문제를 \u001b[1m수학적 최적화 문제\u001b[0m로 명확히 정의함으로써,                                                    \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m체계적인 데이터 선별 전략 수립의 기반을 마련했습니다.                                                        \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m후속 섹션(§2.3-2.5)에서 제안된 복잡성, 품질, 다양성 지표가 \u001b[3mQ\u001b[0m와 어떻게 연관되는지 분석할 수 있는 토대를       \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0m제공합니다.                                                                                                  \n",
       "\u001b[1;33m • \u001b[0m이 프레임워크는 \u001b[1mDEITA\u001b[0m 모델 개발 시 데이터 효율성을 극대화하는 데 직접적으로 활용됩니다.                         \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "\n",
       "                                              \u001b[1;4m2.2 EXPERIMENTAL SETUP\u001b[0m                                               \n",
       "\n",
       "\u001b[1m2.2 실험 설계 (EXPERIMENTAL SETUP) 설명\u001b[0m                                                                            \n",
       "이 섹션에서는 데이터 측정 지표의 효과를 검증하기 위한 \u001b[1m체계적인 실험 절차\u001b[0m를 소개합니다. 핵심은 \u001b[1m3단계 프레임워크\u001b[0m를   \n",
       "통해 각 지표의 유효성을 평가하는 것입니다:                                                                         \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                                  \u001b[1m실험 프레임워크\u001b[0m                                                  \n",
       "\n",
       "\u001b[1;33m 1 \u001b[0m\u001b[1m데이터 선별\u001b[0m: 특정 측정 지표(예: 복잡성)를 기반으로 데이터 풀에서 \u001b[3mm=6,000개\u001b[0m 샘플을 선택합니다.                   \n",
       "\u001b[1;33m 2 \u001b[0m\u001b[1m모델 미세 조정\u001b[0m: 선별된 데이터로 LLaMA-1 13B 모델을 지시 튜닝합니다.                                             \n",
       "\u001b[1;33m 3 \u001b[0m\u001b[1m성능 평가\u001b[0m: MT-Bench 점수를 통해 모델의 \u001b[1m지시 수행 능력\u001b[0m을 측정합니다.                                             \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                                  \u001b[1m데이터 풀 구성\u001b[0m                                                   \n",
       "\n",
       "두 가지 유형의 데이터 풀을 구축해 다양한 실제 시나리오를 모의합니다:                                               \n",
       "\n",
       "\u001b[1;33m 1 \u001b[0m\u001b[1mX_sota (고품질 데이터 풀)\u001b[0m                                                                                       \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1m목적\u001b[0m: 이미 우수한 데이터 풀에서 \u001b[1m효율성 극대화\u001b[0m 가능성 탐구.                                                   \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1m구성\u001b[0m: WizardLM, UltraChat 등 SOTA 모델의 학습 데이터를 통합 (총 300K 샘플).                                  \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1m특징\u001b[0m: 복잡성, 다양성, 품질이 모두 높음.                                                                      \n",
       "\u001b[1;33m 2 \u001b[0m\u001b[1mX_base (저품질 데이터 풀)\u001b[0m                                                                                       \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1m목적\u001b[0m: 실제 환경에서 흔히 접하는 \u001b[1m저품질/중복 데이터\u001b[0m 대응 전략 검증.                                           \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1m구성\u001b[0m: Alpaca, Dolly 등 기본 데이터셋 통합 (총 100K 샘플).                                                    \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1m특징\u001b[0m: 응답 길이 짧고, 주제/형식 다양성 낮음.                                                                 \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                                 \u001b[1m학습 및 평가 설정\u001b[0m                                                 \n",
       "\n",
       "\u001b[1;33m • \u001b[0m\u001b[1m모델\u001b[0m: LLaMA-1 13B (고정된 하이퍼파라미터 사용, 부록 A 참조).                                                    \n",
       "\u001b[1;33m • \u001b[0m\u001b[1m데이터 예산\u001b[0m: \u001b[3mm=6,000\u001b[0m 샘플.                                                                                      \n",
       "\u001b[1;33m • \u001b[0m\u001b[1m평가 지표\u001b[0m: \u001b[1mMT-Bench\u001b[0m (다중 회차 대화 평가, GPT-4가 응답 점수화).                                                 \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                            \u001b[1m복잡성 측정 지표 비교 결과\u001b[0m                                             \n",
       "\n",
       "표 2는 다양한 복잡성 지표로 선별된 데이터로 학습한 모델의 MT-Bench 점수를 보여줍니다.                              \n",
       "\n",
       "                                                     \u001b[1;2m주요 결과\u001b[0m                                                     \n",
       "\n",
       "\u001b[1;33m 1 \u001b[0m\u001b[1mEVOL COMPLEXITY의 우수성\u001b[0m:                                                                                       \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mX_sota: \u001b[1m6.27점\u001b[0m (최고 성능).                                                                                  \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mX_base: \u001b[1m5.57점\u001b[0m (기존 방법 대비 큰 격차).                                                                     \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1m강점\u001b[0m: 데이터 품질에 관계없이 \u001b[1m강건한 성능\u001b[0m 발휘.                                                               \n",
       "\u001b[1;33m 2 \u001b[0m\u001b[1m기존 방법의 한계\u001b[0m                                                                                                \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1mInstruction Length (지시 길이)\u001b[0m: 긴 지시문 ≠ 고복잡성 (X_base 4.00점).                                        \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1mPerplexity (응답 혼란도)\u001b[0m: 낮은 성능 (X_sota 4.06점) → 짧은 응답 샘플 선별 경향성 문제.                       \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1mDirect Scoring/Instruction Node\u001b[0m: ChatGPT 주석 비용高 → 50K 샘플 제한 시 성능 하락.                           \n",
       "\u001b[1;33m 3 \u001b[0m\u001b[1mEVOL COMPLEXITY의 혁신성\u001b[0m                                                                                        \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1m진화 기반 평가\u001b[0m: 단일 데이터를 점진적 복잡성 변형 → ChatGPT로 세밀한 점수화.                                  \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1m자동 점수 판별기\u001b[0m: 소량 시드 데이터 학습 → 대규모 데이터에 확장 적용 가능.                                    \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                                   \u001b[1m결론적 시사점\u001b[0m                                                   \n",
       "\n",
       "\u001b[1;33m • \u001b[0m\u001b[1m데이터 복잡성 ≠ 단순 길이/혼란도\u001b[0m: 질적 진화와 세밀한 평가가 필수적.                                             \n",
       "\u001b[1;33m • \u001b[0m\u001b[1mEVOL 기법의 효용성\u001b[0m: 비용 효율적이며, 다양한 데이터 환경에서 일관된 성능 확보.                                   \n",
       "\u001b[1;33m • \u001b[0m\u001b[1m실용적 프레임워크\u001b[0m: 제한된 자원으로 고성능 모델 구축 가능성 입증.                                                \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "\n",
       "                                  \u001b[1;4m2.4 FROM THE QUALITY PERSPECTIVE – EVOL QUALITY\u001b[0m                                  \n",
       "\n",
       "\u001b[1m2.4 품질 관점 – EVOL QUALITY\u001b[0m                                                                                       \n",
       "이 섹션은 지시 튜닝 데이터의 \u001b[1m품질(Quality)\u001b[0m 측정 방법을 탐구하며, 특히 \u001b[1mEVOL QUALITY\u001b[0m 기법을 제안합니다. 핵심 내용은  \n",
       "다음과 같습니다:                                                                                                   \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                                \u001b[1m품질 측정의 중요성\u001b[0m                                                 \n",
       "\n",
       "\u001b[1;33m • \u001b[0m\u001b[1m목표\u001b[0m: 정확성, 상세성, 유용성이 높은 응답을 생성하는 모델 개발.                                                  \n",
       "\u001b[1;33m • \u001b[0m\u001b[1m문제 인식\u001b[0m:                                                                                                      \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m저품질 데이터(모호한 답변, 오류 포함)는 모델 성능을 크게 저하시킵니다.                                       \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m기존 방법(예: 응답 길이)은 품질을 정확히 반영하지 못함.                                                      \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                                \u001b[1m품질 측정 방법 비교\u001b[0m                                                \n",
       "\n",
       "\u001b[1;33m 1 \u001b[0m\u001b[1mRandom Selection (무작위 선택)\u001b[0m: 기준 없이 샘플링.                                                               \n",
       "\u001b[1;33m 2 \u001b[0m\u001b[1mResponse Length (응답 길이)\u001b[0m: 긴 응답 = 고품질 가정.                                                             \n",
       "\u001b[1;33m 3 \u001b[0m\u001b[1mDirect Scoring (직접 점수화)\u001b[0m: ChatGPT로 응답 정확성 평가 (고비용).                                              \n",
       "\u001b[1;33m 4 \u001b[0m\u001b[1mEVOL QUALITY (제안 방법)\u001b[0m:                                                                                       \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1m진화 기반 품질 향상\u001b[0m:                                                                                         \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0m\u001b[1;33m 1 \u001b[0m원본 데이터 $(I_k^{(0)}, R_k^{(0)})$에 대해 ChatGPT가 응답을 \u001b[1m품질 향상 방향\u001b[0m으로 변형 (예: 세부 정보 추가, \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0m창의성 강화).                                                                                             \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0m\u001b[1;33m 2 \u001b[0m5회 변형을 거쳐 다양한 품질의 응답 집합 ${R_k^{(0)}, ..., R_k^{(5)}}$ 생성.                               \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1mChatGPT 순위/점수화\u001b[0m:                                                                                         \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m동일 지시문에 대한 변형 응답들을 비교하여 세밀한 품질 점수($q$) 부여.                                     \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1m자동 점수 판별기 학습\u001b[0m:                                                                                       \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mLLaMA-1 7B 모델을 미세 조정해 품질 점수 예측.                                                             \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                                 \u001b[1m실험 결과 (표 3)\u001b[0m                                                  \n",
       "\n",
       "\u001b[1;33m • \u001b[0m\u001b[1mX_sota (고품질 풀)\u001b[0m:                                                                                             \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mEVOL QUALITY \u001b[1m6.19점\u001b[0m (Random 5.84점 대비 우수).                                                               \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m고품질 풀에서는 응답 길이 영향 적음 (5.94점).                                                                \n",
       "\u001b[1;33m • \u001b[0m\u001b[1mX_base (저품질 풀)\u001b[0m:                                                                                             \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mEVOL QUALITY \u001b[1m5.67점\u001b[0m (Random 4.93점 대비 큰 격차).                                                            \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m품질 지표가 저품질 풀에서 더 큰 성능 향상 기여.                                                              \n",
       "\n",
       "\u001b[1m결론\u001b[0m:                                                                                                              \n",
       "\n",
       "\u001b[1;33m • \u001b[0mEVOL QUALITY는 \u001b[1m데이터 품질 편차가 큰 환경\u001b[0m에서 특히 효과적.                                                      \n",
       "\u001b[1;33m • \u001b[0mChatGPT 주석 의존도 낮춰 비용 효율성 확보.                                                                      \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "\u001b[1m2.5 다양성 관점 – 임베딩 기반 접근법\u001b[0m                                                                               \n",
       "이 섹션은 데이터 \u001b[1m다양성(Diversity)\u001b[0m 측정 및 선택 전략을 다룹니다.                                                   \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                                  \u001b[1m다양성의 중요성\u001b[0m                                                  \n",
       "\n",
       "\u001b[1;33m • \u001b[0m\u001b[1m목표\u001b[0m: 다양한 주제/형식의 요청 처리 능력 확보.                                                                   \n",
       "\u001b[1;33m • \u001b[0m\u001b[1m문제 인식\u001b[0m: 실제 데이터는 중복성 높음 → 다양성 보장 필수.                                                        \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                               \u001b[1m다양성 측정 방법 비교\u001b[0m                                               \n",
       "\n",
       "\u001b[1;33m 1 \u001b[0m\u001b[1mRandom Selection\u001b[0m: 다양성 무시.                                                                                  \n",
       "\u001b[1;33m 2 \u001b[0m\u001b[1mInstag Diversity (태그 기반)\u001b[0m:                                                                                   \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m데이터에 의미론적 태그 부여 → 태그 집합의 성장으로 다양성 측정.                                              \n",
       "\u001b[1;33m 3 \u001b[0m\u001b[1mRepr Filter (제안 방법, 임베딩 기반)\u001b[0m:                                                                           \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1mLLaMA-1 13B 임베딩\u001b[0m 활용:                                                                                     \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0m\u001b[1;33m 1 \u001b[0m데이터 샘플을 벡터로 변환.                                                                                \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0m\u001b[1;33m 2 \u001b[0m\u001b[1m코사인 거리\u001b[0m 계산 → 기존 선택 집합($S$)과의 유사도 평가.                                                   \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1m반복적 선택 프로세스\u001b[0m:                                                                                        \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m임계값($\\tau=0.9$) 미만 시 샘플 추가 → $S$의 다양성 유지.                                                 \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1m복잡성/품질 점수 선정렬\u001b[0m: 우수한 샘플 우선 검토.                                                              \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                                 \u001b[1m실험 결과 (표 4)\u001b[0m                                                  \n",
       "\n",
       "\u001b[1;33m • \u001b[0m\u001b[1mX_sota\u001b[0m:                                                                                                         \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mRepr Filter \u001b[1m6.17점\u001b[0m (Instag Diversity 6.10점 대비 소폭 우위).                                                 \n",
       "\u001b[1;33m • \u001b[0m\u001b[1mX_base\u001b[0m:                                                                                                         \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mRepr Filter \u001b[1m4.68점\u001b[0m (Instag Diversity 4.46점 대비 성능 개선).                                                 \n",
       "\n",
       "\u001b[1m결론\u001b[0m:                                                                                                              \n",
       "\n",
       "\u001b[1;33m • \u001b[0m임베딩 기반 접근법이 \u001b[1m태그 기반 방법보다 강건함\u001b[0m.                                                                 \n",
       "\u001b[1;33m • \u001b[0m다양성 보장 시 무작위 선택 대비 성능 향상 필수적.                                                               \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                                    \u001b[1m종합 시사점\u001b[0m                                                    \n",
       "\n",
       "\u001b[1;33m • \u001b[0m\u001b[1m품질, 복잡성, 다양성\u001b[0m의 3축 데이터 측정이 모델 정렬 성능을 결정.                                                 \n",
       "\u001b[1;33m • \u001b[0m\u001b[1mEVOL 기법\u001b[0m과 \u001b[1m임베딩 필터링\u001b[0m을 결합해 자동화된 고효율 데이터 선택 가능 → DEITA 모델의 성공적 구현.                 \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "\n",
       "                             \u001b[1;4m3 DEITA– DATA EFFICIENT INSTRUCTION TUNING FOR ALIGNMENT\u001b[0m                              \n",
       "\n",
       "\u001b[1m3. DEITA – 데이터 효율적 지시 튜닝을 위한 정렬\u001b[0m                                                                     \n",
       "이 섹션에서는 복잡성(Complexity), 품질(Quality), 다양성(Diversity)의 \u001b[1m3가지 차원을 통합\u001b[0m하여 최적의 데이터를 선별하는\n",
       "방법론 \u001b[1mDEITA\u001b[0m를 제안합니다. DEITA는 적은 양의 데이터로도 고성능 모델을 구축하는 것을 목표로 합니다.                 \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                             \u001b[1mDEITA의 데이터 선택 전략\u001b[0m                                              \n",
       "\n",
       "\u001b[1;33m 1 \u001b[0m\u001b[1m3차원 통합 접근법\u001b[0m:                                                                                              \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1m복잡성\u001b[0m: EVOL COMPLEXITY로 측정된 점수를 기반으로 고난이도 데이터 우선 선정.                                  \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1m품질\u001b[0m: EVOL QUALITY 점수를 통해 정확성과 유용성이 높은 응답을 가진 데이터 필터링.                             \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1m다양성\u001b[0m: 임베딩 기반 \u001b[1mRepr Filter\u001b[0m를 적용해 중복성을 제거하고 주제/형식 다양성 보장.                            \n",
       "\u001b[1;33m 2 \u001b[0m\u001b[1m선별 프로세스\u001b[0m:                                                                                                  \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1m단계적 필터링\u001b[0m:                                                                                               \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0m\u001b[1;33m 1 \u001b[0m\u001b[1m복잡성 + 품질 점수\u001b[0m로 상위 데이터 추출.                                                                    \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0m\u001b[1;33m 2 \u001b[0m\u001b[1m다양성 필터링\u001b[0m: 임베딩 유사도 분석을 통해 중복 데이터 제거.                                                \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1m우선순위 정렬\u001b[0m: 복잡성과 품질이 높은 데이터를 우선 검토한 후, 다양성을 확보하기 위해 반복적 선택 수행.        \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                                  \u001b[1mDEITA 모델 학습\u001b[0m                                                  \n",
       "\n",
       "\u001b[1;33m • \u001b[0m\u001b[1m기반 모델\u001b[0m: LLaMA 및 Mistral 모델을 사전 학습된 모델로 사용.                                                     \n",
       "\u001b[1;33m • \u001b[0m\u001b[1m학습 데이터\u001b[0m: 상기 전략으로 선별된 \u001b[1m6,000개의 SFT 데이터\u001b[0m만 활용.                                                  \n",
       "\u001b[1;33m • \u001b[0m\u001b[1m성능\u001b[0m:                                                                                                           \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1mDEITA-Mistral-7B\u001b[0m: 6K SFT 데이터로 \u001b[1mMT-Bench 7.22점\u001b[0m, \u001b[1mAlpacaEval 80.78%\u001b[0m 달성.                                   \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1mDPO 추가 학습 시\u001b[0m: 6K SFT + 10K DPO 데이터로 \u001b[1mMT-Bench 7.55점\u001b[0m, \u001b[1mAlpacaEval 90.06%\u001b[0m 기록.                         \n",
       "\u001b[1;33m • \u001b[0m\u001b[1m효율성\u001b[0m: 기존 모델 대비 \u001b[1m10배 이상 적은 데이터\u001b[0m로 동등/우수한 성능 구현.                                           \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                                   \u001b[1m의의 및 기여\u001b[0m                                                    \n",
       "\n",
       "\u001b[1;33m 1 \u001b[0m\u001b[1m과학적 데이터 선별\u001b[0m:                                                                                             \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m복잡성, 품질, 다양성의 체계적 측정을 통해 경험적 방법의 한계 극복.                                           \n",
       "\u001b[1;33m 2 \u001b[0m\u001b[1m리소스 효율성\u001b[0m:                                                                                                  \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m대량 데이터 수집/주석 비용 절감 및 학습 시간 단축.                                                           \n",
       "\u001b[1;33m 3 \u001b[0m\u001b[1m오픈소스 공개\u001b[0m:                                                                                                  \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m선별된 데이터셋과 모델을 공개해 연구 재현성 및 후속 연구 지원.                                               \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                                       \u001b[1m결론\u001b[0m                                                        \n",
       "\n",
       "DEITA는 \u001b[1m데이터 효율성\u001b[0m과 \u001b[1m모델 성능\u001b[0m 간의 균형을 최적화하는 프레임워크로, LLM 정렬에 필요한 데이터 선택의 과학적      \n",
       "기준을 제시했습니다. 이 접근법은 향후 모델 개발 시 자원 제약 문제를 해결하는 데 기여할 것으로 기대됩니다.          \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "\n",
       "                                                    \u001b[1;4m3.1 METHOD\u001b[0m                                                     \n",
       "\n",
       "\u001b[1m3.1 방법론 (METHOD) 설명\u001b[0m                                                                                           \n",
       "(참고: 원문에 내용이 누락된 것으로 보이지만, 논문의 흐름과 이전 섹션들을 바탕으로 \u001b[1m추론된 설명\u001b[0m을 제공합니다.)       \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                             \u001b[1mDEITA 방법론의 핵심 단계\u001b[0m                                              \n",
       "\n",
       "DEITA는 복잡성(Complexity), 품질(Quality), 다양성(Diversity)의 \u001b[1m3가지 차원을 종합\u001b[0m하여 데이터를 선택하고, 이를       \n",
       "바탕으로 고효율 지시 튜닝을 수행합니다. 구체적인 단계는 다음과 같습니다:                                           \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                             \u001b[1;2m1. 데이터 측정 및 점수화\u001b[0m                                              \n",
       "\n",
       "\u001b[1;33m 1 \u001b[0m\u001b[1m복잡성 점수 (Complexity Score)\u001b[0m:                                                                                 \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1mEVOL COMPLEXITY\u001b[0m 기법을 사용해 각 데이터 샘플의 복잡성을 측정합니다.                                          \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mChatGPT로 생성된 변형 예시의 순위와 점수를 학습해 자동 복잡성 판별기를 구축합니다.                           \n",
       "\u001b[1;33m 2 \u001b[0m\u001b[1m품질 점수 (Quality Score)\u001b[0m:                                                                                      \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1mEVOL QUALITY\u001b[0m 기법을 적용해 응답의 정확성과 유용성을 평가합니다.                                              \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m동일한 지시문에 대한 다양한 품질의 응답을 비교하여 세밀한 점수화를 수행합니다.                               \n",
       "\u001b[1;33m 3 \u001b[0m\u001b[1m다양성 점수 (Diversity Score)\u001b[0m:                                                                                  \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1m임베딩 기반 Repr Filter\u001b[0m를 활용해 데이터 간 유사도를 계산합니다.                                              \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mLLaMA 모델의 임베딩 공간에서 코사인 거리를 측정하여 중복성을 제거합니다.                                     \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                                \u001b[1;2m2. 데이터 선별 전략\u001b[0m                                                \n",
       "\n",
       "\u001b[1;33m 1 \u001b[0m\u001b[1m우선순위 정렬\u001b[0m:                                                                                                  \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m복잡성과 품질 점수를 종합해 상위 데이터를 선별합니다.                                                        \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m예: 복잡성 점수 × 품질 점수의 가중합으로 순위 결정.                                                          \n",
       "\u001b[1;33m 2 \u001b[0m\u001b[1m다양성 필터링\u001b[0m:                                                                                                  \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m선정된 상위 데이터 집합에 대해 \u001b[1m임베딩 유사도 분석\u001b[0m을 수행합니다.                                              \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m임계값(τ=0.9)을 초과하는 중복 샘플을 제거하며, 최종 6K 데이터 선택.                                          \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                               \u001b[1;2m3. 모델 학습 및 평가\u001b[0m                                                \n",
       "\n",
       "\u001b[1;33m 1 \u001b[0m\u001b[1m모델 미세 조정\u001b[0m:                                                                                                 \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m선별된 데이터로 LLaMA 또는 Mistral 모델을 지시 튜닝합니다.                                                   \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m고정된 하이퍼파라미터를 사용해 재현성 보장 (부록 A 참조).                                                    \n",
       "\u001b[1;33m 2 \u001b[0m\u001b[1m성능 평가\u001b[0m:                                                                                                      \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1mMT-Bench\u001b[0m, \u001b[1mAlpacaEval\u001b[0m, \u001b[1mOpen LLM Leaderboard\u001b[0m에서 성능을 측정합니다.                                            \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mGPT-4를 평가자로 활용해 응답의 유용성과 정확성을 점수화합니다.                                               \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                                       \u001b[1m의의\u001b[0m                                                        \n",
       "\n",
       "\u001b[1;33m • \u001b[0m\u001b[1m통합 프레임워크\u001b[0m: 3가지 차원의 측정 지표를 조합해 데이터 효율성을 극대화합니다.                                  \n",
       "\u001b[1;33m • \u001b[0m\u001b[1m계층적 선택\u001b[0m: 복잡성/품질 → 다양성 순의 단계적 필터링으로 최적화된 데이터셋 구축.                                \n",
       "\u001b[1;33m • \u001b[0m\u001b[1m확장성\u001b[0m: 다른 LLM 및 데이터셋에 적용 가능한 일반적인 방법론을 제시합니다.                                        \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "이 방법론은 \u001b[1mDEITA 모델\u001b[0m의 우수한 성능(§3 결과 섹션 참조)을 가능하게 한 핵심 기여로, 적은 데이터로도 고품질 정렬을   \n",
       "달성하는 과학적 접근법을 구현합니다.                                                                               \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "\n",
       "                              \u001b[1;4mAlgorithm 1 Score-First, Diversity-Aware Data Selection\u001b[0m                              \n",
       "\n",
       "\u001b[1m알고리즘 1: 점수 우선, 다양성 고려 데이터 선택 (Score-First, Diversity-Aware Data Selection)\u001b[0m                       \n",
       "\n",
       "이 알고리즘은 **복잡성(Complexity)**과 \u001b[1m품질(Quality)\u001b[0m 점수를 기반으로 데이터를 우선순위화한 후,                     \n",
       "**다양성(Diversity)**을 보장하기 위해 중복 샘플을 제거하는 과정을 체계적으로 결합합니다.                           \n",
       "DEITA 모델의 데이터 효율적 학습을 위해 설계되었으며, 주요 단계는 다음과 같습니다:                                  \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                                \u001b[1m알고리즘 단계 설명\u001b[0m                                                 \n",
       "\n",
       "\u001b[1;33m 1 \u001b[0m\u001b[1m입력\u001b[0m:                                                                                                           \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m데이터 풀 ( X ): 지시-응답 쌍으로 구성된 대규모 데이터 집합.                                                 \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m데이터 예산 ( m ): 선택할 샘플 수 (예: 6,000개).                                                             \n",
       "\u001b[1;33m 2 \u001b[0m\u001b[1m출력\u001b[0m:                                                                                                           \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m선별된 데이터 부분집합 ( S_{\\pi_{\\mathrm{DEITA}}}^{(m)} ).                                                   \n",
       "\u001b[1;33m 3 \u001b[0m\u001b[1m초기화\u001b[0m:                                                                                                         \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m빈 데이터셋 ( S ) 생성.                                                                                      \n",
       "\u001b[1;33m 4 \u001b[0m\u001b[1m점수 계산 및 정렬\u001b[0m:                                                                                              \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m각 샘플의 **복잡성 점수(( c ))**와 **품질 점수(( q ))**를 곱해 종합 점수 ( s = c \\times q ) 계산.            \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m( s )를 기준으로 데이터 풀 ( X )를 내림차순 정렬 → ( X^* ).                                                  \n",
       "\u001b[1;33m 5 \u001b[0m\u001b[1m반복적 선택 및 다양성 필터링\u001b[0m:                                                                                   \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m정렬된 ( X^* )의 샘플을 순차적으로 검토:                                                                     \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1m단계 7-8\u001b[0m: 현재 샘플 ( x )와 ( S ) 내 가장 가까운 샘플 간 \u001b[1m임베딩 거리\u001b[0m 계산.                                \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1mLLaMA-1 13B\u001b[0m 모델로 임베딩 추출 → \u001b[1m코사인 거리\u001b[0m 측정.                                                     \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1m단계 9-12\u001b[0m: 거리가 임계값 ( \\tau=0.9 ) 미만이면 ( S )에 추가 (중복으로 판단해 제외).                       \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1m단계 14-16\u001b[0m: ( S )의 크기가 ( m )에 도달하면 종료.                                                         \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                                     \u001b[1m핵심 개념\u001b[0m                                                     \n",
       "\n",
       "\u001b[1;33m 1 \u001b[0m\u001b[1mEvol Score (( s = c \\times q ))\u001b[0m:                                                                                \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m복잡성과 품질을 동시에 반영한 종합 점수.                                                                     \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m높은 ( s )를 가진 샘플은 \u001b[1m난이도 높고 정확한 응답\u001b[0m을 가짐.                                                     \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1m다중 회차 대화\u001b[0m에서는 각 회차별 점수를 합산해 전체 점수 계산.                                                 \n",
       "\u001b[1;33m 2 \u001b[0m\u001b[1mRepr Filter (임베딩 기반 필터링)\u001b[0m:                                                                               \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1mLLaMA 임베딩\u001b[0m을 사용해 샘플 간 의미적 유사도 측정.                                                            \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m코사인 거리 ( d(x, S) )가 임계값 ( \\tau=0.9 )보다 작으면 중복으로 판단 → 제외.                               \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1m계층적 선택\u001b[0m: 우수한 샘플을 우선 검토한 후, 다양성 보장을 위해 필터링.                                        \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                                  \u001b[1mDEITA 모델 학습\u001b[0m                                                  \n",
       "\n",
       "\u001b[1;33m • \u001b[0m\u001b[1m학습 데이터\u001b[0m: 알고리즘으로 선별된 ( m )개 샘플 (예: 6K).                                                         \n",
       "\u001b[1;33m • \u001b[0m\u001b[1m기반 모델\u001b[0m: LLaMA-1-13B, LLaMA-2-13B, Mistral-7B 등.                                                             \n",
       "\u001b[1;33m • \u001b[0m\u001b[1m학습 세부사항\u001b[0m: 고정된 하이퍼파라미터 사용 (부록 A 참조).                                                        \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                                       \u001b[1m의의\u001b[0m                                                        \n",
       "\n",
       "\u001b[1;33m • \u001b[0m\u001b[1m효율성\u001b[0m: 복잡성/품질 점수 정렬 + 다양성 필터링으로 \u001b[1m적은 데이터로 고성능 달성\u001b[0m.                                    \n",
       "\u001b[1;33m • \u001b[0m\u001b[1m과학적 데이터 선택\u001b[0m: 경험적 방법 대신 체계적 지표 기반 접근.                                                     \n",
       "\u001b[1;33m • \u001b[0m\u001b[1m확장성\u001b[0m: 다른 LLM 및 데이터셋에 적용 가능한 일반화된 프레임워크.                                                 \n",
       "\n",
       "이 알고리즘은 DEITA 모델이 \u001b[1m10배 이상 적은 데이터\u001b[0m로도 SOTA 성능을 내는 데 기여한 핵심 메커니즘입니다.               \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "\n",
       "                                              \u001b[1;4m3.2 EXPERIMENTAL SETUP\u001b[0m                                               \n",
       "\n",
       "\u001b[1m3.2 실험 설정 (EXPERIMENTAL SETUP) 설명\u001b[0m                                                                            \n",
       "이 섹션에서는 DEITA 모델의 학습 및 평가를 위한 구체적인 실험 환경을 설명합니다. 주요 내용은 다음과 같습니다:       \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                                \u001b[1m데이터 및 학습 설정\u001b[0m                                                \n",
       "\n",
       "\u001b[1;33m 1 \u001b[0m\u001b[1m데이터 예산\u001b[0m:                                                                                                    \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1m6K\u001b[0m 및 \u001b[1m10K\u001b[0m 샘플로 DEITA 모델을 각각 학습합니다.                                                               \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m데이터 풀: 고품질 데이터 집합인 \u001b[1mX_sota\u001b[0m에서 샘플 선별.                                                        \n",
       "\u001b[1;33m 2 \u001b[0m\u001b[1m기반 모델\u001b[0m:                                                                                                      \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1mLLaMA-1-13B\u001b[0m, \u001b[1mLLaMA-2-13B\u001b[0m, \u001b[1mMistral-7B\u001b[0m를 기본 모델로 사용합니다.                                               \n",
       "\u001b[1;33m 3 \u001b[0m\u001b[1m학습 방법\u001b[0m:                                                                                                      \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m**지시 튜닝(SFT)**에 집중: 데이터 선택 전략의 효과를 명확히 분석하기 위해 RLHF 대신 SFT만 적용.              \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m추가 실험: 최고 성능 SFT 모델에 **DPO(Direct Preference Optimization)**를 적용해 성능 향상 확인.             \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mDPO 데이터: \u001b[1mUltraFeedback\u001b[0m 데이터셋에서 추출한 10K 비교 쌍 사용.                                           \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                                   \u001b[1m평가 벤치마크\u001b[0m                                                   \n",
       "\n",
       "\u001b[1;33m 1 \u001b[0m\u001b[1mMT-Bench\u001b[0m:                                                                                                       \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m다중 회차 대화 평가 (글쓰기, 추론, 코딩 등).                                                                 \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mGPT-4가 응답 품질을 점수화.                                                                                  \n",
       "\u001b[1;33m 2 \u001b[0m\u001b[1mAlpacaEval\u001b[0m:                                                                                                     \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m지시 수행 능력 평가.                                                                                         \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m인간 평가자 또는 GPT-4가 응답의 유용성과 정확성을 평가.                                                      \n",
       "\u001b[1;33m 3 \u001b[0m\u001b[1mOpen LLM Leaderboard\u001b[0m:                                                                                           \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m4가지 분류 과제로 구성:                                                                                      \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1mARC\u001b[0m: 과학적 추론 능력.                                                                                    \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1mHellaSwag\u001b[0m: 상식 추론.                                                                                     \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1mMMLU\u001b[0m: 다학제적 지식 이해.                                                                                 \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1mTruthfulQA\u001b[0m: 사실 기반 응답 정확성.                                                                        \n",
       "\u001b[1;33m 4 \u001b[0m\u001b[1m인간 평가\u001b[0m: 부록 D에서 추가 결과 제공.                                                                           \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                                  \u001b[1m비교 대상 모델\u001b[0m                                                   \n",
       "\n",
       "\u001b[1;33m 1 \u001b[0m\u001b[1m데이터 선택 기법 비교\u001b[0m:                                                                                          \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1mLIMA\u001b[0m, \u001b[1mAlpagasus\u001b[0m, \u001b[1mTAGLM\u001b[0m과 DEITA의 성능 차이 분석.                                                             \n",
       "\u001b[1;33m 2 \u001b[0m\u001b[1m오픈소스 SOTA 모델 비교\u001b[0m:                                                                                        \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1mVicuna\u001b[0m, \u001b[1mWizardLM\u001b[0m, \u001b[1mMistral-Instruct\u001b[0m, \u001b[1mZephyr\u001b[0m 등과 성능 경쟁력 평가.                                            \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                                     \u001b[1m실험 목적\u001b[0m                                                     \n",
       "\n",
       "\u001b[1;33m 1 \u001b[0m\u001b[1m데이터 선택 전략 검증\u001b[0m:                                                                                          \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m제안된 복잡성-품질-다양성 통합 전략이 기존 방법 대비 우수함을 입증.                                          \n",
       "\u001b[1;33m 2 \u001b[0m\u001b[1m모델 확장성 확인\u001b[0m:                                                                                               \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m다양한 기반 모델(LLaMA-1, LLaMA-2, Mistral)에서 DEITA의 일반화 가능성 검토.                                  \n",
       "\u001b[1;33m 3 \u001b[0m\u001b[1mDPO 효과 분석\u001b[0m:                                                                                                  \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mSFT 후 DPO 적용 시 최종 성능 향상 정도 측정.                                                                 \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                                       \u001b[1m의의\u001b[0m                                                        \n",
       "\n",
       "\u001b[1;33m • \u001b[0mDEITA의 \u001b[1m데이터 효율성\u001b[0m과 \u001b[1m범용성\u001b[0m을 다각도로 입증하기 위한 체계적 실험 설계.                                       \n",
       "\u001b[1;33m • \u001b[0m오픈소스 LLM 생태계에서 \u001b[1m적은 데이터로 고성능 모델 구축\u001b[0m 가능성을 제시.                                           \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "\n",
       "                                                    \u001b[1;4m3.3 RESULTS\u001b[0m                                                    \n",
       "\n",
       "\u001b[1m3.3 실험 결과 (RESULTS) 설명\u001b[0m                                                                                       \n",
       "이 섹션은 DEITA 모델의 성능을 다양한 벤치마크와 기존 SOTA 모델과 비교한 결과를 제시합니다. 핵심 내용은 다음과      \n",
       "같습니다:                                                                                                          \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                                  \u001b[1m주요 비교 결과\u001b[0m                                                   \n",
       "\n",
       "                              \u001b[1;2m표 5: 데이터 선택 기법 간 성능 비교 (LLaMA-1-13B 기반)\u001b[0m                               \n",
       "\n",
       "\u001b[1;33m • \u001b[0m\u001b[1mDEITA-LLaMA1-13B (6K)\u001b[0m:                                                                                          \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1mMT-Bench 6.46\u001b[0m, **AlpacaEval 77.08%**로 모든 경쟁 방법(Random, Alpagasus, LIMA, TAGLM)을 큰 격차로 능가.      \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1mLIMA (1K 데이터)\u001b[0m 대비 MT-Bench \u001b[1m+2.17점\u001b[0m, AlpacaEval \u001b[1m+35.1%p\u001b[0m 향상.                                             \n",
       "\n",
       "                                      \u001b[1;2m표 6: 다양한 기반 모델별 SOTA 모델 비교\u001b[0m                                      \n",
       "\n",
       "\u001b[1;33m 1 \u001b[0m\u001b[1mLLaMA-1-13B 기반\u001b[0m:                                                                                               \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1mDEITA-10K\u001b[0m: MT-Bench \u001b[1m6.60\u001b[0m, AlpacaEval **78.01%**로 WizardLM(70K 데이터) 및 Vicuna(125K 데이터)보다 우수.      \n",
       "\u001b[1;33m 2 \u001b[0m\u001b[1mLLaMA-2-13B 기반\u001b[0m:                                                                                               \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1mDEITA-10K\u001b[0m: MT-Bench \u001b[1m6.79\u001b[0m, AlpacaEval **81.09%**로 RLHF 적용된 LLaMA2-Chat(>100K SFT + 1M RLHF)와 동등.       \n",
       "\u001b[1;33m 3 \u001b[0m\u001b[1mMistral-7B 기반\u001b[0m:                                                                                                \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1mDEITA-6K + DPO\u001b[0m: MT-Bench \u001b[1m7.55\u001b[0m, AlpacaEval **90.06%**로 Zephyr(200K SFT + 60K DPO)과 비슷한 성능 달성.        \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1mMistral-Instruct-v0.2\u001b[0m (비공개 데이터)에 근접한 성능.                                                         \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                         \u001b[1mOpen LLM Leaderboard 결과 (표 7)\u001b[0m                                          \n",
       "\n",
       "\u001b[1;33m • \u001b[0m\u001b[1mDEITA-Mistral-7B (6K + DPO)\u001b[0m:                                                                                    \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1m평균 69.86점\u001b[0m으로 Zephyr-beta(66.36점)를 능가.                                                                \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1mTruthfulQA 67.14점\u001b[0m, \u001b[1mARC 66.21점\u001b[0m에서 특히 뛰어남.                                                             \n",
       "\u001b[1;33m • \u001b[0m\u001b[1mDEITA-LLaMA1-13B (10K)\u001b[0m:                                                                                         \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mLIMA, WizardLM, Vicuna 등 모든 LLaMA-1 기반 모델을 큰 격차로 제치고 최고 평균 점수(\u001b[1m64.27\u001b[0m) 기록.              \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                           \u001b[1m데이터 스케일링 분석 (그림 2)\u001b[0m                                           \n",
       "\n",
       "\u001b[1;33m • \u001b[0m\u001b[1mDEITA의 효율성\u001b[0m:                                                                                                 \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1m3K 데이터\u001b[0m로 전체 300K 데이터 사용 시와 동등 성능 → \u001b[1m100배 데이터 효율성\u001b[0m.                                      \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m데이터 증가 시 초기 성능 상승 후 감소 → \"좋은 데이터\" 비중 제한적임을 시사.                                  \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                         \u001b[1mMT-Bench 세부 능력 분석 (그림 3)\u001b[0m                                          \n",
       "\n",
       "\u001b[1;33m • \u001b[0m\u001b[1mDEITA-Mistral\u001b[0m의 강점:                                                                                           \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1m코딩\u001b[0m, \u001b[1m수학\u001b[0m, \u001b[1m추론\u001b[0m 과제에서 탁월한 성능 → MT-Bench 고득점 주원인.                                              \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mAlpacaEval은 기본 지시 수행에 집중되므로 상대적 격차 작음.                                                   \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                                    \u001b[1m핵심 시사점\u001b[0m                                                    \n",
       "\n",
       "\u001b[1;33m 1 \u001b[0m\u001b[1m데이터 효율성\u001b[0m:                                                                                                  \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m\u001b[1m6K~10K 데이터\u001b[0m로 기존 70K~200K 데이터 기반 모델 대비 우수한 성능.                                             \n",
       "\u001b[1;33m 2 \u001b[0m\u001b[1mDPO의 시너지\u001b[0m:                                                                                                   \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mSFT 후 DPO 적용 시 성능 추가 향상 (MT-Bench \u001b[1m7.22 → 7.55\u001b[0m, AlpacaEval \u001b[1m80.78% → 90.06%\u001b[0m).                        \n",
       "\u001b[1;33m 3 \u001b[0m\u001b[1m범용성\u001b[0m:                                                                                                         \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0mLLaMA-1, LLaMA-2, Mistral 등 다양한 기반 모델에서 일관된 우수성 입증.                                        \n",
       "\u001b[1;33m 4 \u001b[0m\u001b[1m데이터 품질의 중요성\u001b[0m:                                                                                           \n",
       "\u001b[1;33m   \u001b[0m\u001b[1;33m • \u001b[0m고품질 데이터 선택이 양적 확장보다 성능에 더 직결됨을 실험적으로 검증.                                       \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                                       \u001b[1m결론\u001b[0m                                                        \n",
       "\n",
       "DEITA는 \u001b[1m데이터 선택의 과학적 접근법\u001b[0m을 통해 적은 자원으로도 SOTA 성능을 달성함으로써, LLM 정렬 분야에 새로운        \n",
       "패러다임을 제시했습니다. 특히 오픈소스 모델 생태계에서 리소스 효율적 고성능 모델 개발의 가능성을 입증했습니다.     \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rich.console import Console\n",
    "from rich.markdown import Markdown\n",
    "from rich.panel import Panel\n",
    "from rich.syntax import Syntax\n",
    "from rich.table import Table\n",
    "from typing import Dict\n",
    "import os\n",
    "\n",
    "class MarkdownPrinter:\n",
    "    def __init__(self):\n",
    "        self.console = Console()\n",
    "        \n",
    "    def print_markdown_file(self, file_path: str):\n",
    "        \"\"\"마크다운 파일을 이쁘게 출력\"\"\"\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                markdown_content = f.read()\n",
    "            \n",
    "            # 마크다운 렌더링\n",
    "            md = Markdown(markdown_content)\n",
    "            \n",
    "            # 마크다운 내용 출력\n",
    "            self.console.print(md)\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.console.print(f\"[bold red]Error reading file: {str(e)}[/]\")\n",
    "            \n",
    "    def print_sections(self, sections: Dict[str, str]):\n",
    "        \"\"\"섹션별로 구분하여 출력\"\"\"\n",
    "        for section, content in sections.items():\n",
    "            # 섹션 제목\n",
    "            self.console.print(\"\\n\")\n",
    "            self.console.print(Panel(\n",
    "                f\"[bold cyan]{section}[/]\",\n",
    "                border_style=\"cyan\"\n",
    "            ))\n",
    "            \n",
    "            # 섹션 내용\n",
    "            md = Markdown(content)\n",
    "            self.console.print(md)\n",
    "            \n",
    "            # 구분선\n",
    "            self.console.print(\"[dim]\" + \"=\"*80 + \"[/]\")\n",
    "\n",
    "printer = MarkdownPrinter()\n",
    "\n",
    "# 마크다운 파일 출력\n",
    "printer.print_markdown_file(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### **ChatGPT를 활용한 데이터 순위화 및 선별 과정**  \n",
      "본 논문(§2.3-2.4, Algorithm 1)에서는 **단일 데이터 샘플을 변형해 다중 예시를 생성**한 후, ChatGPT로 순위를 매겨 고품질 데이터를 선별합니다. 구체적 단계는 다음과 같습니다:\n",
      "\n",
      "---\n",
      "\n",
      "### **1. 단일 데이터 진화 및 다중 변형 생성**  \n",
      "1. **진화(Evolve)**:  \n",
      "   - 기존 데이터 샘플 $(I_k, R_k)$을 **EVOL-COMPLEXITY** 또는 **EVOL-QUALITY** 프롬프트로 변형합니다.  \n",
      "   - *예*: 원본 지시문 \"고양이 설명\" → \"고양이 품종의 유전적 특성 설명\" 등 **5회 변형**해 총 6개 샘플 생성.  \n",
      "\n",
      "2. **변형 예시 예시**:  \n",
      "   - 복잡성 진화: 지시문에 **추론 단계**, **전문 용어**, **제약 조건** 추가.  \n",
      "   - 품질 진화: 응답의 **정확성**, **상세성**, **유용성** 개선.  \n",
      "\n",
      "---\n",
      "\n",
      "### **2. ChatGPT 기반 순위화 및 점수 부여**  \n",
      "1. **동시 비교 평가**:  \n",
      "   - 동일 원본에서 생성된 **6개 변형 샘플**을 ChatGPT에 한 번에 제공해 **상대적 순위**와 **점수**를 부여받습니다(그림 1 참조).  \n",
      "   - *프롬프트 예시*:  \n",
      "     ```  \n",
      "     \"다음 6개 지시문을 복잡성 순서대로 1~6위로 나열하고, 각각에 1~10점을 부여하세요.\"  \n",
      "     ```  \n",
      "\n",
      "2. **세밀한 점수 차별화**:  \n",
      "   - 단일 샘플 독립 평가 대신 **변형 샘플 그룹 비교**를 통해 미세한 점수 차이 포착(§2.3, §2.4).  \n",
      "\n",
      "---\n",
      "\n",
      "### **3. 고품질 데이터셋 구축 방식**  \n",
      "1. **직접 추가가 아닌 간접 선별**:  \n",
      "   - 생성된 변형 샘플 자체를 데이터셋에 추가하지 **않습니다**.  \n",
      "   - 대신, 변형 샘플의 ChatGPT 점수로 **복잡성·품질 판별기**를 학습시킵니다(§2.3-2.4).  \n",
      "\n",
      "2. **대규모 데이터 풀 적용**:  \n",
      "   - 학습된 판별기로 기존 데이터 풀의 모든 샘플을 **자동 점수화**합니다.  \n",
      "   - 상위 점수 샘플을 **다양성 필터링**을 거쳐 최종 선별(Algorithm 1).  \n",
      "\n",
      "---\n",
      "\n",
      "### **4. 핵심 원리**  \n",
      "- **시드 데이터 활용**: 2K Alpaca 데이터로 시작해 변형 샘플 생성 → ChatGPT 점수 → 판별기 학습.  \n",
      "- **확장성**: 판별기 학습 후, **수동 주석 없이** 대규모 데이터 풀에 자동 적용 가능.  \n",
      "- **효율성**: 변형 샘플 생성 비용은 소량의 시드 데이터에 한정되며, 실제 데이터 선별은 자동화됩니다.  \n",
      "\n",
      "---\n",
      "\n",
      "### **결과 검증**  \n",
      "- **표 2,3**: EVOL 기법으로 선별된 데이터가 기존 방법 대비 **MT-Bench, AlpacaEval**에서 우수한 성능 달성.  \n",
      "- **그림 2**: 3K 데이터로 300K 전체 데이터와 동등 성능 → **100배 효율성** 입증.  \n",
      "\n",
      "이 방법은 **고품질 데이터 직접 생성**이 아닌, **기존 데이터 풀에서 과학적 기준으로 최적의 샘플을 선별**하는 접근법입니다.\n"
     ]
    }
   ],
   "source": [
    "question = \"\"\" \n",
    "데이터를 평가하기 위해 ChatGPT 를 이용해서 순위화를 한다고 하는데 그럼 여러개의 데이터를 한번에 생성하고 순위가 높은 것들을 고품질 데이터셋에 추가하는 식으로 데이터가 생성되는거? \n",
    "\"\"\"\n",
    "\n",
    "response = qa.ask_question(question)\n",
    "\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
