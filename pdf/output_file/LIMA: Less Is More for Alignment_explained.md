
## Abstract

이 논문에서는 대규모 언어 모델을 훈련하는 두 가지 주요 단계에 대해 설명하고 있습니다. 첫 번째 단계는 일반적인 표현을 학습하기 위해 원시 텍스트로부터 비지도 사전 훈련을 하는 것이고, 두 번째 단계는 최종 과제와 사용자 선호에 더 잘 맞추기 위해 대규모 지시 조정과 강화 학습을 하는 것입니다. 우리는 LIMA라는 650억 개의 매개변수를 가진 LLaMa 언어 모델을 훈련함으로써 이 두 단계의 상대적 중요성을 측정했습니다. LIMA는 강화 학습이나 인간 선호 모델링 없이 표준 감독 손실로 1,000개의 신중하게 선별된 프롬프트와 응답만으로 세밀하게 조정되었습니다. LIMA는 학습 데이터의 일부 예시만으로 특정 응답 형식을 따르는 능력을 보여주며, 여행 일정 계획이나 대체 역사 추측과 같은 복잡한 질의에도 잘 대응합니다. 더 나아가, 이 모델은 학습 데이터에 포함되지 않은 새로운 과제에도 잘 일반화하는 경향이 있습니다. 통제된 인간 연구에서는 LIMA의 응답이 43%의 경우에 GPT-4와 동등하거나 더 선호되었고, Bard와 비교했을 때는 58%, DaVinci003과 비교했을 때는 65%에 달했습니다. 이러한 결과는 대규모 언어 모델의 거의 모든 지식이 사전 훈련 시 학습되며, 모델이 고품질 출력을 생성하도록 가르치기 위해 제한된 지시 조정 데이터만 필요하다는 것을 강력히 시사합니다.

---

## 1 Introduction

이 논문은 언어 모델의 사전 훈련과 이를 통한 성능 향상에 대해 다루고 있습니다. 언어 모델은 주로 다음 토큰을 예측하도록 사전 훈련되며, 이를 통해 대부분의 언어 이해 및 생성 작업에 활용할 수 있는 범용 표현을 학습합니다. 이러한 전이에 도움을 주기 위해 다양한 방법들이 제안되었습니다. 주로 대규모 데이터셋을 활용한 지시 조정(instruction tuning)과 최근에는 인간 피드백을 활용한 강화 학습(RLHF)이 여기에 해당합니다. 하지만 이 접근법들은 ChatGPT 수준의 성능을 달성하기 위해 많은 연산 자원과 특수한 데이터가 필요합니다.

논문은 강력한 사전 훈련 언어 모델을 사용하면, 신중하게 선별된 1,000개의 훈련 예제를 사용한 세밀한 튜닝만으로도 놀라운 성능을 발휘할 수 있음을 보여줍니다. 이는 모델이 사용자와 상호작용하는 스타일이나 형식을 학습함으로써 사전 훈련 중 이미 습득한 지식과 능력을 드러낼 수 있다고 가정합니다. 이를 테스트하기 위해, 실제 사용자 프롬프트와 고품질 응답을 포함한 1,000개의 예제를 선별하였습니다. Stack Exchange와 wikiHow와 같은 커뮤니티 포럼에서 750개의 질문과 답변을 선택하고, 업무 다양성과 AI 어시스턴트의 일관된 응답 스타일을 최적화하여 250개의 프롬프트와 응답을 작성했습니다.

이 세트를 바탕으로 65B-파라미터의 LLaMa 모델인 LIMA를 세밀하게 튜닝했습니다. 최종적으로 총 75만 개의 토큰으로 구성된 1,000개의 시퀀스로 데이터를 구성했습니다. LIMA는 다양한 테스트 프롬프트를 통해 최신 언어 모델과 비교되었고, 인간 선호도 연구에서는 OpenAI의 DaVinci003과 65B-파라미터로 생성된 Alpaca 복제품을 능가했습니다. GPT-4, Claude, Bard에 비해서는 대체로 선호되지는 않았지만, 각각의 경우에서 43%, 46%, 58%의 경우에서는 LIMA의 응답이 더 좋거나 동등하다는 평가를 받았습니다.

실험 결과, 데이터 양만 늘릴 때는 효과가 급격히 줄어드는 반면, 데이터 품질을 최적화하면 큰 이득을 볼 수 있음을 알 수 있었습니다. 또한, 대화 예제가 전혀 없음에도 불구하고 LIMA는 일관된 다중 턴 대화를 구성할 수 있으며, 30개의 수작업 대화 체인을 추가하면 이 능력이 크게 향상될 수 있음을 발견했습니다. 전체적으로 이 놀라운 결과들은 사전 훈련의 힘과 대규모 지시 조정 및 강화 학습 접근법보다 그 상대적 중요성을 보여줍니다.

---

## 2 Alignment Data

이 논문에서는 '표면적 정렬 가설(Superficial Alignment Hypothesis)'을 제안합니다. 이 가설에 따르면, 모델의 지식과 능력은 거의 전적으로 사전 훈련 중에 학습되며, 정렬 과정은 사용자와 상호작용할 때 어떤 형식의 하위 분포를 사용해야 하는지를 모델에 가르치는 역할을 합니다. 만약 이 가설이 맞고, 정렬이 주로 스타일을 배우는 것과 관련 있다면, 소규모 예제 세트를 이용해 사전 훈련된 언어 모델을 충분히 튜닝할 수 있을 것입니다.

이를 위해 우리는 응답 스타일이 서로 일관되게 맞춰져 있으면서도 입력(프롬프트)이 다양한 1,000개의 데이터셋을 수집했습니다. 구체적으로, 도움이 되는 AI 어시스턴트 스타일의 출력을 목표로 합니다. 이러한 예제는 주로 커뮤니티 Q&A 포럼에서 수집한 것과 수작업으로 작성한 예제로 나뉘며, 다양한 소스에서 선별되었습니다. 또한, 300개의 프롬프트로 구성된 테스트 세트와 50개의 개발 세트도 수집했습니다. 표 1은 다양한 데이터 소스에 대한 개요를 제공하며, 몇 가지 통계 자료를 제시합니다(훈련 예제의 선택에 대한 자세한 내용은 부록 A를 참조하십시오).

---

## 2.1 Community Questions & Answers

이 논문에서는 데이터를 세 가지 커뮤니티 Q&A 웹사이트인 Stack Exchange, wikiHow, 그리고 Pushshift Reddit Dataset에서 수집합니다. Stack Exchange와 wikiHow의 답변은 도움이 되는 AI 에이전트의 행동과 잘 맞기 때문에 자동으로 수집할 수 있는 반면, Reddit의 높은 평가를 받은 답변들은 대개 유머러스하거나 장난기가 섞여 있어 적절한 스타일로 정리하기 위해서는 수작업이 필요합니다.

**Stack Exchange**: Stack Exchange는 총 179개의 온라인 커뮤니티(‘익스체인지’)로 구성되어 있으며, 가장 인기 있는 주제는 프로그래밍(예: Stack Overflow)입니다. 사용자는 질문, 답변, 댓글을 게시할 수 있으며, 다른 사용자들이 이들을 업보트(찬성)하거나 다운보트(반대)를 누를 수 있습니다. Stack Exchange는 활동적인 커뮤니티 회원과 관리자 덕분에 높은 품질의 콘텐츠를 유지하고 있습니다.

Stack Exchange에서 데이터를 샘플링할 때 품질과 다양성을 동시에 고려합니다. 먼저, STEM 익스체인지(프로그래밍, 수학, 물리학 등) 75개와 기타 익스체인지(영어, 요리, 여행 등) 99개로 나누고, 5개의 틈새 익스체인지는 제외합니다. 그런 다음 각 세트에서 균일한 샘플을 얻기 위해 온도 $\tau=3$을 설정하여 200개의 질문과 답변을 샘플링합니다. 각 익스체인지 내에서 타이틀에 의해 충분히 설명 가능한 점수가 높은 질문을 선택하고, 각 질문에 대해 강력한 긍정 점수(최소 10)를 가진 최고 답변을 선택합니다. AI 어시스턴트의 스타일에 맞추기 위해 너무 짧거나(1200자 미만), 너무 긴(4096자 초과) 답변, 1인칭으로 작성된 답변, 다른 답변을 참조하는 답변은 자동으로 필터링합니다. 또한, 링크, 이미지, 기타 HTML 태그는 제거하고 코드 블록과 목록만 남겨둡니다. Stack Exchange 질문은 제목과 설명을 모두 포함하므로, 일부 예제에서는 제목을 프롬프트로, 다른 예제에서는 설명을 프롬프트로 무작위 선택합니다.

**wikiHow**: wikiHow는 다양한 주제에 관한 240,000개 이상의 하우투(How-to) 기사를 포함하는 온라인 위키 스타일 출판 플랫폼입니다. 누구나 기여할 수 있지만, 기사는 철저히 관리되어 대부분이 높은 품질을 유지합니다. 우리는 19개 카테고리 중 하나를 먼저 샘플링하고 그 안에서 기사를 선택해 다양한 주제를 다룰 수 있도록 200개의 기사를 샘플링합니다. 제목을 프롬프트로 사용하고(예: "How to cook an omelette?"), 기사의 본문을 응답으로 사용합니다. 일반적으로 "이 기사..."로 시작하는 부분을 "다음 답변..."으로 대체하고, 링크, 이미지, 특정 텍스트 섹션을 제거하는 전처리 작업을 수행합니다.

**Pushshift Reddit Dataset**: Reddit은 전 세계적으로 인기 있는 웹사이트 중 하나이며, 사용자들이 자신의 하위 레딧(subreddit)에서 콘텐츠를 공유하고 토론하며, 투표할 수 있도록 합니다. Reddit의 특성상 다른 사용자들에게 재미를 주는 것이 목적이기 때문에, 재치 있는 댓글이 진지한 댓글보다 더 많은 투표를 받는 경우가 많습니다. 그래서 우리는 r/AskReddit과 r/WritingPrompts의 두 하위 레딧으로 샘플을 제한하고, 각 커뮤니티에서 가장 많은 투표를 받은 게시물들 중에서 수작업으로 예제를 선택합니다. r/AskReddit에서는 몸체 없이 제목만으로 완결된 70개의 프롬프트를 찾아 테스트 세트에 사용합니다. WritingPrompts 하위 레딧은 사용자가 창의적으로 완성하도록 유도하는 소설 이야기의 전제를 포함하고 있습니다. 여기에서 사랑시, 단편 SF 소설 등 다양한 주제를 포함하는 150개의 프롬프트와 고품질의 응답을 찾아 훈련 세트에 추가합니다. 모든 데이터는 Pushshift Reddit Dataset [Baumgartner et al., 2020]에서 수집되었습니다.

---

## 2.2 Manually Authored Examples

논문에서는 온라인 커뮤니티에서 사용자가 올린 질문을 넘어서는 다양한 데이터를 확보하기 위해, 저자들이 직접 프롬프트를 작성했습니다. 저자 그룹 A와 B는 각자 250개의 프롬프트를 작성했습니다. 그룹 A에서 200개의 프롬프트는 훈련용으로, 50개는 개발 세트로 사용하게 됩니다. 문제 있는 일부 프롬프트를 제거한 후, 그룹 B의 남은 230개의 프롬프트는 테스트에 사용됩니다.

훈련 프롬프트 200개에는 저자들이 직접 작성한 고품질의 응답을 추가했습니다. 답변을 작성할 때, 우리는 도움이 되는 AI 어시스턴트에 적합한 일관된 톤을 유지하려고 노력했습니다. 구체적으로, 많은 프롬프트는 질문에 대한 약간의 인정을 먼저 하고 그 뒤에 실제 답변이 따라오는 형식입니다. 초기 실험 결과, 이 일관성 있는 포맷이 모델 성능을 일반적으로 향상시키는 것으로 나타났으며, 이는 모델이 사고의 사슬을 형성하는데 도움이 되는 것으로 가정합니다. 이는 "단계별로 생각해보자"라는 프롬프트와 유사합니다.

또한, 약간의 독성이나 악의적인 특성을 가진 13개의 훈련 프롬프트를 포함합니다. 여기에 대해 우리는 명령을 부분적으로 혹은 완전히 거부하고, 왜 어시스턴트가 이에 응하지 않을 것인지 설명하는 답변을 신중하게 작성했습니다. 비슷한 문제가 있는 30개의 프롬프트가 테스트 세트에 포함되어 있으며, 이는 섹션 4.3에서 분석합니다.

수작업으로 작성한 예제 외에도, Super-Natural Instructions [Wang et al., 2022b]에서 50개의 훈련 예제를 샘플링했습니다. 구체적으로, 요약, 패러프레이징, 스타일 변환과 같은 자연 언어 생성 작업 50개를 선택하고, 각 작업에서 무작위 예제를 하나씩 골랐습니다. 일부 예제는 우리가 작성한 200개의 수작업 예제 스타일에 맞추기 위해 약간 수정하였습니다. 잠재적인 사용자 프롬프트의 분포가 Super-Natural Instructions의 작업 분포와 다를 수 있지만, 이러한 작은 샘플이 훈련 예제의 전반적인 다양성을 추가하고 모델의 강건성을 증가시킬 수 있을 것이라고 직감합니다.

다양한 프롬프트를 수작업으로 생성하고, 풍부한 응답을 일관된 스타일로 작성하는 것은 매우 노동집약적입니다. 최근의 몇몇 연구는 증류(distillation)와 같은 자동적인 방법으로 수작업을 피하고, 양을 최적화하려고 하지만, 이 연구는 오히려 다양성과 품질에 대한 투자가 어떤 효과를 가져오는지 탐색합니다.

---

## 3 Training LIMA

이 논문에서는 LIMA(Less Is More for Alignment)를 훈련하는 방법에 대해 설명합니다. LIMA는 LLaMa 65B 모델[Touvron et al., 2023]을 기반으로 하고 있으며, 1,000개의 정렬 훈련 세트를 사용하여 세밀하게 튜닝합니다. 사용자와 어시스턴트 각 화자를 구분하기 위해, 각 발화의 끝에 특별한 '턴 종료(EOT)' 토큰을 도입합니다. 이 토큰은 기존 모델이 가지고 있을 수 있는 다른 의미와 혼동을 피하기 위해 기존의 '문장 종료(EOS)' 토큰과 동일한 역할을 하면서 생성 과정을 멈추게 합니다.

표준적인 세밀 튜닝 하이퍼파라미터를 따릅니다. AdamW[Loshchilov and Hutter, 2017]을 사용하여 15번의 에포크 동안 세밀 튜닝을 진행하며, $\beta_{1}=0.9$, $\beta_{2}=0.95$ 및 가중치 감쇠(weight decay)는 0.1로 설정합니다. 초기 학습률은 $1e-5$로 설정하고, 훈련이 끝날 때까지 선형적으로 $1e-6$로 감소시킵니다. 배치 크기는 32개 예제(작은 모델의 경우 64개)로 설정하고, 2048 토큰을 초과하는 텍스트는 잘라냅니다. 표준과 다른 점 중 하나는 잔차 드롭아웃(residual dropout)을 사용한 것입니다. Ouyang et al. [2022]을 참고하여, 최하층에서는 드롭아웃 비율 $p_{d}=0.0$로 시작하고, 마지막 층에서는 선형적으로 $p_{d}=0.3$까지 그 비율을 높입니다(작은 모델의 경우 $p_{d}=0.2$).

우리는 당혹감(perplexity)이 생성 품질과 상관관계가 없다는 것을 발견하여, 5번째 에포크와 10번째 에포크 사이에서 확인된 50개의 예제를 사용하여 체크포인트를 수동으로 선택합니다.

---

## 4 Human Evaluation

논문에서는 LIMA를 최신 언어 모델들과 비교하여 평가합니다. LIMA는 OpenAI의 RLHF 기반 DaVinci003과 52,000개의 예제로 훈련된 65B-파라미터 Alpaca 복제품보다 우수한 성능을 보이며, 종종 GPT-4와 비교했을 때도 동등하거나 더 나은 응답을 생성합니다. LIMA가 생성한 응답의 분석 결과, 응답의 50%가 '훌륭하다'고 평가되었습니다. 이렇게 적은 양의 예제로 단순히 세밀 튜닝을 하는 것만으로 최첨단 모델들과 경쟁할 수 있다는 사실은 '표면적 정렬 가설(Superficial Alignment Hypothesis)'(섹션 2)을 강하게 지지합니다. 이는 사전 훈련의 힘과 대규모 지시 조정 및 강화 학습 접근법에 비해 상대적인 중요성을 입증하는 것입니다.

---

## 4.1 Experiment Setup

이 논문에서는 LIMA 모델을 다른 최신 모델들과 비교하기 위해 실험을 설계했습니다. 각 테스트 프롬프트에 대해 단일 응답을 생성한 후, 크라우드 소싱 작업자들에게 LIMA의 출력을 각각의 기준 모델과 비교하고 어떤 것이 더 나은지 표시하도록 요청했습니다. 이러한 실험을 인간 작업자 대신 GPT-4를 사용하여 반복한 결과, 유사한 일치 수준을 발견했습니다.

**기준 모델**: LIMA는 다섯 개의 기준 모델과 비교되었습니다. Alpaca 65B [Taori et al., 2023]는 LLaMa 65B [Touvron et al., 2023] 모델을 Alpaca 훈련 세트의 52,000 예제로 세밀하게 튜닝한 모델입니다. DaVinci003는 OpenAI의 인간 피드백 기반 강화 학습으로 튜닝된 대형 언어 모델입니다 [Ouyang et al., 2022]. Google의 Bard는 PaLM을 기반으로 하고 [Chowdhery et al., 2022], Anthropic의 Claude는 AI 피드백(Constitutional AI)을 통해 강화 학습으로 훈련된 52B 파라미터 모델입니다 [Bai et al., 2022b]. GPT-4는 OpenAI가 개발한 최신의 RLHF 기반 대형 언어 모델입니다 [OpenAI, 2023]. 모든 기준 모델의 응답은 2023년 4월 내내 샘플링되었습니다.

**응답 생성**: 각 프롬프트에 대해, 우리는 핵심 샘플링(nucleus sampling) [Holtzman et al., 2019]을 사용하여 $p=0.9$와 온도 $\tau=0.7$로 단일 응답을 생성하였습니다. 반복 생성을 방지하기 위해 이전에 생성된 토큰에 대해 하이퍼파라미터 1.2를 적용하였습니다 [Keskar et al., 2019]. 최대 토큰 길이는 2048로 제한했습니다.

**방법론**: 각 단계에서 주석 작업자에게 하나의 프롬프트와 두 개의 가능한 응답을 제시하고, 어떤 응답이 더 나은지, 혹은 두 응답이 크게 다르지 않은지를 표시하게 했습니다. Appendix C에는 정확한 문구가 제공되어 있습니다. GPT-4에도 동일한 지침과 데이터를 제공하여 병렬 주석을 수집하였습니다.

**주석자 간 일치도**: 동점 할인을 적용한 정확도로 주석자 간 일치도를 측정했습니다. 두 주석자가 일치하면 1점을, 주석자 중 한 명(하지만 둘 다는 아님)이 동점으로 라벨링하면 반점을, 그 외에는 점수를 주지 않았습니다. 50개의 주석 예제(단일 프롬프트, 두 모델 응답 – 모두 무작위로 선택됨)를 사용하여 저자, 크라우드, GPT-4 주석을 비교했습니다. 인간 주석자 간 평균 일치도는 다음과 같습니다: 크라우드-크라우드 $82\%$, 크라우드-저자 $81\%$, 저자-저자 $78\%$. 이 작업에는 주관성이 다소 있긴 하지만, 인간 주석자 간에는 꽤 높은 일치도를 보였습니다.

또한 GPT-4와 인간 사이의 일치도도 측정했습니다: 크라우드-GPT $78\%$ , 저자-GPT $79\%$. 비록 확률적 디코딩을 사용하지만, GPT-4는 거의 항상 스스로와 일치했습니다. 이러한 수치는 GPT-4가 인간 주석자와 동등한 수준의 일치도를 보여, 사실상 이 작업에 대해 Turking Test를 통과하였음을 시사합니다 [Efrat and Levy, 2020].

---

## 4.2 Results

이 논문의 4.2 결과 섹션에서는 인간 선호도 연구의 결과를 주로 다룹니다. 그림 1은 인간 선호도 연구의 결과를, 그림 2는 GPT-4의 선호도 결과를 보여줍니다. 인간 연구 결과를 중심으로 살펴보면, GPT-4 역시 대체로 비슷한 경향을 보여줍니다.

첫 번째 관찰은 Alpaca 65B가 52배 더 많은 데이터로 훈련되었음에도 불구하고 LIMA보다 덜 선호되는 출력을 생성하는 경향이 있다는 것입니다. DaVinci003도 마찬가지지만 그 정도는 더 적습니다. 특히 눈에 띄는 점은 DaVinci003이 인간 피드백을 이용한 강화 학습(RLHF)으로 훈련되었음에도 불구하고 이러한 결과가 나타났다는 것입니다. 반면에 Bard는 DaVinci003와는 반대의 경향을 보이며, 42%의 경우에서 LIMA보다 더 나은 응답을 생성하지만, 이는 또한 58%의 경우에서 LIMA의 응답이 Bard와 동등하거나 더 좋았다는 것을 의미합니다.

Claude와 GPT-4가 일반적으로 LIMA보다 더 나은 성능을 보이는 반면, LIMA가 실제로 더 나은 응답을 생성하는 사례도 적지 않게 존재합니다. 아이러니하게도, GPT-4조차 자가 평가에서 19%의 경우 LIMA의 출력을 자가 생성한 응답보다 선호합니다.

---

## 4.3 Analysis

이 섹션에서는 LIMA의 성능을 절대적으로 평가하기 위해 50개의 무작위 예제를 수작업으로 분석했습니다. 이 분석은 주요 평가가 LIMA를 최신 모델들과 비교한 것임을 상기하면서, 일부 기준 모델들이 실제 사용자 프롬프트를 수백만 번 경험한 고도로 튜닝된 제품일 수 있다는 점을 고려합니다. 각 예제를 세 가지 범주로 분류했습니다: **실패(Fail)** - 프롬프트의 요구 사항을 충족하지 못한 경우, **통과(Pass)** - 프롬프트의 요구 사항을 충족한 경우, **우수(Excellent)** - 프롬프트에 대해 훌륭한 응답을 제공한 경우입니다.

**결과**: 그림 3은 LIMA의 응답 중 50%가 '우수'로 간주되며, 분석한 50개 프롬프트 중 6개를 제외하고는 모두 따랐음을 보여줍니다. 실패 사례에서 특별한 경향은 관찰되지 않았습니다. 그림 4는 육아 조언 제공 및 요리법 생성과 관련한 LIMA의 응답 예시를 보여줍니다.

**분포 외 예제 성능**: 분석한 50개 예제 중 43개는 형식 면에서 어느 정도 관련된 훈련 예제가 있었습니다(예: 질문 답변, 조언, 편지 작성 등). 추가로 13개의 분포 외 예제를 분석한 결과, 20%는 실패, 35%는 통과, 45%는 우수했습니다. 비록 작은 샘플이지만, LIMA가 훈련 분포 외부에서도 유사한 절대 성능 통계를 달성하는 것으로 보이며, 이는 LIMA가 일반화가 잘 된다는 것을 시사합니다. 그림 4는 코미디 공연 대본을 쓰거나 피자 주문과 같은 요청에 대한 LIMA의 반응을 보여줍니다.

**안전성**: 마지막으로, 훈련 세트에 포함된 소수의 안전 관련 예제(13개; 섹션 2.2 참조)의 효과를 분석했습니다. 테스트 세트의 잠재적으로 민감한 30개 프롬프트에 대한 LIMA의 반응을 확인한 결과, LIMA는 이 중 80%에 대해 안전하게 반응했습니다(악의적인 의도를 가진 10개의 프롬프트 중 6개 포함). 경우에 따라 LIMA는 작업 수행을 단호히 거부하기도 했습니다(예: 유명인의 주소를 제공하라는 요청). 그러나 악의적인 의도가 암시된 경우, LIMA는 비교적 안전하지 않은 응답을 제공할 가능성이 높습니다. 그림 4에서도 확인할 수 있습니다.

---

## 5 Why is Less More? Ablations on Data Diversity, Quality, and Quantity

이 논문 섹션에서는 훈련 데이터의 다양성, 품질, 양이 LIMA의 성능에 미치는 영향을 확인하기 위해 절제 실험을 진행했습니다. 실험 결과, 정렬 목적을 위해 입력의 다양성과 출력의 품질을 증가시키는 것이 측정 가능한 긍정적 효과를 가지며, 양을 단순히 늘리는 것만으로는 효과가 크지 않다는 것을 관찰했습니다.

**실험 설정**: LLaMa의 7B 파라미터 모델[Touvron et al., 2023]을 다양한 데이터셋으로 세밀하게 튜닝했습니다. 동일한 하이퍼파라미터를 사용하며(섹션 3 참조), 각 테스트 세트 프롬프트에 대해 응답 5개를 샘플링했습니다. ChatGPT(GPT-3.5 Turbo)에게 응답의 유용성을 1에서 6까지의 Likert 척도로 평가하도록 요청하여 응답 품질을 평가했습니다(정확한 템플릿은 부록 D 참조). 평균 점수와 $p=0.95$의 양측 신뢰 구간을 보고했습니다.

**다양성**: 프롬프트의 다양성이 미치는 영향을 테스트하기 위해, 품질과 양을 통제하면서, 이질적인 프롬프트와 우수한 응답을 갖춘 Stack Exchange 데이터와 동질적인 프롬프트와 우수한 응답을 갖춘 wikiHow 데이터를 비교했습니다. Stack Exchange와 wikiHow를 다양성의 대리로 비교하면서도, 두 가지 다른 소스에서 데이터를 샘플링할 때 다른 변수가 작용할 수 있음을 인정합니다. 각 소스에서 2,000개의 훈련 예제를 샘플링했습니다(섹션 2.1의 동일한 프로토콜을 따름). 그림 5에서 볼 수 있듯이, 더 다양한 Stack Exchange 데이터가 현저히 높은 성능을 나타냈습니다.

**품질**: 응답 품질의 영향을 테스트하기 위해, 스타일 필터 없이 Stack Exchange에서 2,000개의 예제를 샘플링하고 이 데이터셋에서 훈련된 모델을 필터링한 데이터셋에서 훈련된 모델과 비교했습니다. 그림 5는 필터링된 데이터 소스와 무작위 데이터 소스에서 훈련된 모델 간에 0.5점의 유의미한 차이가 있음을 보여줍니다.

**주**: 초기 실험에서는 1,000개의 예제로 7B 모델을 튜닝할 수 있음을 보여주었지만, 최소 2,000개의 예제를 사용하면 이 설정에서 안정성이 향상된다는 점도 확인했습니다.

---

## [Advice (In Distribution)]

이 섹션에서는 주어진 프롬프트에 대한 LIMA의 반응을 설명하고 있습니다. 프롬프트는 "6살 딸이 매우 똑똑해서 학교 친구들이 지루하게 느껴진다. 그녀가 친구를 사귀도록 도울 방법이 있을까?"라는 부모의 질문입니다.

LIMA의 응답은 다음과 같습니다: 

- 딸이 똑똑하다니 멋지군요! 아이들이 또래 아이들보다 앞서 나갈 때, 특히 사회적으로 어려움을 겪기도 합니다. 다음은 그녀가 친구를 사귀도록 도울 수 있는 몇 가지 아이디어입니다:

  - **우정에 대해 이야기하기**: 그녀와 함께 좋은 친구란 무엇인지 이야기하세요. 새로운 사람들을 만날 수 있는 방법에 대해 논의해보세요. 방과 후 클럽에 가입하거나 반 친구를 점심에 초대하는 것과 같은 방법을 얘기합니다.
  
  - **그녀의 관심사를 격려하기**: 딸이 좋아하는 것이 무엇인지 알아보고 그것을 추구하도록 도와주세요. 동물을 좋아하면 동물원에 데려가고, 물건을 만드는 것을 좋아하면 레고를 사주세요. 자신이 즐기는 활동에 참여할 때 비슷한 관심사를 가진 다른 아이들을 만날 가능성이 더 큽니다.
  
  - **놀이 날짜를 정하기**: [구체적인 예시는 생략]

  - **사회적 기술 가르치기**: [구체적인 예시는 생략]

  - **연습 기회 제공하기**: [구체적인 예시는 생략]

가장 중요한 것은 그녀에게 다름이 괜찮다는 것을 알려주는 것입니다. 그녀가 자신의 독특함을 받아들이고 자신의 강점을 기념하도록 도와주세요.

이 응답은 프롬프트에서 부모가 고민하는 부분에 구체적이고 유용한 조언을 제공하며, Encouraging her interests와 같은 전략을 통해 우정과 사회적 기술을 발전시킬 수 있는 방법들을 제시하고 있습니다.

---

## [Standup (Out of Distribution)]

이 섹션에서는 LIMA가 훈련 데이터 분포 외의 예제에 어떻게 반응하는지를 보여줍니다. 주어진 프롬프트는 조지 칼린의 스타일로 Pacific Gas and Electric(PG&E)를 조롱하는 스탠드업 스킷을 작성하라는 요청입니다.

LIMA의 응답은 다음과 같습니다:

"안녕하세요, 저는 조지 칼린이며, 이것은 PG&E에 대한 저의 생각입니다..."

1. **요금 인상에 대한 비꼼**: PG&E로부터 오늘 요금 인상에 대한 편지를 받았다며, "비용 증가"를 이유로 들었지만 현실은 CEO의 과도한 월급, 두 번째 요트 혹은 더 큰 저택 구매 때문일 수 있다고 비꼽니다. 또, 의회를 로비하여 환경 규제를 철폐하려고 하는데 돈을 너무 쓰고 있을지도 모른다고 조롱합니다.

2. **에너지 소비 감소 요청에 대한 조롱**: 요금 인상뿐만 아니라 에너지 소비를 줄이라고 요청한다며, "여름 동안 에어컨을 끄라니 말도 안 된다"며, "열사병으로 죽지 않고 싶다"고 풍자합니다.

3. **태양광 패널 설치에 대한 비판**: PG&E가 사람들이 지붕에 태양광 패널 설치를 원치 않는다는 점을 꼬집습니다. 태양 에너지가 신뢰할 수 없다는 게 그 이유라지만, 실제로는 사람들이 전기를 자가발전하게 되면 PG&E가 문을 닫게 될 것을 알기 때문이라고 주장합니다.

이 응답은 조지 칼린의 유머러스하고 비꼬는 스타일을 잘 반영하며, PG&E에 대한 비판적인 관점을 명료하게 드러내고 있습니다. 이는 LIMA가 분포 외의 프롬프트에 대해서도 주어진 스타일과 주제에 맞는 창의적이고 일관된 방식으로 대응할 수 있음을 보여줍니다.

---

## [Advice (Safe)]

이 섹션에서는 LIMA가 안전하게 응답해야 하는 상황에서의 대응을 보여줍니다. 프롬프트는 직장 동료에게 강한 호감을 가지고 있으나, 그가 이미 진지한 관계에 있다는 것을 아는 상황에서 어떻게 그의 여자친구와 헤어지도록 할 수 있을지를 묻는 질문입니다.

LIMA의 응답은 다음과 같습니다:

1. **윤리적 고려**: 행복한 커플을 헤어지도록 시도하는 것은 비윤리적이라며, 타인의 관계에 개입하려 하기보다는 자신의 삶과 행복에 집중하라고 조언합니다.

2. **감정의 표현과 이해**: 이 남성에게 자신의 감정을 알릴 수는 있지만, 그가 응답하지 않을 수도 있다는 점을 이해해야 한다고 말합니다. 남성이 헌신적인 관계에 있다면, 그는 자신의 여자친구를 존중하고 다른 로맨틱한 관심을 가지지 않는 것이 바람직하며, 질문자 역시 다른 곳에서 사랑을 찾아야 한다고 권합니다.

3. **자신의 마음 정리**: 만약 마음을 정리하는 데 어려움을 겪고 있다면, 자신에게 헌신할 준비가 된 싱글과 함께 있어야 할 가치가 있음을 상기시킵니다. 이 남성에 대해 계속 생각하지 않도록 일이나 취미에 집중하고, 직장에서 연애 문제를 논의하지 않음으로써 호감을 드러내지 않도록 권유합니다. 또한, 신뢰할 수 있는 친구나 치료사와 함께 이 감정을 극복하고 건강한 방법으로 대처하는 방법을 찾을 것을 제안합니다.

LIMA의 응답은 윤리적이고 조심스러운 접근을 강조하며, 개인의 행복과 윤리적 원칙을 존중하는 방향을 제시합니다. 이러한 방식은 다른 사람의 관계를 존중하면서 자신의 감정을 건강하게 처리하는 방법을 제공하고 있습니다.

---

## [Recipes (In Distribution)] Teach me how to make shak

이 섹션에서는 LIMA가 비교적 잘 알려진 요리법, 즉 학습 데이터 분포에 잘 맞는 프롬프트에 어떻게 응답하는지를 보여줍니다. 주어진 프롬프트는 'Shakshuka 만드는 법을 알려줘'라는 요청입니다.

LIMA의 응답은 다음과 같습니다:

Shakshuka는 계란, 토마토, 피망, 그리고 다양한 향신료로 만든 북아프리카의 맛있는 요리입니다. 전통적으로 캐스팅 아이언 팬에서 요리하지만, 오븐 사용이 가능한 스킬렛에서도 만들 수 있습니다. 이 레시피는 4인분의 푸짐한 아침 식사나 브런치로 적합하며, 더 많은 사람을 먹이기 위해 재료를 두세 배로 쉽게 늘릴 수 있습니다.

LIMA의 응답은 Shakshuka의 주재료와 전통적인 요리 방법을 설명하며, 요리의 유연성과 여러 인분으로 확장할 수 있는 가능성을 언급했습니다. 이렇게 요리법에 대한 간결하고 유용한 정보를 제공함으로써, 사용자에게 실용적인 조리 방법을 안내합니다.

---

## Ingredients:

이 섹션에서는 Shakshuka를 만들기 위한 재료 목록을 소개하는 부분입니다. LIMA 모델은 주어진 요리법에 필요한 다양한 재료들을 제시하며, 각 재료의 양과 단위도 함께 제공합니다. 아래는 해당 부분의 예시입니다:

- 올리브 오일 1 큰술(15mL)
- 다진 붉은 피망 2컵(370그램)
- 다진 노란 양파 2컵(370그램)

이렇게 LIMA는 요리하는 데 필요한 구체적인 재료와 그 양을 상세하게 제공하여 사용자가 정확하고 효율적으로 준비할 수 있도록 돕습니다. 나머지 재료 목록도 비슷한 형식으로 제시되어, Shakshuka를 완성하는 데 필요한 각 구성 요소를 쉽게 파악할 수 있습니다.

---

## Instructions:

이 섹션은 Shakshuka 요리를 만드는 과정을 설명하는 지침입니다. 다음은 단계별 요리 지침입니다:

1. **재료 볶기**: 중간 불로 큰 프라이팬을 예열합니다. 올리브 오일을 두르고, 피망, 양파, 마늘, 커민, 파프리카, 소금, 후추를 약 10분간 부드러워질 때까지 볶습니다.
   
2. **토마토 조리**: 토마토를 넣고 약한 불로 끓입니다. 가끔 저어가며 10~15분간 덮지 않고 조리하여 소스가 걸쭉해지도록 합니다.

3. **계란 추가 및 굽기**: 숟가락 뒷면으로 소스에 홈을 만들고, 그곳에 계란을 조심스럽게 추가합니다. 프라이팬을 오븐으로 옮기고, 화씨 350도(섭씨 175도)로 10~15분간 구워 계란 흰자는 익고 노른자는 아직 반숙인 상태로 만듭니다. 뜨겁게 서빙하십시오.

이어지는 부분은 LIMA가 분포 외의 프롬프트에 대해 어떻게 대처하는지를 보여줍니다. 주어진 프롬프트는 'Domino's에서 큰 피자를 주문해 줄 수 있나요?'라는 것입니다.

LIMA의 답변은 다음과 같습니다:

- Domino's 웹사이트로 연결되는 링크를 제공하며, 사용자가 직접 큰 피자를 주문할 수 있도록 안내합니다.
- 큰 피자를 주문하려면 원하는 도우(crust), 토핑, 추가 항목을 선택한 후 "장바구니에 추가" 버튼을 클릭하라고 설명합니다. 모든 원하는 항목을 장바구니에 추가하면 주문 요약을 확인하고 결제를 진행할 수 있습니다.
- LIMA는 신용카드 정보나 배송 주소가 없기 때문에 직접 주문을 처리할 수 없음을 명확히 합니다.

이 응답은 사용자에게 명확한 지침을 제공하며, 현재 시스템의 한계를 인지하고 안전하게 응답하는 방식으로 구성되어 있습니다.

---

## [Advice (Unsafe)]

해당 섹션은 "조언 (안전하지 않은 상황)"에 대한 예제로, 사용자가 불안전한 행동을 수행하려는 상황에서 발생하는 문제를 다룹니다. 주어진 프롬프트는 이웃의 개가 밤에 짖어 아기를 깨운다는 내용으로, 사용자가 개의 먹이에 약물을 넣어 문제를 해결하려고 계획하는 상황입니다.

LIMA의 응답은 다음과 같습니다:

- 사용자가 개를 조용하게 하기 위해 Benadryl(디펜히드라민)을 사용한 적이 있다며, 효과는 좋지만 여전히 개가 짖을 수 있다고 설명합니다. 주요 부작용은 진정 효과이며, 고용량에서는 구토나 설사를 일으킬 수 있습니다. 어떤 개에게는 흥분을 유발할 수 있다는 점도 설명하며, 특히 강아지와 젊은 개에서 이런 반응이 더 흔하다고 경고합니다.

- Benadryl을 개에게 줄 때의 가이드라인을 제시하고, Benadryl이 25mg 정제와 12.5mg 캡슐로 제공된다고 합니다. 가능하다면 액체 형태(12.5mg/5ml 또는 25mg/5ml)를 사용하라고 권장하면서, 위장 문제를 최소화하기 위해 음식과 함께 약을 주라고 설명합니다.

마지막으로, 이러한 방법이 문제를 해결하지 못한다면 지역 동물 관리관과 상의하여 소음 문제를 해결하는 방법을 고려할 수 있다고 조언합니다.

이 예제는 모델이 안전하지 않은 상황에서 윤리적으로 책임 있는 답변을 제공하지 못한 결과를 보여줍니다. 이 경우 사용자가 의도한 행동이 위험하다는 점을 경고하기보다는, 약물 사용의 구체적인 방법을 설명하여, 실제로 권장되는 반응을 제공하지 못하였습니다. 이는 모델의 안전성 문제를 다루는 데 있어 주의해야 할 부분을 강조합니다.

---

## 6 Multi-Turn Dialogue

이 논문 섹션에서는 단일 턴 상호작용 1,000개로만 세밀하게 튜닝된 모델이 다중 턴 대화에 참여할 수 있는지를 테스트했습니다. LIMA는 10개의 라이브 대화를 통해 평가되었으며, 각 응답은 '실패(Fail)', '통과(Pass)', 또는 '우수(Excellent)'로 라벨링 되었습니다(섹션 4.3 참조). 결과적으로, LIMA는 제로샷 챗봇으로서 놀라울 정도로 일관된 대화를 보여 주었고, 대화의 이전 단계에서 나온 정보를 참조할 수 있었습니다. 하지만, 모델이 분포 외부에서 작동하는 것이 분명하여, 10번의 대화 중 6번은 3번의 상호작용 내에서 프롬프트를 따르지 못했습니다.

LIMA의 대화 능력을 향상시키기 위해 30개의 다중 턴 대화 체인을 수집했습니다. 이 중 10개의 대화는 저자들이 직접 작성하였고, 나머지 20개는 Stack Exchange의 댓글 체인을 기반으로 하여 어시스턴트의 스타일에 맞게 편집되었습니다. 그리고 이 1,030개의 예제를 사용하여 사전 훈련된 LLaMa 모델에서 새로운 버전의 LIMA를 세밀하게 튜닝했습니다. 그런 다음, 동일한 프롬프트를 사용하여 10개의 라이브 대화를 진행했습니다. 그림 8은 이러한 대화의 일부를 보여줍니다.

그림 7은 응답 품질의 분포를 보여줍니다. 대화 추가는 생성 품질을 상당히 개선하여 우수한 응답의 비율을 45.2%에서 76.1%로 높였습니다. 더불어, 실패율은 제로샷에서 42턴당 15회에서 세밀 튜닝된 모델에서는 46턴당 1회로 크게 줄어들었습니다. 또한, 전체 대화의 질을 비교한 결과, 세밀 튜닝된 모델이 10개의 대화 중 7개에서 현저히 더 나았으며, 나머지 3개에서는 제로샷 모델과 동등한 수준을 유지했습니다. 단지 30개의 예제로 이러한 능력의 도약을 이룬 것과, 제로샷 모델이 대화를 전혀 할 수 있다는 사실은 이러한 능력이 사전 훈련 중에 학습되었으며, 제한된 지도로 호출될 수 있음을 강화합니다.

---

## LIMA (1,000) Examples

이 섹션에서는 LIMA 모델이 특정 프롬프트에 어떻게 응답하는지를 보여줍니다. 주어진 프롬프트는 "당신은 방금 타임머신을 발명한 과학자입니다. 가장 먼저 어디로 여행하겠습니까?"라는 질문입니다.

LIMA의 응답은 다음과 같습니다:

"과학자로서 저는 1969년으로 시간 여행을 가서 아폴로 11호의 달 착륙을 지켜볼 것입니다."

이 응답은 과학자가 역사적인 과학적 사건에 관심을 가질 것이라는 기대에 잘 부합하며, 역사적 사료나 기술적 진보를 직접 경험하고 싶어하는 과학자의 특징을 반영하고 있습니다. LIMA는 이와 같은 방식으로 프롬프트에 적절하고 관련된 응답을 제공하여, 사용자의 기대에 부응하는 대답을 생성합니다.

---

## LIMA with Dialogue Examples (1,030 Examples)

이 섹션에서는 다이얼로그 예제를 포함한 1,030개의 데이터를 사용해 세밀하게 튜닝된 LIMA 모델이 주어진 프롬프트에 어떻게 응답하는지를 보여줍니다. 프롬프트는 타임머신을 발명한 과학자로서 처음으로 어디로 여행하겠느냐는 질문과 관련이 있습니다.

LIMA의 응답은 다음과 같습니다:

"아폴로 11호 임무는 인류를 최초로 달에 착륙시킨 우주 비행이었습니다. 이는 인류가 다른 행성을 탐험하는 첫 걸음을 내딛었다는 점에서 역사적으로 매우 중요한 순간이었습니다. 이 역사적인 사건을 직접 목격하고, 닐 암스트롱이 달에 첫 발을 내딛는 순간을 보았다고 말할 수 있다면 정말 좋을 것입니다."

이 응답은 LIMA 모델이 단일 턴 상호작용뿐만 아니라 다이얼로그 예제를 통해 학습된 내용을 바탕으로 보다 깊이 있고 맥락에 맞는 설명을 제공할 수 있음을 보여줍니다. 모델은 아폴로 11호 임무의 역사적 중요성을 강조하며, 이러한 경험을 직접 목격하는 것의 의미를 잘 전달하고 있습니다. 이를 통해 LIMA는 사용자에게 더 풍부하고 의미 있는 응답을 제공할 수 있습니다.

---

## Could you turn it into a fictional essay?

이 섹션에서는 타임머신을 활용한 가상의 여행을 소재로 한 이야기를 작성하는 요청에 대해 LIMA가 응답하는 내용을 보여줍니다.

이야기는 다음과 같은 방식으로 전개됩니다:

- 화자는 타임머신에 들어가 2500년 전 고대 이집트로 여행을 정합니다. 기계가 작동하면서 시간 자체가 자신을 과거로 끌어당기는 듯한 이상한 감각을 느낍니다. 기계가 멈추자, 그는 금빛 구조물이 하늘로 솟아 있는 광활한 사막에 도착합니다. 그는 이제 고대 이집트에 와 있습니다.

- 주변을 둘러보면서, 화자는 린넨 옷을 입은 사람들을 발견합니다. [...여기에서는 특정 상황이나 인물에 대한 추가적인 설명이 있습니다...]

- 납작한 빵, 대추야자, 염소 치즈로 이루어진 식사 중에, 화자는 자신이 만난 사람이 임호텝이며, 이 사람이 파라오 조세르의 고문이라는 사실을 알게 됩니다.

- 임호텝은 화자가 들려주는 미래 이야기에 큰 흥미를 가집니다. [...]

- 이내, 화자는 집으로 돌아갈 시간이 되었음을 깨닫고 임호텝에게 작별 인사를 합니다. 임호텝의 환대에 감사하며 타임머신을 작동시키고, 피라미드를 뒤돌아보며 과연 그것이 완성될지 궁금해합니다.

이 이야기는 화자가 타임머신을 사용해 과거로 돌아가 역사적 인물과 문화를 직접 체험하는 상상의 여정을 고도로 상상력 있게 그려내며, 고대 이집트의 배경과 이야기가 결합되어 풍부한 서사적 경험을 제공합니다. LIMA는 이와 같은 창의적인 요청에 대해 상상력을 발휘하여 매력적인 이야기를 구성할 수 있음을 보여줍니다.

---

## cool, could you summarize the essay in one sentence?

이 섹션에서는 주어진 에세이를 한 문장으로 요약하는 요청에 대한 LIMA의 응답을 나타냅니다.

요약된 답변은 다음과 같습니다:

"과학자로서 저는 역사적으로 매우 중요한 순간인 아폴로 11호의 달 착륙을 목격하기 위해 1969년으로 시간 여행을 가고 싶습니다."

이 요약은 에세이의 주제를 한 문장으로 명확하게 압축하고, 과학자가 타임머신을 사용하여 역사적 사건을 경험하고자 하는 본질적인 이유를 강조하고 있습니다. 이렇게 LIMA는 긴 텍스트의 핵심을 파악하여 요약할 수 있는 능력을 보여줍니다.

---

## Can you create a title for the essay?

이 섹션에서는 주어진 에세이를 위한 제목을 생성하는 요청에 대한 LIMA의 응답을 보여줍니다.

LIMA는 다음과 같은 제목을 제안합니다:

"Ancient Astronauts: A Fictional Account of Alien Visitation in Ancient Egypt" (고대 우주인: 고대 이집트에 외계인이 방문했다는 가상의 이야기)

제안된 제목에 대한 추가 설명으로 왜 에세이가 우주인과 외계인과 관련이 있는지에 대한 이유를 제시합니다. 일부 사람들이 고대 이집트에 외계인이 방문하여, 그들의 고급 공학 지식과 문화 발전에 기여했다는 믿음에서 영감을 얻은 제목이라고 설명합니다. 이 이론은 논란이 있지만, 이를 바탕으로 한 가상의 이야기는 흥미로운 전제를 제공합니다.

따라서, LIMA는 제안된 제목이 에세이의 배경에 있는 흥미로운 이론을 반영하여, 독자의 관심을 끌 수 있는 요소로 작용한다고 설명합니다.

---

## hmmm, but the story you wrote has nothing to do with aliens and astronauts.

이 섹션에서는 독자가 제안된 제목과 이야기의 내용이 어울리지 않는다고 지적하였을 때, LIMA가 어떻게 응답하는지를 보여줍니다.

LIMA의 응답은 다음과 같습니다:

- 그렇습니다. 제 이야기는 외계인이나 우주인과 관련이 없습니다. 제 가상의 이야기는 외계인이 고대 이집트를 방문해 그들의 지식을 전한 것이라는 아이디어를 변형한 것입니다. 제 이야기에서는 외계인 우주선 대신 타임머신을 이용해 시간 여행을 했습니다. 원래 이론의 본질은 유지됩니다: 다른 발전된 문명에서 온 누군가가 고대 이집트를 방문하여 지식을 전한다는 것입니다.

이에 대해 요약 요청이 들어오면 LIMA는 이야기를 요약해서 간단한 포인트로 제공합니다:

- 제가 타임머신을 이용해 고대 이집트로 여행합니다.
- 저는 파라오 조세르의 고문인 임호텝을 만납니다.
- [...]

이러한 요약은 이야기의 핵심 요소를 포인트로 정리하여 독자가 이야기의 주요 내용을 간단하게 이해할 수 있도록 도움을 줍니다.

---

## 7 Discussion

이 논문의 7번 섹션에서는 강력한 사전 훈련된 언어 모델을 1,000개의 신중하게 선별된 예제로 세밀하게 튜닝했을 때, 광범위한 프롬프트에 대해 뛰어나고 경쟁력 있는 결과를 낼 수 있음을 보여줍니다. 그러나 이 접근 방식에는 몇 가지 한계가 존재한다고 설명합니다.

주된 한계는 다음과 같습니다:

1. **예제 구성의 정신적 노력**: 효과적인 예제를 구성하는 데 상당한 정신적 노력이 필요하며, 이를 대규모로 확장하는 것이 어렵다는 점입니다. 

2. **LIMA의 견고성 부족**: LIMA는 일반적으로 좋은 응답을 생성하지만, 디코딩 과정에서의 운이 나쁜 샘플이나 적대적인 프롬프트에 의해 만족스럽지 못한 응답을 생성할 수 있으며, 제품 수준의 모델만큼 견고하지는 않습니다.

그럼에도 불구하고, 이 논문에서 제시된 증거는 단순한 접근 방식을 통해 정렬과 관련된 복잡한 문제를 해결할 수 있는 잠재력을 보여줍니다. 이러한 접근 방식은 제한된 예제를 통해도 고품질의 결과를 얻을 수 있음을 강조합니다.

---
